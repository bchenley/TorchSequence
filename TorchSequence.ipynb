{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bchenley/TorchSequence/blob/main/TorchSequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9I72fiMKm4lU"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install torch --quiet\n",
        "!pip install pytorch_lightning --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xS_iyBPb2gSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccfc91d6-1cb5-4eff-c840-e5288861559c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchsummary import summary\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar\n",
        "\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "%load_ext tensorboard\n",
        "\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn.preprocessing as skp\n",
        "\n",
        "import scipy.io\n",
        "import scipy as sc\n",
        "from scipy import signal as sp\n",
        "from scipy import interpolate as interp\n",
        "from scipy.special import factorial\n",
        "\n",
        "import itertools\n",
        "import math\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "import sys\n",
        "\n",
        "import random\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import copy\n",
        "\n",
        "import pickle\n",
        "\n",
        "import time\n",
        "\n",
        "import pdb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NF7g9B-BPR2d"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5tIh447EWLB"
      },
      "outputs": [],
      "source": [
        "class FeatureTransform():\n",
        "  '''\n",
        "  A class for performing feature scaling and transformation operations on data.\n",
        "  '''\n",
        "\n",
        "  def __init__(self,\n",
        "                scale_type = 'minmax', minmax = [0., 1.], dim = 0,\n",
        "                device = 'cpu', dtype = torch.float32):\n",
        "    '''\n",
        "    Initializes the FeatureTransform instance.\n",
        "\n",
        "    Args:\n",
        "        scale_type (str): The type of scaling to be applied. Options are 'identity', 'minmax', or 'standard'.\n",
        "        minmax (list): The minimum and maximum values to scale the data when using 'minmax' scaling.\n",
        "        dim (int): The dimension along which the scaling is applied.\n",
        "        device (str): The device to be used for computations.\n",
        "        dtype (torch.dtype): The data type to be used for computations.\n",
        "    '''\n",
        "\n",
        "    if scale_type not in ['identity', 'minmax', 'standard']:\n",
        "        raise ValueError(f\"scale_type ({scale_type}) is not set to 'identity', 'minmax', or 'standard'.\")\n",
        "\n",
        "    self.scale_type = scale_type\n",
        "    self.minmax = minmax\n",
        "    self.dim = dim\n",
        "    self.device, self.dtype = device, dtype\n",
        "\n",
        "  def identity(self, X):\n",
        "    '''\n",
        "    Returns the input data as it is without any scaling.\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): The input data.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The input data unchanged.\n",
        "    '''\n",
        "    self.min_, self.max_ = X.min(self.dim).values, X.max(self.dim).values\n",
        "    return X\n",
        "\n",
        "  def standardize(self, X):\n",
        "    '''\n",
        "    Performs standardization on the input data.\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): The input data.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The standardized input data.\n",
        "    '''\n",
        "    self.mean_, self.std_ = X.mean(self.dim), X.std(self.dim)\n",
        "    return (X - self.mean_) / self.std_\n",
        "\n",
        "  def inverse_standardize(self, X):\n",
        "    '''\n",
        "    Applies inverse standardization on the input data.\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): The input data.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The inversely standardized input data.\n",
        "    '''\n",
        "    return X * self.std_ + self.mean_\n",
        "\n",
        "  def normalize(self, X):\n",
        "    '''\n",
        "    Performs normalization on the input data.\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): The input data.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The normalized input data.\n",
        "    '''\n",
        "    self.min_, self.max_ = X.min(self.dim).values, X.max(self.dim).values\n",
        "    return (X - self.min_) / (self.max_ - self.min_) * (self.minmax[1] - self.minmax[0]) + self.minmax[0]\n",
        "\n",
        "  def inverse_normalize(self, X):\n",
        "    '''\n",
        "    Applies inverse normalization on the input data.\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): The input data.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The inversely normalized input data.\n",
        "    '''\n",
        "    return (X - self.minmax[0]) * (self.max_ - self.min_) / (self.minmax[1] - self.minmax[0]) + self.min_\n",
        "\n",
        "  def fit_transform(self, X):\n",
        "    '''\n",
        "    Fits the scaling parameters based on the input data and transforms the data accordingly.\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): The input data.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The transformed input data.\n",
        "    '''\n",
        "    if self.scale_type == 'identity':\n",
        "        X_transformed = self.identity(X)\n",
        "    elif self.scale_type == 'minmax':\n",
        "        X_transformed = self.normalize(X)\n",
        "    elif self.scale_type == 'standard':\n",
        "        X_transformed = self.standardize(X)\n",
        "\n",
        "    return X_transformed\n",
        "\n",
        "  def transform(self, X):\n",
        "    '''\n",
        "    Transforms the input data based on the previously fitted scaling parameters.\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): The input data.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The transformed input data.\n",
        "    '''\n",
        "    if self.scale_type == 'identity':\n",
        "        X_transformed = X\n",
        "    elif self.scale_type == 'minmax':\n",
        "        X_transformed = (X - self.min_) / (self.max_ - self.min_) * (self.minmax[1] - self.minmax[0]) + self.minmax[0]\n",
        "    elif self.scale_type == 'standard':\n",
        "        X_transformed = (X - self.mean_) / self.std_\n",
        "\n",
        "    return X_transformed\n",
        "\n",
        "  def inverse_transform(self, X):\n",
        "    '''\n",
        "    Applies the inverse transformation on the input data.\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): The input data.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The inversely transformed input data.\n",
        "    '''\n",
        "    if self.scale_type == 'identity':\n",
        "        X_inverse_transformed = X\n",
        "    elif self.scale_type == 'minmax':\n",
        "        X_inverse_transformed = self.inverse_normalize(X)\n",
        "    elif self.scale_type == 'standard':\n",
        "        X_inverse_transformed = self.inverse_standardize(X)\n",
        "\n",
        "    return X_inverse_transformed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MofuMI2c1GG"
      },
      "outputs": [],
      "source": [
        "class Loss():\n",
        "  '''\n",
        "  A class for computing loss functions.\n",
        "  '''\n",
        "\n",
        "  def __init__(self, name='mse', dims=0):\n",
        "    '''\n",
        "    Initializes the Loss instance.\n",
        "\n",
        "    Args:\n",
        "        name (str): The name of the loss function. Options are 'mae', 'mse', 'mase', 'rmse', 'nmse', 'mape', 'fb'.\n",
        "        dims (int): The dimension along which the loss is computed.\n",
        "    '''\n",
        "    self.name = name\n",
        "    self.dims = dims\n",
        "\n",
        "  def __call__(self, y_pred, y_true):\n",
        "    '''\n",
        "    Computes the loss based on the predicted and true values.\n",
        "\n",
        "    Args:\n",
        "        y_pred (torch.Tensor): The predicted values.\n",
        "        y_true (torch.Tensor): The true values.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The computed loss value.\n",
        "    '''\n",
        "    if self.name == 'mae':\n",
        "        # Mean Absolute Error (L1 loss)\n",
        "        loss = (y_true - y_pred).abs().nanmean(dim=self.dims)\n",
        "    elif self.name == 'mse':\n",
        "        # Mean Squared Error\n",
        "        loss = (y_true - y_pred).pow(2).nanmean(dim=self.dims)\n",
        "    elif self.name == 'mase':\n",
        "        # Mean Absolute Scaled Error\n",
        "        loss = (y_true - y_pred).abs().nanmean(dim=self.dims) / (y_true.diff(n=1, dim=self.dims).abs().nanmean(dim=self.dims))\n",
        "    elif self.name == 'rmse':\n",
        "        # Root Mean Squared Error\n",
        "        loss = (y_true - y_pred).pow(2).nanmean(dim=self.dims).sqrt()\n",
        "    elif self.name == 'nmse':\n",
        "        # Normalized Mean Squared Error\n",
        "        loss = (y_true - y_pred).pow(2).nanmean(dim=self.dims) / y_true.pow(2).nanmean(dim=self.dims)\n",
        "    elif self.name == 'mape':\n",
        "        # Mean Absolute Percentage Error\n",
        "        loss = (((y_true - y_pred) / y_true).abs() * 100).nanmean(dim=self.dims)\n",
        "    elif self.name == 'fb':\n",
        "        # Fractional Bias\n",
        "        loss = (y_pred.nansum(dim=self.dims) - y_true.nansum(dim=self.dims)) / y_true.nansum(dim=self.dims)\n",
        "\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX28HQzCFgwL"
      },
      "outputs": [],
      "source": [
        "def fft(x, fs=1, dim=0, nfft=None, norm='backward',\n",
        "        device=None, dtype=torch.complex64):\n",
        "  '''\n",
        "  Computes the Fast Fourier Transform (FFT) of the input signal.\n",
        "\n",
        "  Args:\n",
        "      x: The input signal. If not a torch.Tensor, it will be converted to one.\n",
        "      fs: The sampling frequency of the input signal.\n",
        "      dim: The dimension(s) along which to compute the FFT.\n",
        "      nfft: The number of FFT points. If None, it is set to the size of the input signal along the specified dimension.\n",
        "      norm: The normalization mode. Options are 'backward' (default) and 'forward'.\n",
        "      device: The device to perform the computation on. If None, the default device is used.\n",
        "      dtype: The data type of the output.\n",
        "\n",
        "  Returns:\n",
        "      freq: The frequency values corresponding to the FFT.\n",
        "      x_fft_mag: The magnitude of the FFT coefficients.\n",
        "      x_fft_phase: The phase of the FFT coefficients.\n",
        "  '''\n",
        "  if not isinstance(x, torch.Tensor):\n",
        "      if isinstance(x, pd.core.frame.DataFrame):\n",
        "          x = x.values\n",
        "      x = torch.tensor(x).to(device=device, dtype=dtype)\n",
        "\n",
        "  if nfft is None:\n",
        "      nfft = x.shape[dim]\n",
        "      print(f'nfft set to {nfft}')\n",
        "\n",
        "  s, dim = [nfft, dim if isinstance(dim, int) else (-2, -1)]\n",
        "\n",
        "  s += np.mod(s, 2)\n",
        "  x_fft = torch.fft.fftn(x, s=s, dim=dim, norm=norm).to(device=device, dtype=dtype)\n",
        "\n",
        "  N = int(s // 2)\n",
        "\n",
        "  if isinstance(dim, int):\n",
        "      freq = torch.fft.fftfreq(s, d=1 / fs).to(device=device)[:N]\n",
        "\n",
        "      x_fft = x_fft.split(N, dim=dim)[0]\n",
        "\n",
        "      x_fft_mag = 2.0 / s * torch.abs(x_fft)\n",
        "\n",
        "      x_fft_phase = torch.angle(x_fft)\n",
        "\n",
        "  elif dim == (-2, -1):\n",
        "      freq = torch.meshgrid(freq, freq, indexing='ij')\n",
        "\n",
        "      x_fft_mag = 2 / s * torch.abs(x_fft[..., :N, :N])\n",
        "\n",
        "      x_fft_phase = torch.angle(x_fft)[..., :N, :N]\n",
        "\n",
        "  else:\n",
        "      raise ValueError(f'dim ({dim}) must be 1 or (-2, -1)... for now.')\n",
        "\n",
        "  return freq, x_fft_mag, x_fft_phase\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def periodogram(X, sf=1, window='hann', nfft=512,\n",
        "                detrend=None, return_onesided=True,\n",
        "                scaling='density', axis=0):\n",
        "  '''\n",
        "  Computes the periodogram of a signal using the SciPy library.\n",
        "\n",
        "  Args:\n",
        "      X: The input signal.\n",
        "      sf: The sampling frequency of the input signal.\n",
        "      window: The window function to apply to the signal.\n",
        "      nfft: The number of points to compute the FFT.\n",
        "      detrend: The detrend function to remove a trend from the signal.\n",
        "      return_onesided: If True, returns only the one-sided spectrum for real inputs.\n",
        "      scaling: The scaling mode for the power spectrum.\n",
        "      axis: The axis along which to compute the periodogram.\n",
        "\n",
        "  Returns:\n",
        "      f: The frequencies at which the periodogram is computed.\n",
        "      psd: The power spectral density (periodogram) of the signal.\n",
        "  '''\n",
        "  if nfft is None:  # or nfft < x.shape[dim]\n",
        "      nfft = X.shape[axis]\n",
        "      print(f'nfft set to {nfft}')\n",
        "\n",
        "  f, psd = sp.periodogram(X, sf=sf, window=window, nfft=nfft,\n",
        "                          detrend=detrend, return_onesided=return_onesided,\n",
        "                          scaling=scaling, axis=axis)\n",
        "\n",
        "  return f, psd\n"
      ],
      "metadata": {
        "id": "K_N6yGrOsV08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def moving_average(X, window):\n",
        "    '''\n",
        "    Applies a moving average filter to the input signal.\n",
        "\n",
        "    Args:\n",
        "        X: The input signal.\n",
        "        window: The window of the moving average filter.\n",
        "\n",
        "    Returns:\n",
        "        y: The output signal after applying the moving average filter.\n",
        "    '''\n",
        "    if isinstance(X, torch.Tensor):\n",
        "        X = X.cpu().numpy()\n",
        "    if isinstance(window, torch.Tensor):\n",
        "        window = window.cpu().numpy()\n",
        "\n",
        "    len_window = window.shape[0]\n",
        "\n",
        "    y = np.empty_like(X)\n",
        "\n",
        "    ww = []\n",
        "\n",
        "    for i in range(X.shape[0]):\n",
        "        is_odd = int(np.mod(len_window, 2) == 1)\n",
        "\n",
        "        m = np.arange((i - (len_window - is_odd) / 2), (i + (len_window - is_odd) / 2 - (is_odd == 0) + 1),\n",
        "                      dtype=np.compat.long)\n",
        "\n",
        "        k = m[(m >= 0) & (m < X.shape[0])]\n",
        "\n",
        "        window_ = window[(m >= 0) & (m < X.shape[0])]\n",
        "        window_ /= window_.sum(0)\n",
        "\n",
        "        y[i] = np.dot(window_.T, X[k])\n",
        "\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "0d2DXQOxtQSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def butter(x, critical_frequency, butter_type = 'low', filter_order = 3, sampling_rate = 1):\n",
        "    '''\n",
        "    Applies a Butterworth filter to the input signal.\n",
        "\n",
        "    Args:\n",
        "        x: The input signal.\n",
        "        critical_frequency: The critical frequency of the filter.\n",
        "        butter_type: The type of Butterworth filter to apply.\n",
        "        filter_order: The order of the filter.\n",
        "        sampling_rate: The sampling rate of the input signal.\n",
        "\n",
        "    Returns:\n",
        "        y: The output signal after applying the Butterworth filter.\n",
        "    '''\n",
        "    b, a = sp.butter(N=filter_order,\n",
        "                     Wn=critical_frequency / (sampling_rate / 2),\n",
        "                     btype=butter_type,\n",
        "                     output='ba')\n",
        "\n",
        "    y = sp.filtfilt(b, a, x, axis=0)\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "Up6Pcw8WtUxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw50yp6ZaRor"
      },
      "outputs": [],
      "source": [
        "def fill(X, steps, interp_kind = 'linear'):\n",
        "  '''\n",
        "  Fills missing values in a dataset using interpolation.\n",
        "\n",
        "  Args:\n",
        "      X: The input dataset.\n",
        "      steps: The time steps associated with the data points.\n",
        "      interp_kind: The kind of interpolation method to use.\n",
        "\n",
        "  Returns:\n",
        "      X: The dataset with missing values filled using interpolation.\n",
        "  '''\n",
        "  for i in range(X.shape[-1]):\n",
        "      X_i = X[:, i].copy()\n",
        "\n",
        "      interpolator = Interpolator(kind=interp_kind)\n",
        "\n",
        "      if np.any(np.isnan(X_i)):\n",
        "          X_i_notnan = X_i[~np.isnan(X_i)]\n",
        "          steps_i_notnan = steps[~np.isnan(X_i)]\n",
        "\n",
        "          interpolator.fit(steps_i_notnan, X_i_notnan)\n",
        "\n",
        "          X[:, i] = interpolator.interp_fn(steps)\n",
        "\n",
        "  return X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN7PyOG2Mt2S"
      },
      "outputs": [],
      "source": [
        "class Interpolator():\n",
        "  '''\n",
        "  Interpolator for 1-dimensional data.\n",
        "\n",
        "  Args:\n",
        "      kind: The kind of interpolation method to use.\n",
        "      axis: The axis along which to interpolate.\n",
        "\n",
        "  Attributes:\n",
        "      interp_fn: The interpolation function.\n",
        "\n",
        "  Methods:\n",
        "      fit: Fits the interpolation function to the provided data.\n",
        "\n",
        "  '''\n",
        "  def __init__(self, kind='linear', axis=0):\n",
        "      super().__init__()\n",
        "\n",
        "      self.kind = kind\n",
        "      self.axis = axis\n",
        "      self.interp_fn = None\n",
        "\n",
        "  def fit(self, x, y):\n",
        "      '''\n",
        "      Fits the interpolation function to the provided data.\n",
        "\n",
        "      Args:\n",
        "          x: The x-coordinates of the data points.\n",
        "          y: The y-coordinates of the data points.\n",
        "\n",
        "      '''\n",
        "      if isinstance(x, torch.Tensor):\n",
        "          x = x.detach().numpy()\n",
        "      if isinstance(y, torch.Tensor):\n",
        "          y = y.detach().numpy()\n",
        "\n",
        "      self.interp_fn = sc.interpolate.interp1d(x, y, kind=self.kind, axis=self.axis)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkIvooFdMQiE"
      },
      "outputs": [],
      "source": [
        "def remove_outliers(X, steps, abs_max_change=[np.inf], z_change_critical=[7], interp_type='linear'):\n",
        "  '''\n",
        "  Remove outliers from the input data.\n",
        "\n",
        "  Args:\n",
        "      X: The input data array.\n",
        "      steps: The corresponding steps array.\n",
        "      abs_max_change: The absolute maximum change threshold for outlier removal.\n",
        "      z_change_critical: The z-change critical value for outlier removal.\n",
        "      interp_type: The type of interpolation to use for filling the gaps left by removed outliers.\n",
        "\n",
        "  Returns:\n",
        "      Y: The input data with outliers removed and gaps filled.\n",
        "      steps: The corresponding steps array after outlier removal.\n",
        "\n",
        "  '''\n",
        "  if len(abs_max_change) == 1:\n",
        "      abs_max_change = abs_max_change * X.shape[-1]\n",
        "  if len(z_change_critical) == 1:\n",
        "      z_change_critical = z_change_critical * X.shape[-1]\n",
        "\n",
        "  x, i_x, interpolator = [], [], []\n",
        "\n",
        "  for i in range(X.shape[-1]):\n",
        "      X_i = X[:, i]\n",
        "\n",
        "      i_all = np.arange(X_i.shape[0], dtype=np.compat.long)\n",
        "      i_x.append(i_all)\n",
        "\n",
        "      diff = np.diff(X_i)\n",
        "      z_diff = (diff - diff.mean()) / diff.std()\n",
        "\n",
        "      i_discard = np.where((np.abs(diff) > abs_max_change[i]) | (np.abs(z_diff) > z_change_critical[i]))[0]\n",
        "\n",
        "      if len(i_discard) > 0:\n",
        "          interpolator.append(Interpolator(kind=interp_type))\n",
        "      else:\n",
        "          interpolator.append(None)\n",
        "\n",
        "      while len(i_discard) > 0:\n",
        "          j_discard = i_discard[0] + [0, 1]\n",
        "          j_discard = j_discard[j_discard < len(X_i)]\n",
        "\n",
        "          j_discard = j_discard[np.abs(X_i.mean() - X_i[j_discard]).argmax()]\n",
        "          X_i = np.delete(X_i, j_discard)\n",
        "          i_x[-1] = np.delete(i_x[-1], j_discard)\n",
        "\n",
        "          diff = np.diff(X_i)\n",
        "          z_diff = (diff - diff.mean()) / diff.std()\n",
        "\n",
        "          i_discard = np.where((np.abs(diff) > abs_max_change[i]) | (np.abs(z_diff) > z_change_critical[i]))[0]\n",
        "\n",
        "      x.append(X_i.reshape(-1, 1))\n",
        "\n",
        "      print(f\"{i+1}/{X.shape[-1]}\")\n",
        "\n",
        "  i_min = np.max([np.min(i) for i in i_x])\n",
        "  i_max = np.min([np.max(i) for i in i_x])\n",
        "\n",
        "  i_all = np.arange(i_min, i_max + 1, dtype=np.compat.long)\n",
        "  steps = steps[i_all]\n",
        "\n",
        "  for i, interp in enumerate(interpolator):\n",
        "      if interp is not None:\n",
        "          interp.fit(i_x[i], x[i])\n",
        "          x[i] = interp.interp_fn(i_all)\n",
        "\n",
        "  Y = np.concatenate(x, -1)\n",
        "\n",
        "  return Y, steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYinwMDn1dm9"
      },
      "outputs": [],
      "source": [
        "class BaselineModel():\n",
        "  '''\n",
        "  Baseline models for time series prediction.\n",
        "\n",
        "  Args:\n",
        "      model_type (str): Type of baseline model.\n",
        "      naive_steps (int): Number of steps for the naive baseline model.\n",
        "      ma_window_size (int): Moving average window size for the moving average baseline model.\n",
        "      decay (float): Decay factor for exponential smoothing models.\n",
        "      trend (list): Trend parameters for exponential smoothing models.\n",
        "      period (int): Period parameter for seasonal exponential smoothing model.\n",
        "      seasonal (list): Seasonal parameters for seasonal exponential smoothing model.\n",
        "\n",
        "  '''\n",
        "\n",
        "  def __init__(self, model_type='naive', naive_steps=1, ma_window_size=20, decay=0.5, trend=[0.5, 1.0], period=1, seasonal=[0.5, 1.0]):\n",
        "      self.model_type = model_type\n",
        "      self.naive_steps = naive_steps\n",
        "      self.decay, self.trend, self.seasonal, self.period = decay, trend, seasonal, period\n",
        "      self.ma_window_size = ma_window_size\n",
        "\n",
        "  def ma_prediction(self, input):\n",
        "      '''\n",
        "      Moving average prediction.\n",
        "\n",
        "      Args:\n",
        "          input: The input data tensor.\n",
        "\n",
        "      Returns:\n",
        "          prediction: The predicted values based on the moving average model.\n",
        "\n",
        "      '''\n",
        "      prediction = []\n",
        "      for n in range(input.shape[0]):\n",
        "          prediction_n = input[np.max([0, n - self.ma_window_size]):n].mean(0, keepdims=True)\n",
        "          prediction.append(prediction_n)\n",
        "\n",
        "      prediction = torch.cat(prediction, 0)\n",
        "\n",
        "      return prediction\n",
        "\n",
        "  def naive_prediction(self, input):\n",
        "    '''\n",
        "    Naive prediction.\n",
        "\n",
        "    Args:\n",
        "        input: The input data tensor.\n",
        "\n",
        "    Returns:\n",
        "        prediction: The predicted values based on the naive model.\n",
        "\n",
        "    '''\n",
        "    prediction = torch.full((self.naive_steps, input.shape[1]), float('nan')).to(input)\n",
        "    for n in range(self.naive_steps, input.shape[0]):\n",
        "        prediction_n = input[n - self.naive_steps]\n",
        "        prediction = torch.cat((prediction, prediction_n), 0)\n",
        "\n",
        "    return prediction\n",
        "\n",
        "  def ses_prediction(self, input):\n",
        "    '''\n",
        "    Single exponential smoothing prediction.\n",
        "\n",
        "    Args:\n",
        "        input: The input data tensor.\n",
        "\n",
        "    Returns:\n",
        "        prediction: The predicted values based on the single exponential smoothing model.\n",
        "\n",
        "    '''\n",
        "    prediction = torch.full((1, input.shape[1]), float('nan')).to(input)\n",
        "    for n in range(1, input.shape[0]):\n",
        "        prediction_n = self.decay * input[n - 1] + (1 - self.decay) * prediction_n[n - 1]\n",
        "        prediction = torch.cat((prediction, prediction_n), 0)\n",
        "\n",
        "  def des_prediction(self, input):\n",
        "    '''\n",
        "    Double exponential smoothing prediction.\n",
        "\n",
        "    Args:\n",
        "        input: The input data tensor.\n",
        "\n",
        "    Returns:\n",
        "        prediction: The predicted values based on the double exponential smoothing model.\n",
        "\n",
        "    '''\n",
        "    prediction = torch.full((1, input.shape[1]), float('nan')).to(input)\n",
        "    level_prev, trend_prev = 0, 0\n",
        "    for n in range(1, input.shape[0]):\n",
        "        level_n = self.decay * input[n - 1] + (1 - self.decay) * (level_prev + trend_prev)\n",
        "        trend_n = self.trend[0] * (level_n - level_prev) + (1 - self.trend[0]) * trend_prev\n",
        "\n",
        "        prediction_n = level_n + self.trend[1] * trend_n\n",
        "\n",
        "        prediction = torch.cat((prediction, prediction_n), 0)\n",
        "\n",
        "        level_prev, trend_prev = level_n, trend_prev\n",
        "\n",
        "    return prediction\n",
        "\n",
        "  def tes_prediction(self, input):\n",
        "    '''\n",
        "    Seasonal exponential smoothing prediction.\n",
        "\n",
        "    Args:\n",
        "        input: The input data tensor.\n",
        "\n",
        "    Returns:\n",
        "        prediction: The predicted values based on the seasonal exponential smoothing model.\n",
        "\n",
        "    '''\n",
        "    prediction = torch.full((self.period, input.shape[1]), float('nan')).to(input)\n",
        "    level_prev, trend_prev = 0, 0\n",
        "    season = torch.zeros_like(input).to(input)\n",
        "    for n in range(self.period, input.shape[0]):\n",
        "        level_n = self.decay * input[n - 1] + (1 - self.decay) * (level_prev + trend_prev) + season[n - self.period]\n",
        "        trend_n = self.trend[0] * (level_n - level_prev) + (1 - self.trend[0]) * trend_prev\n",
        "        season[n] = self.seasonal[0] * (input[n - 1] - level_prev - trend_prev) + (1 - self.seasonal) * season[\n",
        "            n - self.period]\n",
        "\n",
        "        prediction_n = level_n + self.trend[1] * trend_n + self.seasonal[1] * season[n]\n",
        "\n",
        "        prediction = torch.cat((prediction, prediction_n), 0)\n",
        "\n",
        "        level_prev, trend_prev = level_n, trend_prev\n",
        "\n",
        "  def __call__(self, input):\n",
        "    '''\n",
        "    Make predictions based on the selected model type.\n",
        "\n",
        "    Args:\n",
        "        input: The input data tensor.\n",
        "\n",
        "    Returns:\n",
        "        prediction: The predicted values based on the selected model type.\n",
        "\n",
        "    '''\n",
        "    if self.model_type == 'naive':\n",
        "        return self.naive_prediction(input)\n",
        "\n",
        "    if self.model_type == 'moving_average':\n",
        "        return self.ma_prediction(input)\n",
        "\n",
        "    if self.model_type == 'bayesian':\n",
        "        return self.bayesian_prediction(input)\n",
        "\n",
        "    if self.model_type == 'ses':\n",
        "        return self.ses_prediction(input)\n",
        "\n",
        "    if self.model_type == 'des':\n",
        "        return self.des_prediction(input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJvtdAJE0JRJ"
      },
      "outputs": [],
      "source": [
        "class Polynomial(torch.nn.Module):\n",
        "  '''\n",
        "  Polynomial regression model.\n",
        "\n",
        "  Args:\n",
        "  - in_features (int): Number of input features.\n",
        "  - degree (int): Degree of the polynomial.\n",
        "  - coef_init (torch.Tensor): Initial coefficients for the polynomial. If None, coefficients are initialized randomly.\n",
        "  - coef_train (bool): Whether to train the coefficients.\n",
        "  - coef_reg (list): Regularization parameters for the coefficients. [Regularization weight, regularization exponent]\n",
        "  - zero_order (bool): Whether to include the zeroth-order term (constant) in the polynomial.\n",
        "  - device (str): Device to use for computation ('cpu' or 'cuda').\n",
        "  - dtype (torch.dtype): Data type of the coefficients.\n",
        "  '''\n",
        "\n",
        "  def __init__(self,\n",
        "               in_features, degree=1, coef_init=None, coef_train=True,\n",
        "               coef_reg=[0.001, 1], zero_order=True,\n",
        "               device='cpu', dtype=torch.float32):\n",
        "      super(Polynomial, self).__init__()\n",
        "\n",
        "      self.to(device=device, dtype=dtype)\n",
        "\n",
        "      if coef_init is None:\n",
        "          coef_init = torch.nn.init.normal_(torch.empty(in_features, degree + int(zero_order)))\n",
        "\n",
        "      coef = torch.nn.Parameter(data=coef_init.to(device=device, dtype=dtype), requires_grad=coef_train)\n",
        "\n",
        "      self.coef, self.coef_reg = coef, coef_reg\n",
        "      self.in_features, self.degree = in_features, degree\n",
        "      self.zero_order = zero_order\n",
        "      self.device, self.dtype = device, dtype\n",
        "\n",
        "  def forward(self, X):\n",
        "    '''\n",
        "    Perform forward pass to compute polynomial regression.\n",
        "\n",
        "    Args:\n",
        "    - X (torch.Tensor): Input data tensor of shape (batch_size, in_features).\n",
        "\n",
        "    Returns:\n",
        "    - y (torch.Tensor): Output predictions of shape (batch_size).\n",
        "    '''\n",
        "\n",
        "    X = X.to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "    pows = torch.arange(1 - int(self.zero_order), (self.degree + 1), device=self.device, dtype=self.dtype)\n",
        "\n",
        "    y = (X.unsqueeze(-1).pow(pows) * self.coef).sum(-1)\n",
        "\n",
        "    return y\n",
        "\n",
        "  def penalize(self):\n",
        "    '''\n",
        "    Compute the penalty term for coefficient regularization.\n",
        "\n",
        "    Returns:\n",
        "    - penalty (torch.Tensor): Penalty term based on coefficient regularization.\n",
        "    '''\n",
        "\n",
        "    return self.coef_reg[0] * torch.norm(self.coef, p=self.coef_reg[1]) * int(self.coef.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzQTuBu4KzEL"
      },
      "outputs": [],
      "source": [
        "class LRU(torch.nn.RNN):\n",
        "  '''\n",
        "  Laguerre Recurrent Unit (LRU) model based on RNN architecture.\n",
        "\n",
        "  Args:\n",
        "      input_size (int): Number of expected features in the input.\n",
        "      hidden_size (int): Number of features in the hidden state.\n",
        "      weight_reg (list): Regularization parameters for the weights. [Regularization weight, regularization exponent]\n",
        "      weight_norm (int): Norm to be used for weight regularization.\n",
        "      bias (bool): If True, adds a learnable bias to the output.\n",
        "      relax_init (list): Initial relaxation values for the LRU model.\n",
        "      relax_train (bool): Whether to train the relaxation values.\n",
        "      relax_minmax (list): Minimum and maximum relaxation values for each filter bank.\n",
        "      device (str): Device to use for computation ('cpu' or 'cuda').\n",
        "      dtype (torch.dtype): Data type of the model parameters.\n",
        "  '''\n",
        "\n",
        "  def __init__(self,\n",
        "               input_size, hidden_size, weight_reg=[0.001, 1], weight_norm=2, bias=False,\n",
        "               relax_init=[0.5], relax_train=True, relax_minmax=[[0.1, 0.9]], device='cpu', dtype=torch.float32):\n",
        "\n",
        "    super(LRU, self).__init__(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
        "\n",
        "    self.to(device=device, dtype=dtype)\n",
        "\n",
        "    num_filterbanks = len(relax_init)\n",
        "\n",
        "    if len(relax_minmax) == 1:\n",
        "        relax_minmax = relax_minmax * num_filterbanks\n",
        "\n",
        "    relax_init = torch.tensor(relax_init).reshape(num_filterbanks,)\n",
        "\n",
        "    relax = torch.nn.Parameter(relax_init.to(device=device, dtype=dtype), requires_grad=relax_train)\n",
        "\n",
        "    if input_size > 1:\n",
        "        input_block = torch.nn.Linear(in_features=input_size, out_features=num_filterbanks, bias=bias)\n",
        "    else:\n",
        "        input_block = torch.nn.Identity()\n",
        "\n",
        "    self.bias_hh_l0.requires_grad = False\n",
        "    self.bias_hh_l0.requires_grad = False\n",
        "\n",
        "    self.input_size, self.hidden_size = input_size, hidden_size\n",
        "    self.num_filterbanks = num_filterbanks\n",
        "    self.input_block = input_block\n",
        "    self.relax_minmax = relax_minmax\n",
        "    self.relax = relax\n",
        "    self.weight_reg, self.weight_norm = weight_reg, weight_norm\n",
        "    self.device, self.dtype = device, dtype\n",
        "\n",
        "    # Remove built-in weights and biases\n",
        "    self.weight_ih_l0 = None\n",
        "    self.weight_hh_l0 = None\n",
        "    self.bias_ih_l0 = None\n",
        "    self.bias_hh_l0 = None\n",
        "\n",
        "  def init_hiddens(self, num_samples):\n",
        "    '''\n",
        "    Initialize the hidden state of the LRU model.\n",
        "\n",
        "    Args:\n",
        "        num_samples (int): Number of samples in the batch.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Initialized hidden state tensor.\n",
        "    '''\n",
        "    return torch.zeros((self.num_filterbanks, num_samples, self.hidden_size)).to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "  def cell(self, input, hiddens=None):\n",
        "    '''\n",
        "    LRU cell computation for a single time step.\n",
        "\n",
        "    Args:\n",
        "        input (torch.Tensor): Input tensor for the current time step.\n",
        "        hiddens (torch.Tensor): Hidden state tensor.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Output tensor for the current time step.\n",
        "        torch.Tensor: Updated hidden state tensor.\n",
        "    '''\n",
        "    num_samples, input_size = input.shape\n",
        "\n",
        "    hiddens = hiddens if hiddens is not None else self.init_hiddens(num_samples)\n",
        "\n",
        "    sq_relax = torch.sqrt(self.relax)\n",
        "\n",
        "    hiddens_new = torch.zeros_like(hiddens).to(hiddens)\n",
        "\n",
        "    hiddens_new[..., 0] = sq_relax[:, None] * hiddens[..., 0] + (1 - sq_relax ** 2).sqrt()[:, None] * self.input_block(input).t()\n",
        "\n",
        "    for i in range(1, self.hidden_size):\n",
        "        hiddens_new[..., i] = sq_relax[:, None] * (hiddens[..., i] + hiddens_new[..., i - 1]) - hiddens[..., i - 1]\n",
        "\n",
        "    output = hiddens_new.permute(1, 0, 2)  # [batch_size, num_filters, hidden_size]\n",
        "\n",
        "    return output, hiddens_new\n",
        "\n",
        "  def forward(self, input, hiddens=None):\n",
        "    '''\n",
        "    Forward pass of the LRU model.\n",
        "\n",
        "    Args:\n",
        "        input (torch.Tensor): Input tensor.\n",
        "        hiddens (torch.Tensor): Hidden state tensor.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Output tensor.\n",
        "        torch.Tensor: Updated hidden state tensor.\n",
        "    '''\n",
        "    num_samples, input_len, input_size = input.shape\n",
        "\n",
        "    hiddens = self.init_hiddens(num_samples) if hiddens is None else hiddens\n",
        "\n",
        "    output = []\n",
        "    for n, input_n in enumerate(input.split(1, 1)):\n",
        "        output_n, hiddens = self.cell(input_n.squeeze(1), hiddens)\n",
        "        output.append(output_n.unsqueeze(1))\n",
        "\n",
        "    output = torch.cat(output, 1)\n",
        "\n",
        "    return output, hiddens\n",
        "\n",
        "  def generate_laguerre_functions(self, max_len):\n",
        "    '''\n",
        "    Generate Laguerre functions up to a specified maximum length.\n",
        "\n",
        "    Args:\n",
        "        max_len (int): Maximum length of the Laguerre functions.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Generated Laguerre functions.\n",
        "    '''\n",
        "    with torch.no_grad():\n",
        "        hiddens = self.init_hiddens(1)\n",
        "\n",
        "        impulse = torch.zeros((1, max_len, self.input_size)).to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "        impulse[:, 0, :] = 1\n",
        "\n",
        "        output, hiddens = self.forward(impulse, hiddens)\n",
        "\n",
        "        return output\n",
        "\n",
        "  def clamp_relax(self):\n",
        "    '''\n",
        "    Clamp relaxation values to the specified minimum and maximum range.\n",
        "    '''\n",
        "    for i in range(self.num_filterbanks):\n",
        "        self.relax[i].data.clamp_(self.relax_minmax[i][0], self.relax_minmax[i][1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTVBpCNzxuYz"
      },
      "outputs": [],
      "source": [
        "class HiddenLayer(torch.nn.Module):\n",
        "  '''\n",
        "  Hidden layer module with various activation functions and regularization options.\n",
        "\n",
        "  Args:\n",
        "      in_features (int): Number of input features.\n",
        "      out_features (int or None): Number of output features. If None or 0, output features will be the same as input features.\n",
        "      bias (bool): If True, adds a learnable bias to the output.\n",
        "      activation (str): Activation function to use. Options: 'identity', 'polynomial', 'tanh', 'sigmoid', 'softmax', 'relu'.\n",
        "      weight_reg (list): Regularization parameters for the weights. [Regularization weight, regularization exponent]\n",
        "      weight_norm (int): Norm to be used for weight regularization.\n",
        "      degree (int): Degree of the polynomial activation function.\n",
        "      coef_init (torch.Tensor): Initial coefficients for the polynomial activation function. If None, coefficients are initialized randomly.\n",
        "      coef_train (bool): Whether to train the coefficients.\n",
        "      coef_reg (list): Regularization parameters for the coefficients. [Regularization weight, regularization exponent]\n",
        "      zero_order (bool): Whether to include the zeroth-order term (constant) in the polynomial activation function.\n",
        "      softmax_dim (int): Dimension along which to apply softmax activation.\n",
        "      dropout_p (float): Dropout probability.\n",
        "      device (str): Device to use for computation ('cpu' or 'cuda').\n",
        "      dtype (torch.dtype): Data type of the model parameters.\n",
        "\n",
        "  '''\n",
        "\n",
        "  def __init__(self, in_features, out_features=None, bias=True, activation='identity',\n",
        "                weight_reg=[0.001, 1], weight_norm=2, degree=1, coef_init=None, coef_train=True,\n",
        "                coef_reg=[0.001, 1], zero_order=False, softmax_dim=-1, dropout_p=0.0,\n",
        "                device='cpu', dtype=torch.float32):\n",
        "    super(HiddenLayer, self).__init__()\n",
        "\n",
        "    self.to(device=device, dtype=dtype)\n",
        "\n",
        "    if out_features is None or out_features == 0:\n",
        "        out_features = in_features\n",
        "        f1 = torch.nn.Identity()\n",
        "    else:\n",
        "        if isinstance(in_features, list):  # bilinear (must be len = 2)\n",
        "            class Bilinear(torch.nn.Module):\n",
        "                def __init__(self, in1_features=in_features[0], in2_features=in_features[1],\n",
        "                              out_features=out_features, bias=bias, device=device, dtype=dtype):\n",
        "                    super(Bilinear, self).__init__()\n",
        "\n",
        "                    self.F = torch.nn.Bilinear(in1_features, in2_features, out_features, bias)\n",
        "\n",
        "                def forward(self, input):\n",
        "                    input1, input2 = input\n",
        "                    return self.F(input1, input2)\n",
        "\n",
        "            f1 = Bilinear()\n",
        "        else:\n",
        "            f1 = torch.nn.Linear(in_features=in_features, out_features=out_features,\n",
        "                                  bias=bias, device=device, dtype=dtype)\n",
        "\n",
        "    if activation == 'identity':\n",
        "        f2 = torch.nn.Identity()\n",
        "    elif activation == 'polynomial':\n",
        "        f2 = Polynomial(in_features=out_features, degree=degree, coef_init=coef_init,\n",
        "                        coef_train=coef_train, coef_reg=coef_reg, zero_order=zero_order,\n",
        "                        device=device, dtype=dtype)\n",
        "    elif activation == 'tanh':\n",
        "        f2 = torch.nn.Tanh()\n",
        "    elif activation == 'sigmoid':\n",
        "        f2 = torch.nn.Sigmoid()\n",
        "    elif activation == 'softmax':\n",
        "        f2 = torch.nn.Softmax(dim=softmax_dim)\n",
        "    elif activation == 'relu':\n",
        "        f2 = torch.nn.ReLU()\n",
        "    else:\n",
        "        raise ValueError(f\"activation ({activation}) must be 'identity', 'polynomial', 'tanh', 'sigmoid', or 'relu'.\")\n",
        "\n",
        "    F = torch.nn.Sequential(f1, f2)\n",
        "\n",
        "    self.dropout = torch.nn.Dropout(dropout_p)\n",
        "\n",
        "    self.F = F\n",
        "    self.device, self.dtype = device, dtype\n",
        "    self.weight_reg, self.weight_norm = weight_reg, weight_norm\n",
        "\n",
        "  def forward(self, input):\n",
        "    '''\n",
        "    Perform a forward pass through the hidden layer.\n",
        "\n",
        "    Args:\n",
        "        input (torch.Tensor): Input tensor.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Output tensor.\n",
        "\n",
        "    '''\n",
        "    y = self.dropout(self.F(input))\n",
        "    return y\n",
        "\n",
        "  def constrain(self):\n",
        "    '''\n",
        "    Constrain the weights of the hidden layer.\n",
        "\n",
        "    '''\n",
        "    for name, param in self.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            param = torch.nn.functional.normalize(param, p=self.weight_norm, dim=1).contiguous()\n",
        "\n",
        "  def penalize(self):\n",
        "    '''\n",
        "    Compute the regularization loss for the hidden layer.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Regularization loss.\n",
        "\n",
        "    '''\n",
        "    loss = 0\n",
        "    for name, param in self.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            loss += self.weight_reg[0] * torch.norm(param, p=self.weight_reg[1]) * int(param.requires_grad)\n",
        "        elif 'coef' in name:\n",
        "            loss += self.coef_reg[0] * torch.norm(param, p=self.coef_reg[1]) * int(param.requires_grad)\n",
        "\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmgvqHmkLLKf"
      },
      "outputs": [],
      "source": [
        "class ModulationLayer(torch.nn.Module):\n",
        "  '''\n",
        "  Modulation layer that applies different modulation functions to the input.\n",
        "\n",
        "  Args:\n",
        "      window_len (int): Length of the input window.\n",
        "      in_features (int): Number of input features.\n",
        "      associated (bool): Whether the modulators are associated with each other.\n",
        "      legendre_degree (int or None): Degree of the Legendre modulation function. If None, Legendre modulation is not applied.\n",
        "      chebychev_degree (int or None): Degree of the Chebychev modulation function. If None, Chebychev modulation is not applied.\n",
        "      dt (float): Time step for Fourier modulation.\n",
        "      num_freqs (int or None): Number of frequencies for Fourier modulation. If None, Fourier modulation is not applied.\n",
        "      freq_init (torch.Tensor or None): Initial frequencies for Fourier modulation. If None, frequencies are initialized uniformly.\n",
        "      freq_train (bool): Whether to train the frequencies for Fourier modulation.\n",
        "      phase_init (torch.Tensor or None): Initial phases for Fourier modulation. If None, phases are initialized as zeros.\n",
        "      phase_train (bool): Whether to train the phases for Fourier modulation.\n",
        "      num_sigmoids (int or None): Number of sigmoid functions for Sigmoid modulation. If None, Sigmoid modulation is not applied.\n",
        "      slope_init (torch.Tensor or None): Initial slopes for Sigmoid modulation. If None, slopes are initialized from a normal distribution.\n",
        "      slope_train (bool): Whether to train the slopes for Sigmoid modulation.\n",
        "      shift_init (torch.Tensor or None): Initial shifts for Sigmoid modulation. If None, shifts are initialized from a uniform distribution.\n",
        "      shift_train (bool): Whether to train the shifts for Sigmoid modulation.\n",
        "      weight_reg (list): Regularization parameters for the linear function weights. [Regularization weight, regularization exponent]\n",
        "      weight_norm (int): Norm to be used for weight regularization.\n",
        "      zero_order (bool): Whether to include the zeroth-order term (constant) in the modulation functions.\n",
        "      bias (bool): If True, adds a learnable bias to the linear function.\n",
        "      pure (bool): If True, concatenates a constant term to the input.\n",
        "      device (str): Device to use for computation ('cpu' or 'cuda').\n",
        "      dtype (torch.dtype): Data type of the model parameters.\n",
        "\n",
        "  '''\n",
        "\n",
        "  def __init__(self, window_len, in_features, associated=False, legendre_degree=None, chebychev_degree=None,\n",
        "               dt=1, num_freqs=None, freq_init=None, freq_train=True, phase_init=None, phase_train=True,\n",
        "               num_sigmoids=None, slope_init=None, slope_train=True, shift_init=None, shift_train=True,\n",
        "               weight_reg=[0.001, 1.], weight_norm=2, zero_order=True, bias=True, pure=False,\n",
        "               device='cpu', dtype=torch.float32):\n",
        "\n",
        "    super(ModulationLayer, self).__init__()\n",
        "\n",
        "    legendre_idx, chebychev_idx, hermite_idx, fourier_idx, sigmoid_idx = None, None, None, None, None\n",
        "    idx = 1\n",
        "\n",
        "    num_modulators, m = 0, 0\n",
        "\n",
        "    F = []\n",
        "\n",
        "    modulators = torch.nn.ModuleList([])\n",
        "    F_legendre, legendre_idx = None, None\n",
        "    if legendre_degree is not None:\n",
        "        m += 1\n",
        "        F_legendre = LegendreModulator(window_len=window_len, scale=True, degree=legendre_degree,\n",
        "                                       zero_order=zero_order, device=device, dtype=dtype)\n",
        "        modulators.append(F_legendre)\n",
        "        F.append(F_legendre.functions)\n",
        "        legendre_idx = [m, torch.arange(idx, idx + F_legendre.num_modulators)]\n",
        "        idx += F_legendre.num_modulators\n",
        "\n",
        "    F_chebychev, chebychev_idx = None, None\n",
        "    if chebychev_degree is not None:\n",
        "        m += 1\n",
        "        F_chebychev = ChebychevModulator(window_len=window_len, scale=True, kind=1, degree=chebychev_degree,\n",
        "                                          zero_order=zero_order * (len(F) == 0), device=device, dtype=dtype)\n",
        "        modulators.append(F_chebychev)\n",
        "        F.append(F_chebychev.functions)\n",
        "        chebychev_idx = [m, torch.arange(idx, idx + F_chebychev.num_modulators)]\n",
        "        idx += F_chebychev.num_modulators\n",
        "\n",
        "    F_fourier, fourier_idx = None, None\n",
        "    if num_freqs is not None:\n",
        "        m += 1\n",
        "        F_fourier = FourierModulator(window_len=window_len, num_freqs=num_freqs, dt=dt,\n",
        "                                      freq_init=freq_init, freq_train=freq_train,\n",
        "                                      phase_init=phase_init, phase_train=phase_train,\n",
        "                                      device=device, dtype=dtype)\n",
        "        modulators.append(F_fourier)\n",
        "        F.append(F_fourier.functions)\n",
        "        fourier_idx = [m, torch.arange(idx, idx + F_fourier.num_modulators)]\n",
        "        idx += F_fourier.num_modulators\n",
        "\n",
        "    F_sigmoid, s, bs, sigmoid_idx = None, None, None, None\n",
        "    if num_sigmoids is not None:\n",
        "        m += 1\n",
        "        F_sigmoid = SigmoidModulator(window_len=window_len, num_sigmoids=num_sigmoids,\n",
        "                                      slope_init=slope_init, slope_train=slope_train,\n",
        "                                      shift_init=shift_init, shift_train=shift_train,\n",
        "                                      device=device, dtype=dtype)\n",
        "        modulators.append(F_sigmoid)\n",
        "        F.append(F_sigmoid.functions)\n",
        "        sigmoid_idx = [m, torch.arange(idx, idx + F_sigmoid.num_modulators)]\n",
        "        idx += F_sigmoid.num_modulators\n",
        "\n",
        "    F = torch.cat(F, -1)\n",
        "\n",
        "    num_modulators = F.shape[-1]\n",
        "\n",
        "    linear_fn = HiddenLayer(in_features=in_features + int(pure),\n",
        "                            out_features=num_modulators,\n",
        "                            bias=bias,\n",
        "                            activation='identity',\n",
        "                            weight_reg=weight_reg,\n",
        "                            weight_norm=weight_norm,\n",
        "                            device=device, dtype=dtype)\n",
        "\n",
        "    self.window_len = window_len\n",
        "    self.in_features = in_features\n",
        "    self.associated = associated\n",
        "    self.weight_reg, self.weight_norm = weight_reg, weight_norm\n",
        "    self.bias = bias\n",
        "    self.modulators, self.num_modulators = modulators, num_modulators\n",
        "    self.pure = pure\n",
        "\n",
        "    self.linear_fn, self.F = linear_fn, F\n",
        "    self.legendre_idx, self.chebychev_idx, self.hermite_idx, self.fourier_idx, self.sigmoid_idx = legendre_idx, chebychev_idx, hermite_idx, fourier_idx, sigmoid_idx\n",
        "    self.dt = dt\n",
        "\n",
        "    self.device, self.dtype = device, dtype\n",
        "\n",
        "  def forward(self, input, steps):\n",
        "    '''\n",
        "    Perform a forward pass through the modulation layer.\n",
        "\n",
        "    Args:\n",
        "        input (torch.Tensor): Input tensor.\n",
        "        steps (int): Index of the modulation step.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Output tensor.\n",
        "\n",
        "    '''\n",
        "    num_samples, seq_len, input_size = input.shape\n",
        "\n",
        "    if self.pure:\n",
        "      input_ = torch.cat((torch.ones((num_samples, seq_len, 1)).to(device=self.device, dtype=self.dtype), input), -1).to(input)\n",
        "    else:\n",
        "      input_ = input\n",
        "\n",
        "    output = self.F[steps] * self.linear_fn(input_)\n",
        "\n",
        "    return output\n",
        "\n",
        "  def constrain(self):\n",
        "    '''\n",
        "    Apply constraints to the modulation parameters.\n",
        "\n",
        "    '''\n",
        "    if self.weight is not None:\n",
        "      self.weight.data = self.weight.data / self.weight.data.norm(self.weight_norm, dim=1, keepdim=True)\n",
        "      self.weight.data = self.weight.data.sum(dim=1, keepdim=True).sign() * self.weight.data\n",
        "\n",
        "    if self.fourier_idx is not None:\n",
        "      self.modulators[self.fourier_idx[0]].f = self.modulators[self.fourier_idx[0]].f.data.clamp_(0, 1 / (2 * self.dt))\n",
        "      self.modulators[self.fourier_idx[0]].p = self.modulators[self.fourier_idx[0]].p.data.clamp_(-torch.pi, torch.pi)\n",
        "\n",
        "  def penalize(self):\n",
        "    '''\n",
        "    Compute the regularization penalty.\n",
        "\n",
        "    Returns:\n",
        "      float: Regularization penalty.\n",
        "\n",
        "    '''\n",
        "    penalty = 0.\n",
        "    if self.weight is not None:\n",
        "        penalty += self.weight_reg[0] * torch.norm(self.weight, p=self.weight_reg[1]) * int(self.weight.requires_grad)\n",
        "\n",
        "    return penalty\n",
        "\n",
        "class LegendreModulator(torch.nn.Module):\n",
        "  '''\n",
        "  Legendre modulation function.\n",
        "\n",
        "  Args:\n",
        "      window_len (int): Length of the input window.\n",
        "      scale (bool): If True, scale the input to the range [0, 1].\n",
        "      degree (int): Degree of the Legendre polynomial.\n",
        "      zero_order (bool): If True, include the zeroth-order term (constant) in the modulation function.\n",
        "      device (str): Device to use for computation ('cpu' or 'cuda').\n",
        "      dtype (torch.dtype): Data type of the model parameters.\n",
        "\n",
        "  '''\n",
        "\n",
        "  def __init__(self, window_len, scale=True, degree=1, zero_order=True, device='cpu', dtype=torch.float32):\n",
        "    super(LegendreModulator, self).__init__()\n",
        "\n",
        "    self.degree = degree\n",
        "    self.zero_order = zero_order\n",
        "    self.num_modulators = degree + int(zero_order)\n",
        "\n",
        "    self.device, self.dtype = device, dtype\n",
        "\n",
        "    self.window_len = window_len\n",
        "    self.scale = scale\n",
        "    self.functions = self.generate_basis_functions()\n",
        "\n",
        "  def generate_basis_functions(self):\n",
        "    '''\n",
        "    Generate the Legendre basis functions.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Legendre basis functions.\n",
        "\n",
        "    '''\n",
        "    t = torch.arange(0, self.window_len).view(-1, 1).to(device=self.device, dtype=self.dtype)\n",
        "    t = t / (t.max() - t.min()) if self.scale else t\n",
        "\n",
        "    N = len(t)\n",
        "\n",
        "    y = torch.zeros((N, (self.degree + 1))).to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "    for q in range(0, (self.degree + 1)):\n",
        "        if q == 0:\n",
        "            y[:, 0] = torch.ones((N,)).to(device=self.device, dtype=self.dtype)\n",
        "        elif q == 1:\n",
        "            y[:, 1:2] = t * y[:, 0:1]\n",
        "        else:\n",
        "            y[:, q:(q + 1)] = ((2 * q - 1) * t * y[:, (q - 1):q] - (q - 1) * y[:, (q - 2):(q - 1)]) / q\n",
        "\n",
        "    if not self.zero_order:\n",
        "        y = y[:, 1:]\n",
        "\n",
        "    self.functions = y\n",
        "\n",
        "    return y\n",
        "\n",
        "  def forward(self, X, steps):\n",
        "    '''\n",
        "    Apply the Legendre modulation to the input.\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): Input tensor.\n",
        "        steps (int): Index of the modulation step.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Modulated tensor.\n",
        "\n",
        "    '''\n",
        "    X = X.to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "    y = X[:, :, None, :] * self.functions[steps]\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "class ChebychevModulator(torch.nn.Module):\n",
        "  '''\n",
        "  Chebychev modulation function.\n",
        "\n",
        "  Args:\n",
        "      window_len (int): Length of the input window.\n",
        "      scale (bool): If True, scale the input to the range [0, 1].\n",
        "      kind (int): Kind of Chebychev polynomial to use. Must be 1 or 2.\n",
        "      degree (int): Degree of the Chebychev polynomial.\n",
        "      zero_order (bool): If True, include the zeroth-order term (constant) in the modulation function.\n",
        "      device (str): Device to use for computation ('cpu' or 'cuda').\n",
        "      dtype (torch.dtype): Data type of the model parameters.\n",
        "\n",
        "  '''\n",
        "\n",
        "  def __init__(self, window_len, scale=True, kind=1, degree=1, zero_order=True, device='cpu', dtype=torch.float32):\n",
        "    super(ChebychevModulator, self).__init__()\n",
        "\n",
        "    self.degree = degree\n",
        "    self.zero_order = zero_order\n",
        "    self.num_modulators = degree + int(zero_order)\n",
        "\n",
        "    self.device, self.dtype = device, dtype\n",
        "\n",
        "    self.window_len = window_len\n",
        "    self.scale = scale\n",
        "    self.kind = kind\n",
        "    self.functions = self.generate_basis_functions()\n",
        "\n",
        "  def generate_basis_functions(self):\n",
        "    '''\n",
        "    Generate the Chebychev basis functions.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Chebychev basis functions.\n",
        "\n",
        "    '''\n",
        "    t = torch.arange(0, self.window_len).view(-1, 1).to(device=self.device, dtype=self.dtype)\n",
        "    t = t / (t.max() - t.min()) if self.scale else t\n",
        "\n",
        "    N = len(t)\n",
        "\n",
        "    y = torch.zeros((N, (self.degree + 1))).to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "    for q in range(0, (self.degree + 1)):\n",
        "        if q == 0:\n",
        "            y[:, 0] = torch.ones((N,)).to(device=self.device, dtype=self.dtype)\n",
        "        elif q == 1:\n",
        "            y[:, 1:2] = self.kind * t * y[:, 0:1]\n",
        "        else:\n",
        "            y[:, q:(q + 1)] = 2 * t * y[:, (q - 1):q] - y[:, (q - 2):(q - 1)]\n",
        "\n",
        "    if not self.zero_order:\n",
        "        y = y[:, 1:]\n",
        "\n",
        "    self.functions = y\n",
        "\n",
        "    return y\n",
        "\n",
        "  def forward(self, X, steps):\n",
        "    '''\n",
        "    Apply the Chebychev modulation to the input.\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): Input tensor.\n",
        "        steps (int): Index of the modulation step.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Modulated tensor.\n",
        "\n",
        "    '''\n",
        "    X = X.to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "    y = X[:, :, None, :] * self.functions[steps]\n",
        "\n",
        "    return y\n",
        "\n",
        "class FourierModulator(torch.nn.Module):\n",
        "  '''\n",
        "  Fourier modulation function.\n",
        "\n",
        "  Args:\n",
        "    window_len (int): Length of the input window.\n",
        "    num_freqs (int): Number of frequencies.\n",
        "    dt (float): Time step.\n",
        "    freq_init (torch.Tensor or None): Initial frequencies. If None, frequencies are initialized uniformly.\n",
        "    freq_train (bool): Whether to train the frequencies.\n",
        "    phase_init (torch.Tensor or None): Initial phases. If None, phases are initialized as zeros.\n",
        "    phase_train (bool): Whether to train the phases.\n",
        "    device (str): Device to use for computation ('cpu' or 'cuda').\n",
        "    dtype (torch.dtype): Data type of the model parameters.\n",
        "\n",
        "  '''\n",
        "\n",
        "  def __init__(self,\n",
        "               window_len, num_freqs, dt=1, freq_init=None, freq_train=True, phase_init=None,\n",
        "               phase_train=True, device='cpu', dtype=torch.float32):\n",
        "    super(FourierModulator, self).__init__()\n",
        "\n",
        "    if freq_init is None:\n",
        "        freq_init = ((1 / dt) / 4) * torch.ones(size=(1, num_freqs))\n",
        "    else:\n",
        "        freq_init = freq_init\n",
        "\n",
        "    if phase_init is None:\n",
        "        phase_init = torch.zeros(size=(1, num_freqs))\n",
        "    else:\n",
        "        phase_init = phase_init\n",
        "\n",
        "    freq = torch.nn.Parameter(data=freq_init.to(device=device, dtype=dtype), requires_grad=freq_train)\n",
        "    phase = torch.nn.Parameter(data=phase_init.to(device=device, dtype=dtype), requires_grad=phase_train)\n",
        "\n",
        "    self.dt = dt\n",
        "    self.window_len = window_len\n",
        "    self.freq, self.phase = freq, phase\n",
        "    self.num_modulators = num_freqs\n",
        "    self.device, self.dtype = device, dtype\n",
        "\n",
        "    self.generate_basis_functions()\n",
        "\n",
        "  def generate_basis_functions(self):\n",
        "    '''\n",
        "    Generate the Fourier basis functions.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Fourier basis functions.\n",
        "\n",
        "    '''\n",
        "    t = self.dt * torch.arange(0, self.window_len).view(-1, 1).to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "    y = torch.sin(2 * torch.pi * t * self.freq + self.phase)\n",
        "\n",
        "    self.functions = y\n",
        "\n",
        "    return y\n",
        "\n",
        "  def forward(self, X, steps):\n",
        "    '''\n",
        "    Apply the Fourier modulation to the input.\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): Input tensor.\n",
        "        steps (int): Index of the modulation step.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Modulated tensor.\n",
        "\n",
        "    '''\n",
        "    X = X.to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "    self.functions = self.generate_basis_functions()\n",
        "\n",
        "    y = X[:, :, None, :] * self.functions[steps]\n",
        "\n",
        "    self.functions = y\n",
        "\n",
        "    return y\n",
        "\n",
        "class SigmoidModulator(torch.nn.Module):\n",
        "  '''\n",
        "  Sigmoid modulation function.\n",
        "\n",
        "  Args:\n",
        "      window_len (int): Length of the input window.\n",
        "      num_sigmoids (int): Number of sigmoid functions.\n",
        "      scale (bool): If True, scale the input to the range [0, 1].\n",
        "      slope_init (torch.Tensor or None): Initial slopes. If None, slopes are initialized from a normal distribution.\n",
        "      slope_train (bool): Whether to train the slopes.\n",
        "      shift_init (torch.Tensor or None): Initial shifts. If None, shifts are initialized from a uniform distribution.\n",
        "      shift_train (bool): Whether to train the shifts.\n",
        "      device (str): Device to use for computation ('cpu' or 'cuda').\n",
        "      dtype (torch.dtype): Data type of the model parameters.\n",
        "\n",
        "  '''\n",
        "\n",
        "  def __init__(self, window_len, num_sigmoids, scale=True, slope_init=None, slope_train=True,\n",
        "                shift_init=None, shift_train=True, device='cpu', dtype=torch.float32):\n",
        "    super(SigmoidModulator, self).__init__()\n",
        "\n",
        "    if slope_init is None:\n",
        "        slope_init = torch.nn.init.normal_(torch.empty((1, num_sigmoids)), mean=0, std=1 / window_len)\n",
        "    slope = torch.nn.Parameter(data=slope_init.to(device=device, dtype=dtype), requires_grad=slope_train)\n",
        "\n",
        "    if shift_init is None:\n",
        "        shift_init = torch.nn.init.uniform_(torch.empty((1, num_sigmoids)), a=-1, b=1)\n",
        "    shift = torch.nn.Parameter(data=shift_init.to(device=device, dtype=dtype), requires_grad=shift_train)\n",
        "\n",
        "    self.window_len = window_len\n",
        "    self.num_modulators = num_sigmoids\n",
        "    self.scale = scale\n",
        "    self.slope, self.shift = slope, shift\n",
        "    self.device, self.dtype = device, dtype\n",
        "\n",
        "    self.functions = self.generate_basis_functions()\n",
        "\n",
        "  def generate_basis_functions(self):\n",
        "    '''\n",
        "    Generate the sigmoid basis functions.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Sigmoid basis functions.\n",
        "\n",
        "    '''\n",
        "    t = torch.arange(0, self.window_len).view(-1, 1).to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "    scaler = (t.max() - t.min()) if self.scale else 1\n",
        "\n",
        "    y = 1 / (1 + torch.exp(-self.slope * (t - self.shift * scaler)))\n",
        "\n",
        "    self.functions = y\n",
        "\n",
        "    return y\n",
        "\n",
        "  def forward(self, X, steps):\n",
        "    '''\n",
        "    Apply the sigmoid modulation to the input.\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): Input tensor.\n",
        "        steps (int): Index of the modulation step.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Modulated tensor.\n",
        "\n",
        "    '''\n",
        "    X = X.to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "    self.functions = self.generate_basis_functions()\n",
        "\n",
        "    print(X.shape)\n",
        "    print(self.functions[steps].shape)\n",
        "\n",
        "    y = X[:, :, None, :] * self.functions[steps]\n",
        "\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJijezBGBqww"
      },
      "outputs": [],
      "source": [
        "class Attention(torch.nn.MultiheadAttention):\n",
        "  '''\n",
        "  Custom attention layer based on the torch.nn.MultiheadAttention module.\n",
        "  This layer supports different types of attention mechanisms: dot, general, and concat.\n",
        "\n",
        "  Args:\n",
        "      embed_dim (int): The input embedding dimension.\n",
        "      num_heads (int): The number of attention heads.\n",
        "      query_dim (int, optional): The query embedding dimension. Defaults to None (same as embed_dim).\n",
        "      key_dim (int, optional): The key embedding dimension. Defaults to None (same as embed_dim).\n",
        "      value_dim (int, optional): The value embedding dimension. Defaults to None (same as embed_dim).\n",
        "      attn_type (str, optional): The attention type. Options: 'dot', 'general', 'concat'. Defaults to 'dot'.\n",
        "      query_weight_reg (List[float], optional): The regularization weights for the query projection layer. Defaults to [0.001, 1].\n",
        "      query_weight_norm (float, optional): The normalization type for the query projection layer. Defaults to 2.\n",
        "      query_bias (bool, optional): Whether to include bias in the query projection layer. Defaults to False.\n",
        "      key_weight_reg (List[float], optional): The regularization weights for the key projection layer. Defaults to [0.001, 1].\n",
        "      key_weight_norm (float, optional): The normalization type for the key projection layer. Defaults to 2.\n",
        "      key_bias (bool, optional): Whether to include bias in the key projection layer. Defaults to False.\n",
        "      value_weight_reg (List[float], optional): The regularization weights for the value projection layer. Defaults to [0.001, 1].\n",
        "      value_weight_norm (float, optional): The normalization type for the value projection layer. Defaults to 2.\n",
        "      value_bias (bool, optional): Whether to include bias in the value projection layer. Defaults to False.\n",
        "      gen_weight_reg (List[float], optional): The regularization weights for the generation weights (concat type). Defaults to [0.001, 1].\n",
        "      gen_weight_norm (float, optional): The normalization type for the generation weights (concat type). Defaults to 2.\n",
        "      gen_bias (bool, optional): Whether to include bias in the generation weights (concat type). Defaults to False.\n",
        "      concat_weight_reg (List[float], optional): The regularization weights for the concatenation layer (concat type). Defaults to [0.001, 1].\n",
        "      concat_weight_norm (float, optional): The normalization type for the concatenation layer (concat type). Defaults to 2.\n",
        "      concat_bias (bool, optional): Whether to include bias in the concatenation layer (concat type). Defaults to False.\n",
        "      average_attn_weights (bool, optional): Whether to average the attention weights across heads. Defaults to False.\n",
        "      is_causal (bool, optional): Whether the attention is causal (supports autoregressive property). Defaults to False.\n",
        "      dropout_p (float, optional): The dropout probability. Defaults to 0.0.\n",
        "      device (str, optional): The device for the computation. Defaults to 'cpu'.\n",
        "      dtype (torch.dtype, optional): The data type. Defaults to torch.float32.\n",
        "  '''\n",
        "\n",
        "  def __init__(self,\n",
        "               embed_dim, num_heads=1,\n",
        "               query_dim=None, key_dim=None, value_dim=None,\n",
        "               attn_type=\"dot\",\n",
        "               query_weight_reg=[0.001, 1], query_weight_norm=2, query_bias=False,\n",
        "               key_weight_reg=[0.001, 1], key_weight_norm=2, key_bias=False,\n",
        "               value_weight_reg=[0.001, 1], value_weight_norm=2, value_bias=False,\n",
        "               gen_weight_reg=[0.001, 1], gen_weight_norm=2, gen_bias=False,\n",
        "               concat_weight_reg=[0.001, 1], concat_weight_norm=2, concat_bias=False,\n",
        "               average_attn_weights=False,\n",
        "               is_causal=False,\n",
        "               dropout_p=0.0,\n",
        "               device=\"cpu\",\n",
        "               dtype=torch.float32):\n",
        "\n",
        "      super(Attention, self).__init__(embed_dim=embed_dim, num_heads=num_heads)\n",
        "\n",
        "      # Choose the appropriate score function based on the attention type\n",
        "      if attn_type == \"dot\":\n",
        "          self.score_fn = self.dot_fn\n",
        "      elif attn_type == \"general\":\n",
        "          self.score_fn = self.general_fn\n",
        "      elif attn_type == \"concat\":\n",
        "          self.score_fn = self.concat_fn\n",
        "\n",
        "      query_dim = query_dim or embed_dim\n",
        "      key_dim = key_dim or embed_dim\n",
        "      value_dim = value_dim or embed_dim\n",
        "\n",
        "      query_blocks = torch.nn.ModuleList([])\n",
        "      key_blocks = torch.nn.ModuleList([])\n",
        "      value_blocks = torch.nn.ModuleList([])\n",
        "      gen_blocks = torch.nn.ModuleList([])\n",
        "      concat_blocks = torch.nn.ModuleList([])\n",
        "\n",
        "      head_dims = np.round(embed_dim / num_heads).astype(int).repeat(num_heads - 1).tolist()\n",
        "      head_dims += [int(embed_dim - np.sum(head_dims))]\n",
        "\n",
        "      for dim in head_dims:\n",
        "        query_blocks.append(HiddenLayer(in_features=embed_dim,\n",
        "                                        out_features=dim,\n",
        "                                        bias=query_bias,\n",
        "                                        activation=\"identity\",\n",
        "                                        weight_reg=query_weight_reg,\n",
        "                                        weight_norm=query_weight_norm,\n",
        "                                        device=device,\n",
        "                                        dtype=dtype))\n",
        "        key_blocks.append(HiddenLayer(in_features=embed_dim,\n",
        "                                      out_features=dim,\n",
        "                                      bias=key_bias,\n",
        "                                      activation=\"identity\",\n",
        "                                      weight_reg=key_weight_reg,\n",
        "                                      weight_norm=key_weight_norm,\n",
        "                                      device=device,\n",
        "                                      dtype=dtype))\n",
        "        value_blocks.append(HiddenLayer(in_features=embed_dim,\n",
        "                                        out_features=dim,\n",
        "                                        bias=value_bias,\n",
        "                                        activation=\"identity\",\n",
        "                                        weight_reg=value_weight_reg,\n",
        "                                        weight_norm=value_weight_norm,\n",
        "                                        device=device,\n",
        "                                        dtype=dtype))\n",
        "\n",
        "        if attn_type == \"general\":\n",
        "          gen_blocks.append(\n",
        "              HiddenLayer(in_features=[dim, dim],\n",
        "                          out_features=1,\n",
        "                          bias=gen_bias,\n",
        "                          activation=\"identity\",\n",
        "                          weight_reg=gen_weight_reg,\n",
        "                          weight_norm=gen_weight_norm,\n",
        "                          device=device,\n",
        "                          dtype=dtype))\n",
        "\n",
        "        if attn_type == \"concat\":\n",
        "          concat_blocks.append(torch.nn.Sequential(*[HiddenLayer(in_features=2 * dim,\n",
        "                                                                  out_features=dim,\n",
        "                                                                  bias=concat_bias,\n",
        "                                                                  activation=\"tanh\",\n",
        "                                                                  weight_reg=concat_weight_reg,\n",
        "                                                                  weight_norm=concat_weight_norm,\n",
        "                                                                  device=device,\n",
        "                                                                  dtype=dtype),\n",
        "                                                      HiddenLayer(in_features=dim,\n",
        "                                                                  out_features=1,\n",
        "                                                                  bias=concat_bias,\n",
        "                                                                  activation=\"identity\",\n",
        "                                                                  weight_reg=concat_weight_reg,\n",
        "                                                                  weight_norm=concat_weight_norm,\n",
        "                                                                  device=device,\n",
        "                                                                  dtype=dtype)]))\n",
        "\n",
        "      self.embed_dim = embed_dim\n",
        "      self.num_heads = num_heads\n",
        "      self.attn_type = attn_type\n",
        "      self.is_causal = is_causal\n",
        "\n",
        "      self.query_blocks = query_blocks\n",
        "      self.key_blocks = key_blocks\n",
        "      self.value_blocks = value_blocks\n",
        "\n",
        "      self.dropout = torch.nn.Dropout(dropout_p)\n",
        "\n",
        "      self.query_weight_reg = query_weight_reg\n",
        "      self.weight_norm = query_weight_norm\n",
        "      self.key_weight_reg = key_weight_reg\n",
        "      self.key_norm = key_weight_norm\n",
        "      self.value_weight_reg = value_weight_reg\n",
        "      self.value_norm = value_weight_norm\n",
        "\n",
        "      self.gen_blocks = gen_blocks\n",
        "      self.concat_blocks = concat_blocks\n",
        "\n",
        "      self.gen_weight_reg = gen_weight_reg\n",
        "      self.gen_norm = gen_weight_norm\n",
        "      self.concat_weight_reg = concat_weight_reg\n",
        "      self.concat_norm = concat_weight_norm\n",
        "\n",
        "      self.average_attn_weights = average_attn_weights\n",
        "\n",
        "      self.device = device\n",
        "      self.dtype = dtype\n",
        "\n",
        "  def dot_fn(self, query, key, block_idx):\n",
        "    '''\n",
        "    Compute the dot-product attention score between query and key.\n",
        "\n",
        "    Args:\n",
        "        query (torch.Tensor): The query tensor of shape (num_samples, query_len, query_dim).\n",
        "        key (torch.Tensor): The key tensor of shape (num_samples, key_len, key_dim).\n",
        "        block_idx (int): The index of the attention block.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The attention score tensor of shape (num_samples, query_len, key_len).\n",
        "    '''\n",
        "    score = (torch.bmm(query, key.transpose(-2, -1)) / torch.math.sqrt(query.shape[-1])).transpose(-1, -2)\n",
        "    return score\n",
        "\n",
        "  def general_fn(self, query, key, block_idx):\n",
        "    '''\n",
        "    Compute the general attention score between query and key.\n",
        "\n",
        "    Args:\n",
        "        query (torch.Tensor): The query tensor of shape (num_samples, query_len, query_dim).\n",
        "        key (torch.Tensor): The key tensor of shape (num_samples, key_len, key_dim).\n",
        "        block_idx (int): The index of the attention block.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The attention score tensor of shape (num_samples, query_len, key_len).\n",
        "    '''\n",
        "    if query.shape[1] == 1:\n",
        "        query = query.repeat(1, key.shape[1], 1)\n",
        "\n",
        "    score = self.gen_blocks[block_idx]((query, key))\n",
        "\n",
        "    return score\n",
        "\n",
        "  def concat_fn(self, query, key, block_idx):\n",
        "    '''\n",
        "    Compute the concat attention score between query and key.\n",
        "\n",
        "    Args:\n",
        "        query (torch.Tensor): The query tensor of shape (num_samples, query_len, query_dim).\n",
        "        key (torch.Tensor): The key tensor of shape (num_samples, key_len, key_dim).\n",
        "        block_idx (int): The index of the attention block.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The attention score tensor of shape (num_samples, query_len, key_len).\n",
        "    '''\n",
        "    if query.shape[1] == 1:\n",
        "        query = query.repeat(1, key.shape[1], 1)\n",
        "\n",
        "    score = self.concat_blocks[block_idx](torch.cat((query, key), -1))\n",
        "    return score\n",
        "\n",
        "  def forward(self, query, key, value, attn_mask=None):\n",
        "    '''\n",
        "    Perform the forward pass of the attention layer.\n",
        "\n",
        "    Args:\n",
        "        query (torch.Tensor): The query tensor of shape (num_samples, query_len, query_dim).\n",
        "        key (torch.Tensor): The key tensor of shape (num_samples, key_len, key_dim).\n",
        "        value (torch.Tensor): The value tensor of shape (num_samples, value_len, value_dim).\n",
        "        attn_mask (torch.Tensor, optional): The attention mask tensor of shape (query_len, key_len)\n",
        "            or (num_samples, num_heads, query_len, key_len). Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The output tensor of shape (num_samples, query_len, value_dim).\n",
        "    '''\n",
        "    num_samples, query_len, query_dim = query.shape\n",
        "    _, key_len, key_dim = key.shape\n",
        "    _, value_len, value_dim = value.shape\n",
        "\n",
        "    ones = torch.ones((query_len, key_len), device=self.device, dtype=torch.bool)\n",
        "\n",
        "    attn_mask = ones.tril(diagonal=0).transpose(-2, -1) if self.is_causal else ones\n",
        "    attn_mask = attn_mask.to(query).masked_fill(~attn_mask, -float('inf')) if attn_mask.dtype == torch.bool else attn_mask\n",
        "\n",
        "    output, weight = [], []\n",
        "    for block_idx, (query_block, key_block, value_block) in enumerate(zip(self.query_blocks, self.key_blocks, self.value_blocks)):\n",
        "\n",
        "      query_h, key_h, value_h = query_block(query), key_block(key), value_block(value)\n",
        "\n",
        "      score_h = self.score_fn(query_h, key_h, block_idx)\n",
        "\n",
        "      weight_h = torch.softmax(score_h + attn_mask, dim=1)\n",
        "\n",
        "      output_h = torch.bmm(weight_h.transpose(-2, -1), value_h)\n",
        "\n",
        "      weight.append(weight_h)\n",
        "      output.append(output_h)\n",
        "\n",
        "    output = self.dropout(torch.cat(output, -1))\n",
        "    weight = torch.cat(weight, 1)\n",
        "\n",
        "    if self.average_attn_weights:\n",
        "      weight = weight.mean(1)\n",
        "\n",
        "    self.weight = weight\n",
        "\n",
        "    return output\n",
        "\n",
        "  def penalize(self):\n",
        "    '''\n",
        "    Compute the regularization loss for the attention layer.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The regularization loss.\n",
        "    '''\n",
        "    loss = 0\n",
        "    for name, param in self.named_parameters():\n",
        "      if 'weight' in name:\n",
        "        if 'query' in name:\n",
        "          loss += self.query_weight_reg[0] * torch.norm(param, p=self.query_weight_reg[1]) * int(param.requires_grad)\n",
        "        elif 'key' in name:\n",
        "          loss += self.key_weight_reg[0] * torch.norm(param, p=self.key_weight_reg[1]) * int(param.requires_grad)\n",
        "        elif 'value' in name:\n",
        "          loss += self.value_weight_reg[0] * torch.norm(param, p=self.value_weight_reg[1]) * int(param.requires_grad)\n",
        "        elif 'gen' in name:\n",
        "          loss += self.gen_weight_reg[0] * torch.norm(param, p=self.gen_weight_reg[1]) * int(param.requires_grad)\n",
        "        elif 'concat' in name:\n",
        "          loss += self.concat_weight_reg[0] * torch.norm(param, p=self.concat_weight_reg[1]) * int(param.requires_grad)\n",
        "\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk6WkUFL_GjC"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderLayer(torch.nn.TransformerEncoderLayer):\n",
        "    '''\n",
        "    Customized Transformer Encoder Layer with optional modifications.\n",
        "\n",
        "    Args:\n",
        "      d_model (int): The input and output feature dimension.\n",
        "      nhead (int, optional): The number of attention heads. Defaults to 1.\n",
        "      dim_feedforward (int, optional): The hidden dimension of the feedforward network. Defaults to 2048.\n",
        "      self_attn_type (str, optional): The type of self-attention. Choices: 'dot', 'general', 'concat'. Defaults to 'dot'.\n",
        "      is_causal (bool, optional): Whether to use causal self-attention. Defaults to False.\n",
        "      query_weight_reg (list[float], optional): Regularization weights for the query weights. Defaults to [0.001, 1].\n",
        "      query_weight_norm (int, optional): Norm type for the query weights. Defaults to 2.\n",
        "      query_bias (bool, optional): Whether to use bias in the query weights. Defaults to False.\n",
        "      key_weight_reg (list[float], optional): Regularization weights for the key weights. Defaults to [0.001, 1].\n",
        "      key_weight_norm (int, optional): Norm type for the key weights. Defaults to 2.\n",
        "      key_bias (bool, optional): Whether to use bias in the key weights. Defaults to False.\n",
        "      value_weight_reg (list[float], optional): Regularization weights for the value weights. Defaults to [0.001, 1].\n",
        "      value_weight_norm (int, optional): Norm type for the value weights. Defaults to 2.\n",
        "      value_bias (bool, optional): Whether to use bias in the value weights. Defaults to False.\n",
        "      gen_weight_reg (list[float], optional): Regularization weights for the generator weights. Defaults to [0.001, 1].\n",
        "      gen_weight_norm (int, optional): Norm type for the generator weights. Defaults to 2.\n",
        "      gen_bias (bool, optional): Whether to use bias in the generator weights. Defaults to False.\n",
        "      concat_weight_reg (list[float], optional): Regularization weights for the concatenator weights. Defaults to [0.001, 1].\n",
        "      concat_weight_norm (int, optional): Norm type for the concatenator weights. Defaults to 2.\n",
        "      concat_bias (bool, optional): Whether to use bias in the concatenator weights. Defaults to False.\n",
        "      average_attn_weights (bool, optional): Whether to average the attention weights. Defaults to False.\n",
        "      dropout_p (float, optional): Dropout probability for the attention and feedforward layers. Defaults to 0.0.\n",
        "      dropout1_p (float, optional): Dropout probability for the first dropout layer in the feedforward network. Defaults to 0.0.\n",
        "      dropout2_p (float, optional): Dropout probability for the second dropout layer in the feedforward network. Defaults to 0.0.\n",
        "      linear1_bias (bool, optional): Whether to use bias in the first linear layer of the feedforward network. Defaults to False.\n",
        "      linear2_bias (bool, optional): Whether to use bias in the second linear layer of the feedforward network. Defaults to False.\n",
        "      linear1_weight_reg (list[float], optional): Regularization weights for the first linear layer weights. Defaults to [0.001, 1].\n",
        "      linear1_weight_norm (int, optional): Norm type for the first linear layer weights. Defaults to 2.\n",
        "      linear2_weight_reg (list[float], optional): Regularization weights for the second linear layer weights. Defaults to [0.001, 1].\n",
        "      linear2_weight_norm (int, optional): Norm type for the second linear layer weights. Defaults to 2.\n",
        "      feedforward_activation (str, optional): The activation function in the feedforward network. Choices: 'identity', 'relu', 'gelu', 'polynomial'. Defaults to 'relu'.\n",
        "      degree (int, optional): The degree of the polynomial activation function. Only applicable when feedforward_activation='polynomial'. Defaults to 2.\n",
        "      coef_init (torch.Tensor, optional): The initial coefficients for the polynomial activation function. Only applicable when feedforward_activation='polynomial'. Defaults to None.\n",
        "      coef_train (bool, optional): Whether to train the coefficients for the polynomial activation function. Only applicable when feedforward_activation='polynomial'. Defaults to True.\n",
        "      coef_reg (list[float], optional): Regularization weights for the polynomial coefficients. Only applicable when feedforward_activation='polynomial'. Defaults to [0.001, 1.].\n",
        "      zero_order (bool, optional): Whether to include the zero-order term in the polynomial activation function. Only applicable when feedforward_activation='polynomial'. Defaults to False.\n",
        "      scale_self_attn_residual_connection (bool, optional): Whether to scale the self-attention residual connection. Defaults to False.\n",
        "      scale_feedforward_residual_connection (bool, optional): Whether to scale the feedforward residual connection. Defaults to False.\n",
        "      device (str, optional): The device to run the layer on. Defaults to 'cpu'.\n",
        "      dtype (torch.dtype, optional): The data type. Defaults to torch.float32.\n",
        "    '''\n",
        "\n",
        "    def __init__(self,\n",
        "                d_model, nhead=1, dim_feedforward=2048,\n",
        "                self_attn_type='dot',\n",
        "                is_causal=False,\n",
        "                query_weight_reg=[0.001, 1], query_weight_norm=2, query_bias=False,\n",
        "                key_weight_reg=[0.001, 1], key_weight_norm=2, key_bias=False,\n",
        "                value_weight_reg=[0.001, 1], value_weight_norm=2, value_bias=False,\n",
        "                gen_weight_reg=[0.001, 1], gen_weight_norm=2, gen_bias=False,\n",
        "                concat_weight_reg=[0.001, 1], concat_weight_norm=2, concat_bias=False,\n",
        "                average_attn_weights=False,\n",
        "                dropout_p=0.0, dropout1_p=0.0, dropout2_p=0.0,\n",
        "                linear1_bias=False, linear2_bias=False,\n",
        "                linear1_weight_reg=[0.001, 1], linear1_weight_norm=2,\n",
        "                linear2_weight_reg=[0.001, 1], linear2_weight_norm=2,\n",
        "                feedforward_activation='relu',\n",
        "                degree=2,\n",
        "                coef_init=None, coef_train=True, coef_reg=[0.001, 1.],\n",
        "                zero_order=False,\n",
        "                scale_self_attn_residual_connection=False,\n",
        "                scale_feedforward_residual_connection=False,\n",
        "                device='cpu', dtype=torch.float32):\n",
        "\n",
        "        super(TransformerEncoderLayer, self).__init__(d_model=d_model,\n",
        "                                                      nhead=nhead,\n",
        "                                                      dim_feedforward=dim_feedforward,\n",
        "                                                      device=device,\n",
        "                                                      dtype=dtype)\n",
        "\n",
        "        self.dropout.p = dropout_p\n",
        "\n",
        "        self.self_attn = Attention(embed_dim=d_model,\n",
        "                                  num_heads=nhead,\n",
        "                                  attn_type=self_attn_type,\n",
        "                                  query_weight_reg=query_weight_reg,\n",
        "                                  query_weight_norm=query_weight_norm,\n",
        "                                  query_bias=query_bias,\n",
        "                                  key_weight_reg=key_weight_reg,\n",
        "                                  key_weight_norm=key_weight_norm,\n",
        "                                  key_bias=key_bias,\n",
        "                                  value_weight_reg=value_weight_reg,\n",
        "                                  value_weight_norm=value_weight_norm,\n",
        "                                  value_bias=value_bias,\n",
        "                                  gen_weight_reg=gen_weight_reg,\n",
        "                                  gen_weight_norm=gen_weight_norm,\n",
        "                                  gen_bias=gen_bias,\n",
        "                                  concat_weight_reg=concat_weight_reg,\n",
        "                                  concat_weight_norm=concat_weight_norm,\n",
        "                                  concat_bias=concat_bias,\n",
        "                                  average_attn_weights=average_attn_weights,\n",
        "                                  is_causal=is_causal,\n",
        "                                  dropout_p=dropout_p,\n",
        "                                  device=device,\n",
        "                                  dtype=dtype)\n",
        "\n",
        "        self.dropout1.p = dropout1_p\n",
        "        self.dropout2.p = dropout2_p\n",
        "\n",
        "        if feedforward_activation == 'identity':\n",
        "          self.activation = torch.nn.Identity()\n",
        "          self.linear2 = torch.nn.Identity()\n",
        "          self.norm2 = torch.nn.Identity()\n",
        "          self.dropout2 = torch.nn.Identity()\n",
        "        elif feedforward_activation == 'relu':\n",
        "          self.activation = torch.nn.ReLU()\n",
        "        elif feedforward_activation == 'gelu':\n",
        "          self.activation = torch.nn.GELU()\n",
        "        elif feedforward_activation == 'polynomial':\n",
        "          self.activation = Polynomial(in_features=dim_feedforward,\n",
        "                                        degree=degree,\n",
        "                                        coef_init=coef_init,\n",
        "                                        coef_train=coef_train,\n",
        "                                        coef_reg=coef_reg,\n",
        "                                        zero_order=zero_order,\n",
        "                                        device=device,\n",
        "                                        dtype=dtype)\n",
        "\n",
        "        if not linear1_bias:\n",
        "          self.linear1.bias = None\n",
        "\n",
        "        self.linear1_weight_reg = linear1_weight_reg\n",
        "        self.linear1_weight_norm = linear1_weight_norm\n",
        "\n",
        "        if not isinstance(self.linear2, torch.nn.Identity):\n",
        "          if not linear2_bias:\n",
        "            self.linear2.bias = None\n",
        "          self.linear2_weight_reg = linear2_weight_reg\n",
        "          self.linear2_weight_norm = linear2_weight_norm\n",
        "\n",
        "        if scale_self_attn_residual_connection:\n",
        "            self.self_attn_residual_scaler = torch.nn.Linear(in_features=d_model, out_features=1).weight.squeeze().to(device=device, dtype=dtype)\n",
        "        else:\n",
        "            self.self_attn_residual_scaler = torch.ones((d_model,)).to(device=device, dtype=dtype)\n",
        "\n",
        "        if scale_feedforward_residual_connection:\n",
        "            self.feedforward_residual_scaler = torch.nn.Linear(in_features=d_model, out_features=1).weight.squeeze().to(device=device, dtype=dtype)\n",
        "        else:\n",
        "            self.feedforward_residual_scaler = torch.ones((d_model,)).to(device=device, dtype=dtype)\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None, is_causal=False):\n",
        "      '''\n",
        "      Forward pass of the transformer encoder layer.\n",
        "\n",
        "      Args:\n",
        "          src (torch.Tensor): The input sequence of shape (seq_len, batch_size, d_model).\n",
        "          src_mask (torch.Tensor, optional): The mask to apply to the source sequence. Defaults to None.\n",
        "          src_key_padding_mask (torch.Tensor, optional): The padding mask for the source sequence. Defaults to None.\n",
        "          is_causal (bool, optional): Whether to use causal self-attention. Defaults to False.\n",
        "\n",
        "      Returns:\n",
        "          torch.Tensor: The output sequence of shape (seq_len, batch_size, d_model).\n",
        "      '''\n",
        "\n",
        "      # Generate self-attn output (dropout applied inside) and add residual connection (scale if desired)\n",
        "      src = self.self_attn(src, src, src, src_mask) + self.self_attn_residual_scaler * src\n",
        "\n",
        "      # Normalize self-attn sub-layer\n",
        "      src = self.norm1(src)\n",
        "\n",
        "      # Generate ff output and add residual connection (scale if desired)\n",
        "      src = self.dropout2(self.linear2(self.dropout1(self.activation(self.linear1(src))))) + self.feedforward_residual_scaler * src\n",
        "\n",
        "      src = self.norm2(src)\n",
        "\n",
        "      return src\n",
        "\n",
        "    def penalize(self):\n",
        "      '''\n",
        "      Calculate the regularization loss for the transformer encoder layer.\n",
        "\n",
        "      Returns:\n",
        "          torch.Tensor: The regularization loss.\n",
        "      '''\n",
        "      loss = 0\n",
        "      if self.self_attn is not None:\n",
        "        loss += self.self_attn.penalize()\n",
        "      loss += (self.linear1_weight_reg[0]\n",
        "               * torch.norm(self.linear1.weight, p=self.linear1_weight_reg[1])\n",
        "               * int(self.linear1.weight.requires_grad))\n",
        "      loss += (self.linear2_weight_reg[0]\n",
        "               * torch.norm(self.linear2.weight, p=self.linear2_weight_reg[1])\n",
        "               * int(self.linear2.weight.requires_grad))\n",
        "\n",
        "      return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyZBxhAVPTGL"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoderLayer(torch.nn.TransformerDecoderLayer):\n",
        "  '''\n",
        "  Transformer Decoder Layer module that extends `torch.nn.TransformerDecoderLayer`.\n",
        "\n",
        "  Args:\n",
        "    d_model (int): The number of expected features in the input.\n",
        "    nhead (int, optional): The number of heads in the multihead attention models. Defaults to 1.\n",
        "    dim_feedforward (int, optional): The dimension of the feedforward network model. Defaults to 2048.\n",
        "    self_attn_type (str, optional): The self-attention type. Defaults to 'dot'.\n",
        "    multihead_attn_type (str, optional): The multihead attention type. Defaults to 'dot'.\n",
        "    memory_is_causal (bool, optional): Whether the memory sequence is causal. Defaults to False.\n",
        "    tgt_is_causal (bool, optional): Whether the target sequence is causal. Defaults to True.\n",
        "    query_weight_reg (list, optional): Regularization parameters for query weight. Defaults to [0.001, 1].\n",
        "    query_weight_norm (int, optional): Norm type for query weight regularization. Defaults to 2.\n",
        "    query_bias (bool, optional): Whether to include bias in query weight. Defaults to False.\n",
        "    key_weight_reg (list, optional): Regularization parameters for key weight. Defaults to [0.001, 1].\n",
        "    key_weight_norm (int, optional): Norm type for key weight regularization. Defaults to 2.\n",
        "    key_bias (bool, optional): Whether to include bias in key weight. Defaults to False.\n",
        "    value_weight_reg (list, optional): Regularization parameters for value weight. Defaults to [0.001, 1].\n",
        "    value_weight_norm (int, optional): Norm type for value weight regularization. Defaults to 2.\n",
        "    value_bias (bool, optional): Whether to include bias in value weight. Defaults to False.\n",
        "    gen_weight_reg (list, optional): Regularization parameters for generation weight. Defaults to [0.001, 1].\n",
        "    gen_weight_norm (int, optional): Norm type for generation weight regularization. Defaults to 2.\n",
        "    concat_weight_reg (list, optional): Regularization parameters for concatenation weight. Defaults to [0.001, 1].\n",
        "    concat_weight_norm (int, optional): Norm type for concatenation weight regularization. Defaults to 2.\n",
        "    concat_bias (bool, optional): Whether to include bias in concatenation weight. Defaults to False.\n",
        "    average_attn_weights (bool, optional): Whether to average the attention weights. Defaults to False.\n",
        "    dropout_p (float, optional): Probability of an element to be zeroed. Defaults to 0.\n",
        "    dropout1_p (float, optional): Probability of an element of the first dropout layer to be zeroed. Defaults to 0.\n",
        "    dropout2_p (float, optional): Probability of an element of the second dropout layer to be zeroed. Defaults to 0.\n",
        "    dropout3_p (float, optional): Probability of an element of the third dropout layer to be zeroed. Defaults to 0.\n",
        "    linear1_bias (bool, optional): Whether to include bias in the first linear layer. Defaults to False.\n",
        "    linear2_bias (bool, optional): Whether to include bias in the second linear layer. Defaults to False.\n",
        "    linear1_weight_reg (list, optional): Regularization parameters for the first linear layer weight. Defaults to [0.001, 1].\n",
        "    linear1_weight_norm (int, optional): Norm type for the first linear layer weight regularization. Defaults to 2.\n",
        "    linear2_weight_reg (list, optional): Regularization parameters for the second linear layer weight. Defaults to [0.001, 1].\n",
        "    linear2_weight_norm (int, optional): Norm type for the second linear layer weight regularization. Defaults to 2.\n",
        "    feedforward_activation (str, optional): Type of activation function for the feedforward network. Defaults to 'relu'.\n",
        "    degree (int, optional): Degree of the polynomial activation function. Defaults to 2.\n",
        "    coef_init (torch.Tensor, optional): Initial coefficients for the polynomial activation function. Defaults to None.\n",
        "    coef_train (bool, optional): Whether to train the coefficients of the polynomial activation function. Defaults to True.\n",
        "    coef_reg (list, optional): Regularization parameters for the polynomial activation function coefficients. Defaults to [0.001, 1.].\n",
        "    zero_order (bool, optional): Whether to include the zero-order term in the polynomial activation function. Defaults to False.\n",
        "    scale_self_attn_residual_connection (bool, optional): Whether to scale the self-attention residual connection. Defaults to False.\n",
        "    scale_cross_attn_residual_connection (bool, optional): Whether to scale the cross-attention residual connection. Defaults to False.\n",
        "    scale_feedforward_residual_connection (bool, optional): Whether to scale the feedforward residual connection. Defaults to False.\n",
        "    device (str, optional): Device on which to allocate tensors. Defaults to 'cpu'.\n",
        "    dtype (torch.dtype, optional): Desired data type of the tensor. Defaults to torch.float32.\n",
        "  '''\n",
        "\n",
        "  def __init__(self,\n",
        "               d_model, nhead=1, dim_feedforward=2048,\n",
        "               self_attn_type=\"dot\", multihead_attn_type=\"dot\",\n",
        "               memory_is_causal=False, tgt_is_causal=True,\n",
        "               query_weight_reg=[0.001, 1], query_weight_norm=2, query_bias=False,\n",
        "               key_weight_reg=[0.001, 1], key_weight_norm=2, key_bias=False,\n",
        "               value_weight_reg=[0.001, 1], value_weight_norm=2, value_bias=False,\n",
        "               gen_weight_reg=[0.001, 1], gen_weight_norm=2, gen_bias = False,\n",
        "               concat_weight_reg=[0.001, 1], concat_weight_norm=2, concat_bias=False,\n",
        "               average_attn_weights=False,\n",
        "               dropout_p=0.0, dropout1_p=0.0, dropout2_p=0.0, dropout3_p=0.0,\n",
        "               linear1_bias=False, linear2_bias=False,\n",
        "               linear1_weight_reg=[0.001, 1], linear1_weight_norm=2,\n",
        "               linear2_weight_reg=[0.001, 1], linear2_weight_norm=2,\n",
        "               feedforward_activation=\"relu\",\n",
        "               degree=2,\n",
        "               coef_init=None, coef_train=True, coef_reg=[0.001, 1.],\n",
        "               zero_order=False,\n",
        "               scale_self_attn_residual_connection=False,\n",
        "               scale_cross_attn_residual_connection=False,\n",
        "               scale_feedforward_residual_connection=False,\n",
        "               device=\"cpu\", dtype=torch.float32):\n",
        "\n",
        "      super(TransformerDecoderLayer, self).__init__(d_model=d_model,\n",
        "                                                    nhead=nhead,\n",
        "                                                    dim_feedforward=dim_feedforward,\n",
        "                                                    device=device,\n",
        "                                                    dtype=dtype)\n",
        "\n",
        "      self.dropout.p = dropout_p\n",
        "\n",
        "      self.self_attn = Attention(embed_dim=d_model,\n",
        "                                 num_heads=nhead,\n",
        "                                 attn_type=self_attn_type,\n",
        "                                 query_weight_reg=query_weight_reg,\n",
        "                                 query_weight_norm=query_weight_norm,\n",
        "                                 query_bias=query_bias,\n",
        "                                 key_weight_reg=key_weight_reg,\n",
        "                                 key_weight_norm=key_weight_norm,\n",
        "                                 key_bias=key_bias,\n",
        "                                 value_weight_reg=value_weight_reg,\n",
        "                                 value_weight_norm=value_weight_norm,\n",
        "                                 value_bias=value_bias,\n",
        "                                 gen_weight_reg=gen_weight_reg,\n",
        "                                 gen_weight_norm=gen_weight_norm,\n",
        "                                 gen_bias=gen_bias,\n",
        "                                 concat_weight_reg=concat_weight_reg,\n",
        "                                 concat_weight_norm=concat_weight_norm,\n",
        "                                 concat_bias=concat_bias,\n",
        "                                 average_attn_weights=average_attn_weights,\n",
        "                                 is_causal=memory_is_causal,\n",
        "                                 dropout_p=dropout_p,\n",
        "                                 device=device,\n",
        "                                 dtype=dtype)\n",
        "\n",
        "      self.multihead_attn = Attention(embed_dim=d_model,\n",
        "                                      num_heads=nhead,\n",
        "                                      attn_type=multihead_attn_type,\n",
        "                                      query_weight_reg=query_weight_reg,\n",
        "                                      query_weight_norm=query_weight_norm,\n",
        "                                      query_bias=query_bias,\n",
        "                                      key_weight_reg=key_weight_reg,\n",
        "                                      key_weight_norm=key_weight_norm,\n",
        "                                      key_bias=key_bias,\n",
        "                                      value_weight_reg=value_weight_reg,\n",
        "                                      value_weight_norm=value_weight_norm,\n",
        "                                      value_bias=value_bias,\n",
        "                                      gen_weight_reg=gen_weight_reg,\n",
        "                                      gen_weight_norm=gen_weight_norm,\n",
        "                                      gen_bias=gen_bias,\n",
        "                                      concat_weight_reg=concat_weight_reg,\n",
        "                                      concat_weight_norm=concat_weight_norm,\n",
        "                                      concat_bias=concat_bias,\n",
        "                                      average_attn_weights=average_attn_weights,\n",
        "                                      is_causal=tgt_is_causal,\n",
        "                                      dropout_p=dropout1_p,\n",
        "                                      device=device,\n",
        "                                      dtype=dtype)\n",
        "\n",
        "      self.dropout2.p = dropout2_p\n",
        "      self.dropout3.p = dropout3_p\n",
        "\n",
        "      if feedforward_activation == \"identity\":\n",
        "        self.activation = torch.nn.Identity()\n",
        "        self.linear2 = torch.nn.Identity()\n",
        "        self.norm3 = torch.nn.Identity()\n",
        "        self.dropout3 = torch.nn.Identity()\n",
        "      elif feedforward_activation == \"relu\":\n",
        "        self.activation = torch.nn.ReLU()\n",
        "      elif feedforward_activation == \"gelu\":\n",
        "        self.activation = torch.nn.GELU()\n",
        "      elif feedforward_activation == \"polynomial\":\n",
        "        self.activation = Polynomial(in_features=dim_feedforward,\n",
        "                                    degree=degree,\n",
        "                                    coef_init=coef_init,\n",
        "                                    coef_train=coef_train,\n",
        "                                    coef_reg=coef_reg,\n",
        "                                    zero_order=zero_order,\n",
        "                                    device=device,\n",
        "                                    dtype=dtype)\n",
        "\n",
        "      self.linear1.bias = None if not linear1_bias else self.linear1.bias\n",
        "      self.linear1_weight_reg, self.linear1_weight_norm = (linear1_weight_reg, linear1_weight_norm)\n",
        "\n",
        "      if not isinstance(self.linear2, torch.nn.Identity):\n",
        "          self.linear2.bias = None if not linear2_bias else self.linear2.bias\n",
        "          self.linear2_weight_reg, self.linear2_weight_norm = (linear2_weight_reg, linear2_weight_norm)\n",
        "\n",
        "      self.self_attn_residual_scaler = (torch.nn.Linear(in_features=d_model, out_features=1).weight.squeeze().to(device=device, dtype=dtype)\n",
        "                                        if scale_self_attn_residual_connection\n",
        "                                        else torch.ones((d_model,)).to(device=device, dtype=dtype))\n",
        "\n",
        "      self.cross_attn_residual_scaler = (torch.nn.Linear(in_features=d_model, out_features=1).weight.squeeze().to(device=device, dtype=dtype)\n",
        "                                          if scale_cross_attn_residual_connection\n",
        "                                          else torch.ones((d_model,)).to(device=device, dtype=dtype))\n",
        "\n",
        "      self.feedforward_residual_scaler = (torch.nn.Linear(in_features=d_model, out_features=1).weight.squeeze().to(device=device, dtype=dtype)\n",
        "                                          if scale_feedforward_residual_connection\n",
        "                                          else torch.ones((d_model,)).to(device=device, dtype=dtype))\n",
        "\n",
        "  def forward(self,\n",
        "              tgt, memory,\n",
        "              tgt_mask=None, memory_mask=None,\n",
        "              tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "      '''\n",
        "      Forward pass of the Transformer Decoder Layer.\n",
        "\n",
        "      Args:\n",
        "          tgt (torch.Tensor): The input to the decoder layer of shape `(target_sequence_length, batch_size, d_model)`.\n",
        "          memory (torch.Tensor): The output of the encoder layer of shape `(input_sequence_length, batch_size, d_model)`.\n",
        "          tgt_mask (torch.Tensor, optional): Mask applied to the target sequence. Defaults to None.\n",
        "          memory_mask (torch.Tensor, optional): Mask applied to the memory sequence. Defaults to None.\n",
        "          tgt_key_padding_mask (torch.Tensor, optional): Mask applied to the target keys. Defaults to None.\n",
        "          memory_key_padding_mask (torch.Tensor, optional): Mask applied to the memory keys. Defaults to None.\n",
        "\n",
        "      Returns:\n",
        "          torch.Tensor: The output of the decoder layer of shape `(target_sequence_length, batch_size, d_model)`.\n",
        "      '''\n",
        "\n",
        "      tgt = self.self_attn(tgt, tgt, tgt, tgt_mask) + self.self_attn_residual_scaler * tgt\n",
        "      tgt = self.norm1(tgt)\n",
        "      tgt = self.multihead_attn(tgt, memory, memory, memory_mask) + self.cross_attn_residual_scaler * tgt\n",
        "      tgt = self.norm2(tgt)\n",
        "      tgt = self.dropout3(self.linear2(self.dropout2(self.activation(self.linear1(tgt))))) + self.feedforward_residual_scaler * tgt\n",
        "      tgt = self.norm3(tgt)\n",
        "\n",
        "      return tgt\n",
        "\n",
        "  def penalize(self):\n",
        "      '''\n",
        "      Compute the regularization loss for the decoder layer.\n",
        "\n",
        "      Returns:\n",
        "          torch.Tensor: The regularization loss.\n",
        "      '''\n",
        "      loss = 0\n",
        "      loss += self.self_attn.penalize()\n",
        "      loss += self.multihead_attn.penalize()\n",
        "      loss += self.linear1_weight_reg[0] * torch.norm(self.linear1.weight, p=self.linear1_weight_reg[1]) * int(self.linear1.weight.requires_grad)\n",
        "      loss += self.linear2_weight_reg[0] * torch.norm(self.linear2.weight, p=self.linear2_weight_reg[1]) * int(self.linear2.weight.requires_grad)\n",
        "\n",
        "      return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spl0DvcEXiZz"
      },
      "outputs": [],
      "source": [
        "class SequenceModelBase(torch.nn.Module):\n",
        "  '''\n",
        "  Base class for sequence models.\n",
        "\n",
        "  Args:\n",
        "    input_size (int): The number of expected features in the input.\n",
        "    hidden_size (int): The number of features in the hidden state/output.\n",
        "    seq_len (int, optional): The length of the input sequence. Default is None.\n",
        "    base_type (str): The type of the base model. Options: 'gru', 'lstm', 'lru', 'cnn', 'transformer'.\n",
        "    num_layers (int, optional): Number of recurrent layers. Default is 1.\n",
        "    encoder_bias (bool, optional): Whether to include a bias term in the encoder block. Default is False.\n",
        "    decoder_bias (bool, optional): Whether to include a bias term in the decoder block. Default is False.\n",
        "    rnn_bias (bool, optional): If False, then the layer does not use bias weights. Default is True.\n",
        "    rnn_dropout_p (float, optional): Dropout probability for the base model. Default is 0.\n",
        "    rnn_bidirectional (bool, optional): If True, becomes a bidirectional RNN. Default is False.\n",
        "    rnn_attn (bool, optional): Whether to apply attention mechanism on RNN outputs. Default is False.\n",
        "    rnn_weight_reg (list, optional): Regularization settings for RNN weights. Default is [0.001, 1].\n",
        "    rnn_weight_norm (float, optional): Norm type for RNN weights. Default is None.\n",
        "    relax_init (list, optional): Initial relaxation values for LRU. Default is [0.5].\n",
        "    relax_train (bool, optional): Whether to train relaxation values for LRU. Default is True.\n",
        "    relax_minmax (list, optional): Minimum and maximum relaxation values for LRU. Default is [0.1, 0.9].\n",
        "    num_filterbanks (int, optional): Number of filterbanks for LRU. Default is 1.\n",
        "    cnn_kernel_size (tuple, optional): Size of the convolving kernel for CNN. Default is (1,).\n",
        "    cnn_stride (tuple, optional): Stride of the convolution for CNN. Default is (1,).\n",
        "    cnn_padding (tuple, optional): Zero-padding added to both sides of the input for CNN. Default is (0,).\n",
        "    cnn_dilation (tuple, optional): Spacing between kernel elements for CNN. Default is (1,).\n",
        "    cnn_groups (int, optional): Number of blocked connections from input channels to output channels for CNN. Default is 1.\n",
        "    cnn_bias (bool, optional): If False, then the layer does not use bias weights. Default is False.\n",
        "    encoder_output_size (int, optional): The size of the output from the encoder block. Default is None.\n",
        "    seq_type (str, optional): Type of the sequence. Options: 'encoder', 'decoder'. Default is 'encoder'.\n",
        "    transformer_embedding_type (str, optional): Type of embedding for Transformer. Default is 'time'.\n",
        "    transformer_embedding_bias (bool, optional): Whether to include a bias term in the embedding for Transformer. Default is False.\n",
        "    transformer_embedding_activation (str, optional): Activation function for Transformer embedding. Options: 'identity', 'relu', 'gelu'. Default is 'identity'.\n",
        "    transformer_embedding_weight_reg (list, optional): Regularization settings for Transformer embedding weights. Default is [0.001, 1].\n",
        "    transformer_embedding_weight_norm (float, optional): Norm type for Transformer embedding weights. Default is 2.\n",
        "    transformer_embedding_dropout_p (float, optional): Dropout probability for Transformer embedding. Default is 0.0.\n",
        "    transformer_positional_encoding_type (str, optional): Type of positional encoding for Transformer. Options: 'absolute'.\n",
        "    transformer_dropout1_p (float, optional): Dropout probability for the first dropout layer in Transformer. Default is 0.\n",
        "    transformer_dropout2_p (float, optional): Dropout probability for the second dropout layer in Transformer. Default is 0.\n",
        "    transformer_dropout3_p (float, optional): Dropout probability for the third dropout layer in Transformer. Default is 0.\n",
        "    transformer_linear1_bias (bool, optional): Whether to include a bias term in the first linear layer in Transformer. Default is False.\n",
        "    transformer_linear2_bias (bool, optional): Whether to include a bias term in the second linear layer in Transformer. Default is False.\n",
        "    transformer_linear1_weight_reg (list, optional): Regularization settings for the weights of the first linear layer in Transformer. Default is [0.001, 1].\n",
        "    transformer_linear1_weight_norm (float, optional): Norm type for the weights of the first linear layer in Transformer. Default is 2.\n",
        "    transformer_linear2_weight_reg (list, optional): Regularization settings for the weights of the second linear layer in Transformer. Default is [0.001, 1].\n",
        "    transformer_linear2_weight_norm (float, optional): Norm type for the weights of the second linear layer in Transformer. Default is 2.\n",
        "    transformer_feedforward_activation (str, optional): Activation function for the feedforward layer in Transformer. Options: 'relu'. Default is 'relu'.\n",
        "    transformer_feedforward_degree (int, optional): Degree of the polynomial activation function for the feedforward layer in Transformer. Default is 2.\n",
        "    transformer_coef_init (None or float, optional): Initial value for the coefficients of the polynomial activation function in Transformer. Default is None.\n",
        "    transformer_coef_train (bool, optional): Whether to train the coefficients of the polynomial activation function in Transformer. Default is True.\n",
        "    transformer_coef_reg (list, optional): Regularization settings for the coefficients of the polynomial activation function in Transformer. Default is [0.001, 1.].\n",
        "    transformer_zero_order (bool, optional): Whether to include the zero-order term in the polynomial activation function in Transformer. Default is False.\n",
        "    transformer_scale_self_attn_residual_connection (bool, optional): Whether to scale the residual connection in the self-attention sub-layer of Transformer. Default is False.\n",
        "    transformer_scale_cross_attn_residual_connection (bool, optional): Whether to scale the residual connection in the cross-attention sub-layer of Transformer. Default is False.\n",
        "    transformer_scale_feedforward_residual_connection (bool, optional): Whether to scale the residual connection in the feedforward sub-layer of Transformer. Default is False.\n",
        "    transformer_layer_norm (bool, optional): Whether to include layer normalization in Transformer layers. Default is True.\n",
        "    num_heads (int, optional): Number of attention heads in Transformer. Default is 1.\n",
        "    transformer_dim_feedforward (int, optional): Dimension of the feedforward layer in Transformer. Default is 2048.\n",
        "    self_attn_type (str, optional): Type of self-attention in Transformer. Options: 'dot'. Default is 'dot'.\n",
        "    multihead_attn_type (str, optional): Type of multihead attention in Transformer. Options: 'dot'. Default is 'dot'.\n",
        "    memory_is_causal (bool, optional): Whether the memory sequence is causal in Transformer. Default is True.\n",
        "    tgt_is_causal (bool, optional): Whether the target sequence is causal in Transformer. Default is False.\n",
        "    query_dim (None or int, optional): The dimension of query in attention mechanism. Default is None.\n",
        "    key_dim (None or int, optional): The dimension of key in attention mechanism. Default is None.\n",
        "    value_dim (None or int, optional): The dimension of value in attention mechanism. Default is None.\n",
        "    query_weight_reg (list, optional): Regularization settings for the query weight in attention mechanism. Default is [0.001, 1].\n",
        "    query_weight_norm (float, optional): Norm type for the query weight in attention mechanism. Default is 2.\n",
        "    query_bias (bool, optional): Whether to include a bias term in the query weight in attention mechanism. Default is False.\n",
        "    key_weight_reg (list, optional): Regularization settings for the key weight in attention mechanism. Default is [0.001, 1].\n",
        "    key_weight_norm (float, optional): Norm type for the key weight in attention mechanism. Default is 2.\n",
        "    key_bias (bool, optional): Whether to include a bias term in the key weight in attention mechanism. Default is False.\n",
        "    value_weight_reg (list, optional): Regularization settings for the value weight in attention mechanism. Default is [0.001, 1].\n",
        "    value_weight_norm (float, optional): Norm type for the value weight in attention mechanism. Default is 2.\n",
        "    value_bias (bool, optional): Whether to include a bias term in the value weight in attention mechanism. Default is False.\n",
        "    gen_weight_reg (list, optional): Regularization settings for the generator weight in attention mechanism. Default is [0.001, 1].\n",
        "    gen_weight_norm (float, optional): Norm type for the generator weight in attention mechanism. Default is 2.\n",
        "    gen_bias (bool, optional): Whether to include a bias term in the generator weight in attention mechanism. Default is False.\n",
        "    concat_weight_reg (list, optional): Regularization settings for the concatenation weight in attention mechanism. Default is [0.001, 1].\n",
        "    concat_weight_norm (float, optional): Norm type for the concatenation weight in attention mechanism. Default is 2.\n",
        "    concat_bias (bool, optional): Whether to include a bias term in the concatenation weight in attention mechanism. Default is False.\n",
        "    attn_dropout_p (float, optional): Dropout probability for attention mechanism. Default is 0.\n",
        "    average_attn_weights (bool, optional): Whether to average attention weights. Default is False.\n",
        "    batch_first (bool, optional): If True, then the input and output tensors are provided as (batch, seq, feature). Default is True.\n",
        "    device (str, optional): The device to run the model on. Default is 'cpu'.\n",
        "    dtype (torch.dtype, optional): The desired data type of the model's parameters. Default is torch.float32.\n",
        "  '''\n",
        "\n",
        "  def __init__(self,\n",
        "              input_size, hidden_size, seq_len=None,\n",
        "              base_type='gru', num_layers=1,\n",
        "              encoder_bias=False, decoder_bias=False,\n",
        "              rnn_bias=True,\n",
        "              rnn_dropout_p=0,\n",
        "              rnn_bidirectional=False,\n",
        "              rnn_attn=False,\n",
        "              rnn_weight_reg=[0.001, 1], rnn_weight_norm=None,\n",
        "              relax_init=[0.5], relax_train=True, relax_minmax=[0.1, 0.9], num_filterbanks=1,\n",
        "              cnn_kernel_size=(1,), cnn_stride=(1,), cnn_padding=(0,), cnn_dilation=(1,), cnn_groups=1,\n",
        "              cnn_bias=False,\n",
        "              encoder_output_size=None, seq_type='encoder',\n",
        "              transformer_embedding_type='time', transformer_embedding_bias=False,\n",
        "              transformer_embedding_activation='identity',\n",
        "              transformer_embedding_weight_reg=[0.001, 1], transformer_embedding_weight_norm=2,\n",
        "              transformer_embedding_dropout_p=0.0,\n",
        "              transformer_positional_encoding_type='absolute',\n",
        "              transformer_dropout1_p=0., transformer_dropout2_p=0., transformer_dropout3_p=0.,\n",
        "              transformer_linear1_bias=False, transformer_linear2_bias=False,\n",
        "              transformer_linear1_weight_reg=[0.001, 1], transformer_linear1_weight_norm=2,\n",
        "              transformer_linear2_weight_reg=[0.001, 1], transformer_linear2_weight_norm=2,\n",
        "              transformer_feedforward_activation='relu',\n",
        "              transformer_feedforward_degree=2, transformer_coef_init=None, transformer_coef_train=True,\n",
        "              transformer_coef_reg=[0.001, 1.], transformer_zero_order=False,\n",
        "              transformer_scale_self_attn_residual_connection=False,\n",
        "              transformer_scale_cross_attn_residual_connection=False,\n",
        "              transformer_scale_feedforward_residual_connection=False,\n",
        "              transformer_layer_norm=True,\n",
        "              num_heads=1, transformer_dim_feedforward=2048,\n",
        "              self_attn_type='dot', multihead_attn_type='dot',\n",
        "              memory_is_causal=True, tgt_is_causal=False,\n",
        "              query_dim=None, key_dim=None, value_dim=None,\n",
        "              query_weight_reg=[0.001, 1], query_weight_norm=2, query_bias=False,\n",
        "              key_weight_reg=[0.001, 1], key_weight_norm=2, key_bias=False,\n",
        "              value_weight_reg=[0.001, 1], value_weight_norm=2, value_bias=False,\n",
        "              gen_weight_reg=[0.001, 1], gen_weight_norm=2, gen_bias=False,\n",
        "              concat_weight_reg=[0.001, 1], concat_weight_norm=2, concat_bias=False,\n",
        "              attn_dropout_p=0.,\n",
        "              average_attn_weights=False,\n",
        "              batch_first=True,\n",
        "              device='cpu', dtype=torch.float32):\n",
        "    super(SequenceModelBase, self).__init__()\n",
        "\n",
        "    self.to(device=device, dtype=dtype)\n",
        "\n",
        "    self.name = f\"{base_type}{num_layers}\"\n",
        "\n",
        "    positional_encoding = None\n",
        "    encoder_block = None\n",
        "    if base_type == 'identity':\n",
        "        base = torch.nn.Identity()\n",
        "    elif base_type == 'gru':\n",
        "        base = torch.nn.GRU(input_size=input_size,\n",
        "                            hidden_size=hidden_size,\n",
        "                            num_layers=num_layers,\n",
        "                            bias=rnn_bias,\n",
        "                            dropout=rnn_dropout_p,\n",
        "                            bidirectional=rnn_bidirectional,\n",
        "                            device=device, dtype=dtype,\n",
        "                            batch_first=True)\n",
        "    elif base_type == 'lstm':\n",
        "        base = torch.nn.LSTM(input_size=input_size,\n",
        "                              hidden_size=hidden_size,\n",
        "                              num_layers=num_layers,\n",
        "                              bias=rnn_bias,\n",
        "                              dropout=rnn_dropout_p,\n",
        "                              bidirectional=rnn_bidirectional,\n",
        "                              device=device, dtype=dtype,\n",
        "                              batch_first=True)\n",
        "    elif base_type == 'lru':\n",
        "        base = LRU(input_size=input_size, hidden_size=hidden_size,\n",
        "                    bias=rnn_bias,\n",
        "                    relax_init=relax_init, relax_train=relax_train, relax_minmax=relax_minmax,\n",
        "                    device=device, dtype=dtype)\n",
        "    elif base_type == 'cnn':\n",
        "        base = torch.nn.Conv1d(in_channels=input_size,\n",
        "                                out_channels=hidden_size,\n",
        "                                kernel_size=cnn_kernel_size,\n",
        "                                stride=cnn_stride,\n",
        "                                padding=cnn_padding,\n",
        "                                dilation=cnn_dilation,\n",
        "                                groups=cnn_groups,\n",
        "                                bias=cnn_bias,\n",
        "                                device=device, dtype=dtype)\n",
        "    elif base_type == 'transformer':\n",
        "        embedding = Embedding(num_embeddings=input_size,\n",
        "                              embedding_dim=hidden_size,\n",
        "                              embedding_type=transformer_embedding_type,\n",
        "                              bias=transformer_embedding_bias,\n",
        "                              activation=transformer_embedding_activation,\n",
        "                              weight_reg=transformer_embedding_weight_reg,\n",
        "                              weight_norm=transformer_embedding_weight_norm,\n",
        "                              dropout_p=transformer_embedding_dropout_p,\n",
        "                              device=device, dtype=dtype)\n",
        "\n",
        "        positional_encoding = PositionalEncoding(dim=hidden_size, seq_len=seq_len,\n",
        "                                                  encoding_type=transformer_positional_encoding_type,\n",
        "                                                  device=device, dtype=dtype)\n",
        "\n",
        "        base = torch.nn.ModuleList([torch.nn.Sequential(*[embedding, positional_encoding])])\n",
        "\n",
        "        if seq_type == 'encoder':\n",
        "            base.append(torch.nn.TransformerEncoder(TransformerEncoderLayer(d_model=hidden_size,\n",
        "                                                                            nhead=num_heads,\n",
        "                                                                            dim_feedforward=transformer_dim_feedforward,\n",
        "                                                                            self_attn_type=self_attn_type,\n",
        "                                                                            is_causal=memory_is_causal,\n",
        "                                                                            query_weight_reg=query_weight_reg,\n",
        "                                                                            query_weight_norm=query_weight_norm,\n",
        "                                                                            query_bias=query_bias,\n",
        "                                                                            key_weight_reg=key_weight_reg,\n",
        "                                                                            key_weight_norm=key_weight_norm,\n",
        "                                                                            key_bias=key_bias,\n",
        "                                                                            value_weight_reg=value_weight_reg,\n",
        "                                                                            value_weight_norm=value_weight_norm,\n",
        "                                                                            value_bias=value_bias,\n",
        "                                                                            gen_weight_reg=gen_weight_reg,\n",
        "                                                                            gen_weight_norm=gen_weight_norm,\n",
        "                                                                            gen_bias=gen_bias,\n",
        "                                                                            concat_weight_reg=concat_weight_reg,\n",
        "                                                                            concat_weight_norm=concat_weight_norm,\n",
        "                                                                            concat_bias=concat_bias,\n",
        "                                                                            average_attn_weights=average_attn_weights,\n",
        "                                                                            dropout_p=attn_dropout_p,\n",
        "                                                                            dropout1_p=transformer_dropout1_p,\n",
        "                                                                            dropout2_p=transformer_dropout2_p,\n",
        "                                                                            linear1_weight_reg=transformer_linear1_weight_reg,\n",
        "                                                                            linear1_weight_norm=transformer_linear1_weight_norm,\n",
        "                                                                            linear2_weight_reg=transformer_linear2_weight_reg,\n",
        "                                                                            linear2_weight_norm=transformer_linear2_weight_norm,\n",
        "                                                                            linear1_bias=transformer_linear1_bias,\n",
        "                                                                            linear2_bias=transformer_linear2_bias,\n",
        "                                                                            feedforward_activation=transformer_feedforward_activation,\n",
        "                                                                            degree=transformer_feedforward_degree,\n",
        "                                                                            coef_init=transformer_coef_init,\n",
        "                                                                            coef_train=transformer_coef_train,\n",
        "                                                                            coef_reg=transformer_coef_reg,\n",
        "                                                                            zero_order=transformer_zero_order,\n",
        "                                                                            scale_self_attn_residual_connection=transformer_scale_self_attn_residual_connection,\n",
        "                                                                            scale_feedforward_residual_connection=transformer_scale_feedforward_residual_connection,\n",
        "                                                                            device=device, dtype=dtype),\n",
        "                                                    num_layers=num_layers))\n",
        "\n",
        "        elif seq_type == 'decoder':\n",
        "            base.append(torch.nn.TransformerDecoder(TransformerDecoderLayer(d_model=hidden_size,\n",
        "                                                                            nhead=num_heads,\n",
        "                                                                            dim_feedforward=transformer_dim_feedforward,\n",
        "                                                                            self_attn_type=self_attn_type,\n",
        "                                                                            memory_is_causal=memory_is_causal,\n",
        "                                                                            tgt_is_causal=tgt_is_causal,\n",
        "                                                                            query_weight_reg=query_weight_reg,\n",
        "                                                                            query_weight_norm=query_weight_norm,\n",
        "                                                                            query_bias=query_bias,\n",
        "                                                                            key_weight_reg=key_weight_reg,\n",
        "                                                                            key_weight_norm=key_weight_norm,\n",
        "                                                                            key_bias=key_bias,\n",
        "                                                                            value_weight_reg=value_weight_reg,\n",
        "                                                                            value_weight_norm=value_weight_norm,\n",
        "                                                                            value_bias=value_bias,\n",
        "                                                                            gen_weight_reg=gen_weight_reg,\n",
        "                                                                            gen_weight_norm=gen_weight_norm,\n",
        "                                                                            gen_bias=gen_bias,\n",
        "                                                                            concat_weight_reg=concat_weight_reg,\n",
        "                                                                            concat_weight_norm=concat_weight_norm,\n",
        "                                                                            concat_bias=concat_bias,\n",
        "                                                                            average_attn_weights=average_attn_weights,\n",
        "                                                                            dropout_p=attn_dropout_p,\n",
        "                                                                            dropout1_p=transformer_dropout1_p,\n",
        "                                                                            dropout2_p=transformer_dropout2_p,\n",
        "                                                                            dropout3_p=transformer_dropout3_p,\n",
        "                                                                            linear1_weight_reg=transformer_linear1_weight_reg,\n",
        "                                                                            linear1_weight_norm=transformer_linear1_weight_norm,\n",
        "                                                                            linear2_weight_reg=transformer_linear2_weight_reg,\n",
        "                                                                            linear2_weight_norm=transformer_linear2_weight_norm,\n",
        "                                                                            linear1_bias=transformer_linear1_bias,\n",
        "                                                                            linear2_bias=transformer_linear2_bias,\n",
        "                                                                            feedforward_activation=transformer_feedforward_activation,\n",
        "                                                                            degree=transformer_feedforward_degree,\n",
        "                                                                            coef_init=transformer_coef_init,\n",
        "                                                                            coef_train=transformer_coef_train,\n",
        "                                                                            coef_reg=transformer_coef_reg,\n",
        "                                                                            zero_order=transformer_zero_order,\n",
        "                                                                            scale_self_attn_residual_connection=transformer_scale_self_attn_residual_connection,\n",
        "                                                                            scale_cross_attn_residual_connection=transformer_scale_cross_attn_residual_connection,\n",
        "                                                                            scale_feedforward_residual_connection=transformer_scale_feedforward_residual_connection,\n",
        "                                                                            device=device, dtype=dtype),\n",
        "                                                    num_layers=num_layers))\n",
        "\n",
        "            if (encoder_output_size != hidden_size):\n",
        "                encoder_block = HiddenLayer(in_features=encoder_output_size,\n",
        "                                            out_features=hidden_size,\n",
        "                                            activation='identity',\n",
        "                                            bias=encoder_bias,\n",
        "                                            device=device, dtype=dtype)\n",
        "\n",
        "        base[1].norm = None if not transformer_layer_norm else base[1].norm\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"'{base_type}' is not a valid value. `base_type` must be 'gru', 'lstm', 'lru', 'cnn', or 'transformer'.\")\n",
        "\n",
        "    attn_mechanism, decoder_block = None, None\n",
        "    if rnn_attn:\n",
        "        attn_mechanism = Attention(embed_dim=hidden_size,\n",
        "                                    num_heads=num_heads,\n",
        "                                    query_dim=query_dim, key_dim=key_dim, value_dim=value_dim,\n",
        "                                    attn_type=multihead_attn_type,\n",
        "                                    query_weight_reg=query_weight_reg, query_weight_norm=query_weight_norm,\n",
        "                                    query_bias=query_bias,\n",
        "                                    key_weight_reg=key_weight_reg, key_weight_norm=key_weight_norm, key_bias=key_bias,\n",
        "                                    value_weight_reg=value_weight_reg, value_weight_norm=value_weight_norm, value_bias=value_bias,\n",
        "                                    is_causal=tgt_is_causal, dropout_p=attn_dropout_p,\n",
        "                                    device=device, dtype=dtype)\n",
        "\n",
        "        if (encoder_output_size != hidden_size * (1 + rnn_bidirectional)):\n",
        "            encoder_block = HiddenLayer(in_features=encoder_output_size,\n",
        "                                        out_features=(hidden_size * (1 + rnn_bidirectional) if base_type in ('lstm', 'gru') else len(relax_init)) * hidden_size * (1 + rnn_bidirectional),\n",
        "                                        activation='identity',\n",
        "                                        bias=encoder_bias,\n",
        "                                        device=device, dtype=dtype)\n",
        "\n",
        "        decoder_block = HiddenLayer(in_features=2 * hidden_size,\n",
        "                                    out_features=hidden_size,\n",
        "                                    activation='identity',\n",
        "                                    bias=decoder_bias,\n",
        "                                    device=device, dtype=dtype)\n",
        "\n",
        "    self.device, self.dtype = device, dtype\n",
        "    self.input_size = input_size\n",
        "    self.base, self.base_type, self.num_layers = base, base_type, num_layers\n",
        "    self.seq_type, self.seq_len = seq_type, seq_len\n",
        "    self.positional_encoding = positional_encoding\n",
        "    self.rnn_attn, self.attn_mechanism = rnn_attn, attn_mechanism\n",
        "    self.encoder_block, self.decoder_block = encoder_block, decoder_block\n",
        "    self.relax_minmax = relax_minmax\n",
        "    self.rnn_weight_reg, self.rnn_weight_norm = rnn_weight_reg, rnn_weight_norm\n",
        "\n",
        "  def init_hiddens(self, num_samples):\n",
        "    '''\n",
        "    Initialize hidden states for the base model.\n",
        "\n",
        "    Args:\n",
        "        num_samples (int): The number of samples in the input.\n",
        "\n",
        "    Returns:\n",
        "        hiddens (list or torch.Tensor): Initialized hidden states.\n",
        "    '''\n",
        "    if self.base_type == 'lru':\n",
        "        hiddens = torch.zeros((self.base.num_filterbanks, num_samples, self.base.hidden_size)).to(device=self.device,\n",
        "                                                                                                    dtype=self.dtype)\n",
        "    else:\n",
        "        if self.base_type == 'lstm':\n",
        "            hiddens = [torch.zeros((self.base.num_layers, num_samples, self.base.hidden_size)).to(device=self.device,\n",
        "                                                                                                  dtype=self.dtype)] * 2\n",
        "        else:\n",
        "            hiddens = torch.zeros((self.base.num_layers, num_samples, self.base.hidden_size)).to(device=self.device,\n",
        "                                                                                                  dtype=self.dtype)\n",
        "\n",
        "    return hiddens\n",
        "\n",
        "  def forward(self, input, hiddens=None, encoder_output=None, mask=None):\n",
        "    '''\n",
        "    Forward pass of the sequence model.\n",
        "\n",
        "    Args:\n",
        "        input (torch.Tensor): Input tensor of shape (num_samples, input_len, input_size).\n",
        "        hiddens (list or torch.Tensor, optional): Hidden states of the base model. Default is None.\n",
        "        encoder_output (torch.Tensor, optional): Output from the encoder block. Default is None.\n",
        "        mask (torch.Tensor, optional): Mask tensor for attention mechanism. Default is None.\n",
        "\n",
        "    Returns:\n",
        "        output (torch.Tensor): Output tensor of shape (num_samples, input_len, output_size).\n",
        "        hiddens (list or torch.Tensor): Updated hidden states of the base model.\n",
        "    '''\n",
        "    num_samples, input_len, input_size = input.shape\n",
        "\n",
        "    if (hiddens is None) & (self.base_type in ['lru', 'lstm', 'gru']):\n",
        "        hiddens = self.init_hiddens(num_samples)\n",
        "\n",
        "    if self.encoder_block is not None:\n",
        "        encoder_output = self.encoder_block(encoder_output)\n",
        "\n",
        "    if self.base_type == 'identity':\n",
        "        output, hiddens = input, hiddens\n",
        "    elif self.base_type in ['lru', 'lstm', 'gru']:\n",
        "        output, hiddens = self.base(input, hiddens)\n",
        "\n",
        "        output = output.reshape(num_samples, input_len, -1)\n",
        "\n",
        "        if self.rnn_attn:\n",
        "            # Pass encoder output and base output (context) to generate attn output and weights\n",
        "            attn_output = self.attn_mechanism(query=output[:, -1:],\n",
        "                                              key=encoder_output,\n",
        "                                              value=encoder_output)\n",
        "\n",
        "            # Ensure attn_output has the same length as the base output\n",
        "            if attn_output.shape[1] == 1:\n",
        "                attn_output = attn_output.repeat(1, output.shape[1], 1)\n",
        "\n",
        "            # Combine attn output and base output, then pass result to the decoder block to generate the new base output\n",
        "            output = self.decoder_block(torch.cat((attn_output, output), -1))\n",
        "\n",
        "    elif self.base_type == 'cnn':\n",
        "        input_t_pad = torch.nn.functional.pad(input.transpose(1, 2), (self.base.kernel_size[0] - 1, 0))\n",
        "        output = self.base(input_t_pad).transpose(1, 2)\n",
        "    elif self.base_type == 'transformer':\n",
        "        input_embedding_pe = self.base[0](input)\n",
        "\n",
        "        output = self.base[1](tgt=input_embedding_pe, memory=encoder_output) if self.seq_type == 'decoder' \\\n",
        "            else self.base[1](src=input_embedding_pe, mask=mask)\n",
        "\n",
        "    return output, hiddens\n",
        "\n",
        "  def constrain(self):\n",
        "    '''\n",
        "    Apply constraints to the model.\n",
        "\n",
        "    This method applies constraints specific to each base model type.\n",
        "    '''\n",
        "    if self.base_type == 'lru':\n",
        "        self.base.clamp_relax()\n",
        "    elif self.weight_norm is not None:\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                param = torch.nn.functional.normalize(param, p=self.rnn_weight_norm, dim=1).contiguous()\n",
        "\n",
        "  def penalize(self):\n",
        "    '''\n",
        "    Compute the penalty for regularization.\n",
        "\n",
        "    Returns:\n",
        "        loss (torch.Tensor): Regularization loss.\n",
        "    '''\n",
        "    loss = 0\n",
        "    if self.base_type == 'transformer':\n",
        "        loss += self.base[0].penalize()  # embedding penalty\n",
        "        loss += sum(layer.penalize() for layer in self.base[1])  # transformer layer penalties\n",
        "    else:\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight' in param:\n",
        "                loss += self.rnn_weight_reg[0] * torch.norm(param, p=self.rnn_weight_reg[1]) * int(\n",
        "                    param.requires_grad)\n",
        "\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSNTv865uhOL"
      },
      "outputs": [],
      "source": [
        "class SequenceModel(torch.nn.Module):\n",
        "  def __init__(self,\n",
        "               num_inputs, num_outputs,\n",
        "               #\n",
        "               input_size = [1], output_size = [1], seq_len = [None],\n",
        "               stateful = False,\n",
        "               dt = 1,\n",
        "               ## Sequence base parameters\n",
        "               # type\n",
        "               base_hidden_size = [1],\n",
        "               base_type = ['gru'], base_num_layers = [1],\n",
        "               base_enc2dec_bias = [False],\n",
        "               encoder_output_size = None,\n",
        "               # GRU/LSTM parameters\n",
        "               base_rnn_bias = [True],\n",
        "               base_rnn_dropout_p = [0],\n",
        "               base_rnn_bidirectional = [False],\n",
        "               base_rnn_attn = [False],\n",
        "               base_encoder_bias = [False], base_decoder_bias = [False],\n",
        "               base_rnn_weight_reg = [[0.001, 1]], base_rnn_weight_norm = [None],\n",
        "               # LRU parameters\n",
        "               base_relax_init = [[0.5]], base_relax_train = [True], base_relax_minmax = [[0.1, 0.9]], base_num_filterbanks = [1],\n",
        "               # CNN parameters\n",
        "               base_cnn_kernel_size = [(1,)], base_cnn_stride = [(1,)], base_cnn_padding = [(0,)], base_cnn_dilation = [(1,)], base_cnn_groups = [1], base_cnn_bias = [False],\n",
        "               # Transformer parameters\n",
        "               base_seq_type = ['encoder'],\n",
        "               base_transformer_embedding_type = ['time'], base_transformer_embedding_bias = [False], base_transformer_embedding_activation = ['identity'],\n",
        "               base_transformer_embedding_weight_reg = [[0.001, 1]], base_transformer_embedding_weight_norm = [2], base_transformer_embedding_dropout_p = [0.0],\n",
        "               base_transformer_positional_encoding_type = ['absolute'],\n",
        "               base_transformer_dropout1_p = [0.], base_transformer_dropout2_p = [0.], base_transformer_dropout3_p = [0.],\n",
        "               base_transformer_linear1_bias = [False], base_transformer_linear2_bias = [False],\n",
        "               base_transformer_linear1_weight_reg = [[0.001, 1]], base_transformer_linear1_weight_norm = [2],\n",
        "               base_transformer_linear2_weight_reg = [[0.001, 1]], base_transformer_linear2_weight_norm = [2],\n",
        "               base_transformer_feedforward_activation = ['relu'],\n",
        "               base_transformer_feedforward_degree = [2], base_transformer_coef_init = [None], base_transformer_coef_train = [True], base_transformer_coef_reg = [[0.001, 1.]], base_transformer_zero_order = [False],\n",
        "               base_transformer_scale_self_attn_residual_connection = [False],\n",
        "               base_transformer_scale_cross_attn_residual_connection = [False],\n",
        "               base_transformer_scale_feedforward_residual_connection = [False],\n",
        "               base_transformer_layer_norm = [True],\n",
        "               # attention parameters\n",
        "               base_num_heads = [1], base_transformer_dim_feedforward = [2048],\n",
        "               base_self_attn_type = ['dot'], base_multihead_attn_type = ['dot'],\n",
        "               base_memory_is_causal = [False], base_tgt_is_causal = [True],\n",
        "               base_query_dim = [None], base_key_dim = [None], base_value_dim = [None],\n",
        "               base_query_weight_reg = [[0.001, 1]], base_query_weight_norm = [2], base_query_bias = [False],\n",
        "               base_key_weight_reg = [[0.001, 1]], base_key_weight_norm = [2], base_key_bias = [False],\n",
        "               base_value_weight_reg = [[0.001, 1]], base_value_weight_norm = [2], base_value_bias = [False],\n",
        "               base_gen_weight_reg = [[0.001, 1]], base_gen_weight_norm = [2], base_gen_bias = [False],\n",
        "               base_concat_weight_reg = [[0.001, 1]], base_concat_weight_norm = [2], base_concat_bias = [False],\n",
        "               base_attn_dropout_p = [0.], base_average_attn_weights = [False],\n",
        "               base_constrain = False, base_penalize = False,\n",
        "               ##\n",
        "               # hidden layer parameters\n",
        "               hidden_out_features = [0], hidden_bias = [False], hidden_activation = ['identity'], hidden_degree = [1],\n",
        "               hidden_coef_init = [None], hidden_coef_train = [True], hidden_coef_reg = [[0.001, 1]], hidden_zero_order = [False],\n",
        "               hidden_softmax_dim = [-1],\n",
        "               hidden_constrain = [False], hidden_penalize = [False],\n",
        "               hidden_dropout_p = [0.],\n",
        "               # interaction layer\n",
        "               interaction_out_features = 0, interaction_bias = False, interaction_activation = 'identity',\n",
        "               interaction_degree = 1, interaction_coef_init = True, interaction_coef_train = True,\n",
        "               interaction_coef_reg = [0.001, 1], interaction_zero_order = False, interaction_softmax_dim = -1,\n",
        "               interaction_constrain = False, interaction_penalize = False,\n",
        "               interaction_dropout_p = 0.,\n",
        "               # modulation layer\n",
        "               modulation_window_len = None, modulation_associated = False,\n",
        "               modulation_legendre_degree = None, modulation_chebychev_degree = None,\n",
        "               modulation_num_freqs = None, modulation_freq_init = None, modulation_freq_train = True,\n",
        "               modulation_phase_init = None, modulation_phase_train = True,\n",
        "               modulation_num_sigmoids = None,\n",
        "               modulation_slope_init = None, modulation_slope_train = True, modulation_shift_init = None, modulation_shift_train = True,\n",
        "               modulation_weight_reg = [0.001, 1.0], modulation_weight_norm = 2,\n",
        "               modulation_zero_order = True,\n",
        "               modulation_bias = True, modulation_pure = False,\n",
        "               # output layer\n",
        "               output_associated = [True],\n",
        "               output_bias = [True], output_activation = ['identity'], output_degree = [1],\n",
        "               output_coef_init = [None], output_coef_train = [True], output_coef_reg = [[0.001, 1]], output_zero_order = [False], output_softmax_dim = [-1],\n",
        "               output_constrain = [False], output_penalize = [False],\n",
        "               output_dropout_p = [0.],\n",
        "               #\n",
        "               device = 'cpu', dtype = torch.float32):\n",
        "\n",
        "    super(SequenceModel, self).__init__()\n",
        "\n",
        "    self.to(device = device, dtype = dtype)\n",
        "\n",
        "    locals_copy = locals().copy() # copy the local variables\n",
        "    for arg in locals_copy:\n",
        "      value = locals_copy[arg]\n",
        "      if isinstance(value, list) and any(x in arg for x in ['seq_type', 'input_size', 'base_', 'decoder_', 'hidden_', 'attn_']):\n",
        "        if len(value) == 1:\n",
        "          setattr(self, arg, value * num_inputs)\n",
        "      elif isinstance(value, list) and any(x in arg for x in ['output_size', 'output_']):\n",
        "        if len(value) == 1:\n",
        "          setattr(self, arg, value * num_outputs)\n",
        "\n",
        "    seq_base, hidden_layer = torch.nn.ModuleList([]), torch.nn.ModuleList([])\n",
        "    for i in range(num_inputs):\n",
        "      # input-associated sequence layer\n",
        "      seq_base_i = SequenceModelBase(input_size = input_size[i],\n",
        "                                      hidden_size = base_hidden_size[i],\n",
        "                                      seq_len = seq_len[i],\n",
        "                                      # type\n",
        "                                      base_type = base_type[i], num_layers = base_num_layers[i],\n",
        "                                      encoder_bias = base_encoder_bias[i], decoder_bias = base_decoder_bias[i],\n",
        "                                      # GRU/LSTM parameters\n",
        "                                      rnn_bias = base_rnn_bias[i],\n",
        "                                      rnn_dropout_p = base_rnn_dropout_p[i],\n",
        "                                      rnn_bidirectional = base_rnn_bidirectional[i],\n",
        "                                      rnn_attn = base_rnn_attn[i],\n",
        "                                      rnn_weight_reg = base_rnn_weight_reg[i], rnn_weight_norm = base_rnn_weight_norm[i],\n",
        "                                      # LRU parameters\n",
        "                                      relax_init = base_relax_init[i], relax_train = base_relax_train[i], relax_minmax = base_relax_minmax[i], num_filterbanks = base_num_filterbanks[i],\n",
        "                                      # CNN parameters\n",
        "                                      cnn_kernel_size = base_cnn_kernel_size[i], cnn_stride = base_cnn_stride[i], cnn_padding = base_cnn_padding[i], cnn_dilation = base_cnn_dilation[i], cnn_groups = base_cnn_groups[i], cnn_bias = base_cnn_bias[i],\n",
        "                                      # Transformer parameters\n",
        "                                      encoder_output_size = encoder_output_size, seq_type = base_seq_type[i],\n",
        "                                      transformer_embedding_type = base_transformer_embedding_type[i], transformer_embedding_bias = base_transformer_embedding_bias[i], transformer_embedding_activation = base_transformer_embedding_activation[i],\n",
        "                                      transformer_embedding_weight_reg = base_transformer_embedding_weight_reg[i], transformer_embedding_weight_norm = base_transformer_embedding_weight_norm[i], transformer_embedding_dropout_p = base_transformer_embedding_dropout_p[i],\n",
        "                                      transformer_positional_encoding_type = base_transformer_positional_encoding_type[i],\n",
        "                                      transformer_dropout1_p = base_transformer_dropout1_p[i], transformer_dropout2_p = base_transformer_dropout2_p[i], transformer_dropout3_p = base_transformer_dropout3_p[i],\n",
        "                                      transformer_linear1_bias = base_transformer_linear1_bias[i], transformer_linear2_bias = base_transformer_linear2_bias[i],\n",
        "                                      transformer_linear1_weight_reg = base_transformer_linear1_weight_reg[i], transformer_linear1_weight_norm = base_transformer_linear1_weight_norm[i],\n",
        "                                      transformer_linear2_weight_reg = base_transformer_linear2_weight_reg[i], transformer_linear2_weight_norm = base_transformer_linear2_weight_norm[i],\n",
        "                                      transformer_feedforward_activation = base_transformer_feedforward_activation[i],\n",
        "                                      transformer_feedforward_degree = base_transformer_feedforward_degree[i], transformer_coef_init = base_transformer_coef_init[i], transformer_coef_train = base_transformer_coef_train[i], transformer_coef_reg = base_transformer_coef_reg[i], transformer_zero_order = base_transformer_zero_order[i],\n",
        "                                      transformer_scale_self_attn_residual_connection = base_transformer_scale_self_attn_residual_connection[i],\n",
        "                                      transformer_scale_cross_attn_residual_connection = base_transformer_scale_cross_attn_residual_connection[i],\n",
        "                                      transformer_scale_feedforward_residual_connection = base_transformer_scale_feedforward_residual_connection[i],\n",
        "                                      transformer_layer_norm = base_transformer_layer_norm[i],\n",
        "                                      # attention parameters\n",
        "                                      num_heads = base_num_heads[i], transformer_dim_feedforward = base_transformer_dim_feedforward[i],\n",
        "                                      self_attn_type = base_self_attn_type[i], multihead_attn_type = base_multihead_attn_type[i],\n",
        "                                      memory_is_causal = base_memory_is_causal[i], tgt_is_causal = base_tgt_is_causal[i],\n",
        "                                      query_dim = base_query_dim[i], key_dim = base_key_dim[i], value_dim = base_value_dim[i],\n",
        "                                      query_weight_reg = base_query_weight_reg[i], query_weight_norm = base_query_weight_norm[i], query_bias = base_query_bias[i],\n",
        "                                      key_weight_reg = base_key_weight_reg[i], key_weight_norm = base_key_weight_norm[i], key_bias = base_key_bias[i],\n",
        "                                      value_weight_reg = base_value_weight_reg[i], value_weight_norm = base_value_weight_norm[i], value_bias = base_value_bias[i],\n",
        "                                      gen_weight_reg = base_gen_weight_reg[i], gen_weight_norm = base_gen_weight_norm[i], gen_bias = base_gen_bias[i],\n",
        "                                      concat_weight_reg = base_concat_weight_reg[i], concat_weight_norm = base_concat_weight_norm[i], concat_bias = base_concat_bias[i],\n",
        "                                      attn_dropout_p = base_attn_dropout_p[i],\n",
        "                                      average_attn_weights = base_average_attn_weights[i],\n",
        "                                      # always batch first\n",
        "                                      batch_first = True,\n",
        "                                      #\n",
        "                                      device = device, dtype = dtype)\n",
        "\n",
        "      seq_base.append(seq_base_i)\n",
        "      #\n",
        "\n",
        "      # input-associated hidden layer\n",
        "      if hidden_out_features[i] > 0:\n",
        "        if base_hidden_size[i] > 0:\n",
        "          if base_type[i] == 'lru':\n",
        "            hidden_in_features_i = base_hidden_size[i]*len(base_relax_init[i])\n",
        "          elif base_type[i] in ['gru', 'lstm']:\n",
        "            hidden_in_features_i = base_hidden_size[i]*(1+base_rnn_bidirectional[i])\n",
        "          else:\n",
        "            hidden_in_features_i = base_hidden_size[i]\n",
        "        else:\n",
        "          input_size = input_size[i]\n",
        "\n",
        "        hidden_layer_i = HiddenLayer(# linear transformation\n",
        "                                     in_features = hidden_in_features_i, out_features = hidden_out_features[i],\n",
        "                                     bias = hidden_bias[i],\n",
        "                                     # activation\n",
        "                                     activation = hidden_activation[i],\n",
        "                                     # polynomial parameters\n",
        "                                     degree = hidden_degree[i],\n",
        "                                     coef_init = hidden_coef_init[i], coef_train = hidden_coef_train[i], coef_reg = hidden_coef_reg[i],\n",
        "                                     zero_order = hidden_zero_order[i],\n",
        "                                     # softmax parameter\n",
        "                                     softmax_dim = hidden_softmax_dim[i],\n",
        "                                     dropout_p = hidden_dropout_p[i],\n",
        "                                     device = device, dtype = dtype)\n",
        "      else:\n",
        "        hidden_layer_i = torch.nn.Identity()\n",
        "\n",
        "      hidden_layer.append(hidden_layer_i)\n",
        "      #\n",
        "\n",
        "    # interaction layer\n",
        "    if interaction_out_features > 0:\n",
        "      if np.sum(hidden_out_features) > 0:\n",
        "        interaction_in_features = int(np.sum(hidden_out_features))\n",
        "      else:\n",
        "        interaction_in_features = 0\n",
        "        for i in range(num_inputs):\n",
        "          interaction_in_features += base_hidden_size[i]*(1+base_rnn_bidirectional[i])\n",
        "        else:\n",
        "          interaction_in_features += base_transformer_dim_feedforward[i]\n",
        "\n",
        "      interaction_layer = HiddenLayer(# linear transformation\n",
        "                                      in_features = interaction_in_features, out_features = interaction_out_features,\n",
        "                                      bias = interaction_bias,\n",
        "                                      # activation\n",
        "                                      activation = interaction_activation,\n",
        "                                      # polynomial parameters\n",
        "                                      degree = interaction_degree,\n",
        "                                      coef_init = interaction_coef_init, coef_train = interaction_coef_train, coef_reg = interaction_coef_reg,\n",
        "                                      zero_order = interaction_zero_order,\n",
        "                                      # softmax parameter\n",
        "                                      softmax_dim = interaction_softmax_dim,\n",
        "                                      dropout_p = interaction_dropout_p,\n",
        "                                      device = device, dtype = dtype)\n",
        "    else:\n",
        "      interaction_layer = torch.nn.Identity()\n",
        "\n",
        "    # modulation layer\n",
        "    if interaction_in_features > 0:\n",
        "      modulation_in_features = interaction_out_features\n",
        "    elif np.sum(hidden_out_features) > 0:\n",
        "      modulation_in_features = np.sum(hidden_out_features)\n",
        "    else:\n",
        "      modulation_in_features = 0\n",
        "      for i in range(num_inputs):\n",
        "        modulation_in_features += base_hidden_size[i]*(1+base_rnn_bidirectional[i])\n",
        "      else:\n",
        "        modulation_in_features += base_transformer_dim_feedforward[i]\n",
        "\n",
        "    modulation_layer = ModulationLayer(window_len = modulation_window_len,\n",
        "                                       in_features = modulation_in_features,\n",
        "                                       associated = modulation_associated,\n",
        "                                       legendre_degree = modulation_legendre_degree,\n",
        "                                       chebychev_degree = modulation_chebychev_degree,\n",
        "                                       dt = dt,\n",
        "                                       num_freqs = modulation_num_freqs, freq_init = modulation_freq_init,  freq_train = modulation_freq_init,\n",
        "                                       phase_init = modulation_phase_init, phase_train = modulation_phase_train,\n",
        "                                       num_sigmoids = modulation_num_sigmoids,\n",
        "                                       slope_init = modulation_slope_init, slope_train = modulation_slope_train,\n",
        "                                       shift_init = modulation_shift_init, shift_train=  modulation_shift_init,\n",
        "                                       weight_reg = modulation_weight_reg, weight_norm = modulation_weight_norm,\n",
        "                                       zero_order = modulation_zero_order,\n",
        "                                       bias = modulation_bias, pure = modulation_pure,\n",
        "                                       device = device, dtype = dtype)\n",
        "    #\n",
        "\n",
        "    # output layer\n",
        "    output_layer = torch.nn.ModuleList([])\n",
        "    for i in range(num_outputs):\n",
        "      if modulation_layer is not None:\n",
        "        output_input_size_i = modulation_layer.num_modulators\n",
        "      elif interaction_out_features > 0:\n",
        "        output_input_size_i = interaction_out_features\n",
        "      elif np.sum(hidden_out_features) > 0:\n",
        "        if output_associated[i]:\n",
        "          output_input_size_i = hidden_out_features[i]\n",
        "        else:\n",
        "          output_input_size_i = int(np.sum(hidden_out_features))\n",
        "      else:\n",
        "        if output_associated[i]:\n",
        "          if base_type[i] in ['gru', 'lstm', 'lru']:\n",
        "            output_input_size_i = base_hidden_size[i]*(1+base_rnn_bidirectional[i])\n",
        "          elif base_type[i] == 'transformer':\n",
        "            output_input_size_i = base_hidden_size[i]\n",
        "          else:\n",
        "            output_input_size_i = input_size[i]\n",
        "        else:\n",
        "          output_input_size_i = 0\n",
        "          for i in range(num_inputs):\n",
        "            if base_type[i] in ['gru', 'lstm', 'lru']:\n",
        "              output_input_size_i += int(base_hidden_size[i]*(1+base_rnn_bidirectional[i]))\n",
        "            elif base_type[i] == 'transformer':\n",
        "              output_input_size_i += base_hidden_size[i]\n",
        "            else:\n",
        "              output_input_size_i += input_size[i]\n",
        "\n",
        "      if output_size[i] > 0:\n",
        "        output_layer_i = HiddenLayer(# linear transformation\n",
        "                                     in_features = output_input_size_i, out_features = output_size[i],\n",
        "                                     bias = output_bias[i],\n",
        "                                     # activation\n",
        "                                     activation = output_activation[i],\n",
        "                                     # polynomial parameters\n",
        "                                     degree = output_degree[i],\n",
        "                                     coef_init = output_coef_init[i], coef_train = output_coef_train[i], coef_reg = output_coef_reg[i],\n",
        "                                     zero_order = output_zero_order[i],\n",
        "                                     # softmax parameter\n",
        "                                     softmax_dim = output_softmax_dim[i],\n",
        "                                     dropout_p = output_dropout_p[i],\n",
        "                                     device = device, dtype = dtype)\n",
        "      else:\n",
        "        output_layer_i = torch.nn.Identity()\n",
        "        if np.sum(hidden_out_features) > 0:\n",
        "          output_size[i] = hidden_out_features[i]\n",
        "        elif interaction_out_features > 0:\n",
        "          output_size[i] = interaction_out_features\n",
        "        elif output_associated[i]:\n",
        "          output_size[i] = base_hidden_size[i]*(1 + base_rnn_bidirectional[i])\n",
        "        else:\n",
        "          output_size[i] = int(np.sum(np.array(base_hidden_size)*(1+np.array(base_rnn_bidirectional))))\n",
        "\n",
        "      output_layer.append(output_layer_i)\n",
        "\n",
        "    self.num_inputs,self.num_outputs = num_inputs, num_outputs\n",
        "    self.input_size, self.output_size = input_size, output_size\n",
        "\n",
        "    self.stateful = stateful\n",
        "    self.seq_base, self.base_hidden_size, self.base_type = seq_base, base_hidden_size, base_type\n",
        "    self.base_constrain, self.base_penalize = base_constrain, base_penalize\n",
        "\n",
        "    self.hidden_layer, self.hidden_out_features = hidden_layer, hidden_out_features\n",
        "    self.hidden_constrain, self.hidden_penalize = hidden_constrain, hidden_penalize\n",
        "\n",
        "    self.interaction_layer, self.interaction_out_features = interaction_layer, interaction_out_features\n",
        "    self.interaction_constrain, self.interaction_penalize = interaction_constrain, interaction_penalize\n",
        "\n",
        "    self.modulation_layer = modulation_layer\n",
        "\n",
        "    self.output_layer = output_layer\n",
        "    self.output_associated = output_associated\n",
        "    self.output_constrain, self.output_penalize = output_constrain, output_penalize\n",
        "\n",
        "    self.device, self.dtype = device, dtype\n",
        "\n",
        "  def __repr__(self):\n",
        "    total_num_params = 0\n",
        "    total_num_trainable_params = 0\n",
        "    lines = []\n",
        "    for name, param in self.named_parameters():\n",
        "      trainable = 'Trainable' if param.requires_grad else 'Untrainable'\n",
        "      lines.append(f\"{name}: shape = {param.shape}. {param.numel()} parameters. {trainable}\")\n",
        "      total_num_params += param.numel()\n",
        "      if param.requires_grad: total_num_trainable_params += param.numel()\n",
        "\n",
        "    lines.append(\"-------------------------------------\")\n",
        "    lines.append(f\"{total_num_params} total parameters.\")\n",
        "    lines.append(f\"{total_num_trainable_params} total trainable parameters.\")\n",
        "\n",
        "    return '\\n'.join(lines)\n",
        "\n",
        "  def init_hiddens(self):\n",
        "    return [None for _ in range(self.num_inputs)]\n",
        "\n",
        "  def process(self,\n",
        "              input, hiddens,\n",
        "              steps = None,\n",
        "              encoder_output = None):\n",
        "\n",
        "    # Get the dimensions of the input\n",
        "    num_samples, input_len, input_size = input.shape\n",
        "\n",
        "    # List to store the output of hidden layers\n",
        "    hidden_output = []\n",
        "\n",
        "    # Process each input in the batch individually\n",
        "    for i,input_i in enumerate(input.split(self.input_size, -1)):\n",
        "\n",
        "      # Generate output and hiddens of sequence base for the ith input\n",
        "      base_output_i, hiddens[i] = self.seq_base[i](input = input_i[:, -1:] \\\n",
        "                                                   if (self.seq_base[i].base_type in ['gru','lstm','lru']) & (self.seq_base[i].seq_type == 'decoder') \\\n",
        "                                                   else input_i,\n",
        "                                                   hiddens = hiddens[i],\n",
        "                                                   encoder_output = encoder_output)\n",
        "\n",
        "      base_output_i = torch.nn.functional.pad(base_output_i,\n",
        "                                              (0, 0, np.max([0, base_output_i.shape[1]-input_len]), 0),\n",
        "                                              \"constant\", 0)\n",
        "\n",
        "      # Generate hidden layer outputs for ith input, append result to previous hidden layer output of previous inputs\n",
        "      hidden_output_i = self.hidden_layer[i](base_output_i)\n",
        "      hidden_output.append(hidden_output_i)\n",
        "\n",
        "    hidden_output = torch.cat(hidden_output,-1)\n",
        "\n",
        "    interaction_output = self.interaction_layer(hidden_output)\n",
        "\n",
        "    modulation_output = self.modulation_layer(interaction_output)\n",
        "\n",
        "    # For each output\n",
        "    output = []\n",
        "    for i in range(self.num_outputs):\n",
        "      # If ith output layer is \"associated\" (linked to a single input)\n",
        "      if self.output_associated[i]:\n",
        "        # Set the output of the ith hidden layer as input to the ith output layer\n",
        "        output_input_i = hidden_output[i]\n",
        "      # Otherwise, pass the entire output of previous layer as the input to the ith output layer\n",
        "      else:\n",
        "        output_input_i = modulation_output\n",
        "\n",
        "      # Generate output of ith output layer, append result to previous outputs\n",
        "      output_i = self.output_layer[i](output_input_i)\n",
        "      output.append(output_i)\n",
        "\n",
        "    # Concatenate outputs into single tensor\n",
        "    output = torch.cat(output, -1)\n",
        "\n",
        "    # Apply modulation layer\n",
        "    if self.modulation_layer is not None:\n",
        "      output = self.modulation_layer(output, steps)\n",
        "\n",
        "    return output, hiddens\n",
        "\n",
        "  def forward(self,\n",
        "              input, steps = None,\n",
        "              hiddens = None,\n",
        "              target = None,\n",
        "              output_window_idx = None,\n",
        "              input_mask = None, output_mask = None,\n",
        "              output_input_idx = None, input_output_idx = None,\n",
        "              encoder_output= None):\n",
        "\n",
        "    # Convert inputs to the correct device\n",
        "    input = input.to(device = self.device)\n",
        "    steps = steps.to(device = self.device) if steps is not None else None\n",
        "    output_mask = output_mask.to(device =  self.device) if output_mask is not None else None\n",
        "\n",
        "    # Get the dimensions of the input\n",
        "    num_samples, input_len, input_size = input.shape\n",
        "\n",
        "    # Get total number of steps\n",
        "    if steps is not None:\n",
        "      _, num_steps = steps.shape\n",
        "\n",
        "    # Get the maximum output sequence length\n",
        "    max_output_len = np.max([len(idx) for idx in output_window_idx]) if output_window_idx is not None else input_len\n",
        "\n",
        "    # Get the total output size\n",
        "    total_output_size = np.sum(self.output_size)\n",
        "\n",
        "    # Initiate hiddens if None or not stateful\n",
        "    if (hiddens is None) | (not self.stateful) & any(type_ in ['gru', 'lstm', 'lru'] for type_ in self.base_type):\n",
        "      hiddens = hiddens or self.init_hiddens()\n",
        "\n",
        "    # Process output and updated hiddens\n",
        "    if 'encoder' in [base.seq_type for base in self.seq_base]: # model is an encoder\n",
        "      output, hiddens = self.process(input = input,\n",
        "                                     steps = steps,\n",
        "                                     hiddens = hiddens,\n",
        "                                     encoder_output = encoder_output)\n",
        "    else: # model is a decoder\n",
        "\n",
        "      # Prepare input for the next step\n",
        "      input_, output = input, []\n",
        "      for n in range(max_output_len):\n",
        "        output_, hiddens = self.process(input = input_.clone()[:, :(n+1)],\n",
        "                                        steps = steps[:, :(n+1)] if steps is not None else None,\n",
        "                                        hiddens = hiddens,\n",
        "                                        encoder_output = encoder_output)\n",
        "\n",
        "        output.append(output_[:, -1:])\n",
        "\n",
        "        if (len(output_input_idx) > 0) & (n < (max_output_len-1)):\n",
        "          input_[:, (n+1):(n+2), output_input_idx] = target[:, n:(n+1), input_output_idx] if target is not None else output[-1][..., input_output_idx]\n",
        "\n",
        "      output = torch.cat(output, 1)\n",
        "\n",
        "    # Only keep the outputs for the maximum output sequence length\n",
        "    output = output[:, -max_output_len:]\n",
        "\n",
        "    # Apply the output mask if specified\n",
        "    if output_mask is not None: output = output*output_mask\n",
        "\n",
        "    return output, hiddens\n",
        "\n",
        "  def constrain(self):\n",
        "\n",
        "    for i in range(self.num_inputs):\n",
        "      if self.base_constrain[i]:\n",
        "        self.seq_base[i].constrain()\n",
        "\n",
        "      if self.hidden_constrain[i]:\n",
        "         self.hidden_layer[i].constrain()\n",
        "\n",
        "    if self.interaction_constrain:\n",
        "       self.interaction_layer.constrain()\n",
        "\n",
        "    for i in range(self.num_outputs):\n",
        "      if self.output_constrain[i]:\n",
        "         self.output_layer[i].constrain()\n",
        "\n",
        "  def penalize(self):\n",
        "    loss = 0\n",
        "\n",
        "    for i in range(self.num_inputs):\n",
        "      if self.base_penalize[i]:\n",
        "        loss += self.seq_base[i].penalize()\n",
        "\n",
        "    if self.hidden_penalize[i]:\n",
        "      loss += self.hidden_layer[i].penalize()\n",
        "\n",
        "    if self.interaction_penalize:\n",
        "      loss += self.interaction_layer.penalize()\n",
        "\n",
        "    for i in range(self.num_outputs):\n",
        "      if self.output_penalize[i]:\n",
        "        loss += self.output_layer[i].penalize()\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def generate_impulse_response(self, seq_len):\n",
        "    with torch.no_grad():\n",
        "      impulse_response = [None for _ in range(self.model.num_inputs)]\n",
        "      for i in range(self.model.num_inputs):\n",
        "        # if self.model.base_type[i] in ['gru', 'lstm', 'lru']:\n",
        "        impulse_response[i] = [None for _ in range(self.model.input_size[i])]\n",
        "        for f in range(self.model.input_size[i]):\n",
        "          impulse_i = torch.zeros((1, seq_len, self.model.input_size[i])).to(device = self.model.device,\n",
        "                                                                                  dtype = self.model.dtype)\n",
        "          impulse_i[0, 0, f] = 1.\n",
        "\n",
        "          base_output_if, _ = self.model.seq_base[i](input = impulse_i)\n",
        "\n",
        "          weight = self.model.hidden_layer[i].F[0].weight\n",
        "\n",
        "          impulse_response[i][f] = base_output_if.squeeze(0) @ weight.t()\n",
        "\n",
        "    return impulse_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RS4g6LsNg5R"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqModel(torch.nn.Module):\n",
        "  '''\n",
        "  Sequence-to-Sequence Model that consists of an encoder and a decoder.\n",
        "\n",
        "  Args:\n",
        "      encoder (torch.nn.Module): The encoder module.\n",
        "      decoder (torch.nn.Module): The decoder module.\n",
        "      learn_decoder_init_input (bool, optional): Whether to learn the decoder's initial input. Defaults to False.\n",
        "      learn_decoder_hiddens (bool, optional): Whether to learn the decoder's hidden states. Defaults to False.\n",
        "      enc2dec_bias (bool, optional): Whether to use bias in the encoder-to-decoder mappings. Defaults to True.\n",
        "      enc2dec_hiddens_bias (bool, optional): Whether to use bias in the encoder-to-decoder hidden state mappings. Defaults to True.\n",
        "      enc2dec_dropout_p (float, optional): Dropout probability for the encoder-to-decoder mappings. Defaults to 0.\n",
        "      enc2dec_hiddens_dropout_p (float, optional): Dropout probability for the encoder-to-decoder hidden state mappings. Defaults to 0.\n",
        "      device (str, optional): Device to run the model on (e.g., 'cpu', 'cuda'). Defaults to 'cpu'.\n",
        "      dtype (torch.dtype, optional): Data type of the model parameters. Defaults to torch.float32.\n",
        "  '''\n",
        "\n",
        "  def __init__(self,\n",
        "              encoder, decoder,\n",
        "              learn_decoder_init_input=False, learn_decoder_hiddens=False,\n",
        "              enc2dec_bias=True, enc2dec_hiddens_bias=True,\n",
        "              enc2dec_dropout_p=0., enc2dec_hiddens_dropout_p=0.,\n",
        "              device='cpu', dtype=torch.float32):\n",
        "\n",
        "    super(Seq2SeqModel, self).__init__()\n",
        "\n",
        "    enc2dec_init_input_block = None\n",
        "    if learn_decoder_init_input:\n",
        "      enc2dec_init_input_block = HiddenLayer(in_features=sum(encoder.input_size),\n",
        "                                              out_features=sum(decoder.input_size),\n",
        "                                              bias=enc2dec_bias,\n",
        "                                              activation='identity',\n",
        "                                              dropout_p=enc2dec_dropout_p,\n",
        "                                              device=device,\n",
        "                                              dtype=dtype)\n",
        "\n",
        "    enc2dec_hiddens_block = None\n",
        "    if learn_decoder_hiddens:\n",
        "      if any(type_ in ['gru', 'lstm', 'lru'] for type_ in encoder.base_type):\n",
        "        enc2dec_hiddens_input = 0\n",
        "        for i in range(encoder.num_inputs):\n",
        "          if encoder.base_type[i] in ['gru', 'lstm', 'lru']:\n",
        "              enc2dec_hiddens_input += (1 + int(encoder.base_type[i] == 'lstm')) * encoder.base_hidden_size[i] * (1 + int(encoder.base_rnn_bidirectional[i]))\n",
        "      else:\n",
        "          enc2dec_hiddens_input = sum(encoder.output_size)\n",
        "\n",
        "      enc2dec_hiddens_output = sum(np.array([1 + int(type_ == 'lstm') for type_ in decoder.base_type]) * np.array(decoder.base_hidden_size) * np.array([1 + int(bd) for bd in decoder.base_rnn_bidirectional]))\n",
        "\n",
        "      enc2dec_hiddens_block = HiddenLayer(in_features=enc2dec_hiddens_input,\n",
        "                                          out_features=enc2dec_hiddens_output,\n",
        "                                          bias=enc2dec_hiddens_bias,\n",
        "                                          activation='identity',\n",
        "                                          dropout_p=enc2dec_hiddens_dropout_p,\n",
        "                                          device=device,\n",
        "                                          dtype=dtype)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "    self.num_inputs = encoder.num_inputs\n",
        "    self.num_outputs = decoder.num_outputs\n",
        "    self.input_size = encoder.input_size\n",
        "    self.output_size = decoder.output_size\n",
        "    self.base_type = encoder.base_type\n",
        "    self.enc2dec_init_input_block = enc2dec_init_input_block\n",
        "    self.enc2dec_hiddens_block = enc2dec_hiddens_block\n",
        "    self.device = device\n",
        "    self.dtype = dtype\n",
        "\n",
        "  def forward(self,\n",
        "              input,\n",
        "              steps=None,\n",
        "              hiddens=None,\n",
        "              input_mask=None, output_mask=None,\n",
        "              output_input_idx=[], input_output_idx=[],\n",
        "              encoder_output=None,\n",
        "              target=None,\n",
        "              output_window_idx=None):\n",
        "\n",
        "    '''\n",
        "    Forward pass of the Seq2SeqModel.\n",
        "\n",
        "    Args:\n",
        "        input (torch.Tensor): Input tensor of shape (num_samples, input_len, input_size).\n",
        "        steps (torch.Tensor, optional): Tensor indicating the number of steps to process for each sample. Shape: (num_samples, input_len). Defaults to None.\n",
        "        hiddens (list, optional): List of initial hidden states for the encoder. Defaults to None.\n",
        "        input_mask (torch.Tensor, optional): Mask tensor for the input. Shape: (num_samples, input_len). Defaults to None.\n",
        "        output_mask (torch.Tensor, optional): Mask tensor for the output. Shape: (num_samples, output_len). Defaults to None.\n",
        "        output_input_idx (list, optional): List of indices indicating which inputs are used as inputs to the decoder. Defaults to [].\n",
        "        input_output_idx (list, optional): List of indices indicating which inputs are used as outputs from the encoder. Defaults to [].\n",
        "        encoder_output (torch.Tensor, optional): Output tensor from the encoder. Shape: (num_samples, input_len, encoder_output_size). Defaults to None.\n",
        "        target (torch.Tensor, optional): Target tensor. Shape: (num_samples, output_len, output_size). Defaults to None.\n",
        "        output_window_idx (list, optional): List of indices indicating which outputs are used for the output window. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Decoder output tensor of shape (num_samples, output_len, output_size).\n",
        "        list: List of hidden states after the encoder.\n",
        "    '''\n",
        "\n",
        "    num_samples, input_len, input_size = input.shape\n",
        "\n",
        "    encoder_steps = steps[:, :input_len] if steps is not None else None\n",
        "    decoder_steps = steps[:, (input_len - 1):] if steps is not None else None\n",
        "\n",
        "    encoder_output, encoder_hiddens = self.encoder(input=input,\n",
        "                                                   steps=encoder_steps,\n",
        "                                                   hiddens=hiddens,\n",
        "                                                   input_mask=input_mask)\n",
        "\n",
        "    hiddens = encoder_hiddens\n",
        "\n",
        "    decoder_hiddens = [None for _ in range(self.decoder.num_inputs)]\n",
        "    if self.enc2dec_hiddens_block is not None:\n",
        "      # If the enc2dec_hiddens_block exists (decoder must contain rnn's)\n",
        "      if encoder_hiddens is not None:\n",
        "        # If there are rnn hidens\n",
        "        enc2dec_hiddens_input = torch.cat([eh.reshape(num_samples, 1, -1) for eh in encoder_hiddens if eh is not None],-1)\n",
        "      else:\n",
        "          enc2dec_hiddens_input = encoder_output\n",
        "\n",
        "      enc2dec_hiddens_output = self.enc2dec_hiddens_block(enc2dec_hiddens_input)\n",
        "\n",
        "      j = 0\n",
        "      for i in range(self.decoder.num_inputs):\n",
        "          if self.decoder.base_type in ['gru', 'lstm', 'lru']:\n",
        "              total_base_hidden_size_i = ((1 + self.decoder.base_type[i]) * self.decoder.base_hidden_size[i] *  (1 + self.decoder.rnn_bidirectional[i]))\n",
        "              decoder_hiddens_i = enc2dec_hiddens_output[..., j:(j + total_base_hidden_size_i)].split( total_base_hidden_size_i, 2)\n",
        "              decoder_hiddens[i] = decoder_hiddens_i[0] if self.base_type[i] != 'lstm' else decoder_hiddens_i\n",
        "              j += total_base_hidden_size_i\n",
        "    else:\n",
        "      decoder_hiddens = encoder_hiddens\n",
        "\n",
        "    max_output_len = np.max([base.seq_len for base in self.decoder.seq_base])\n",
        "\n",
        "    decoder_init_input = self.enc2dec_init_input_block(input[:, -1:]) if self.enc2dec_init_input_block is not None else input[:, -1:]\n",
        "\n",
        "    decoder_init_input = torch.nn.functional.pad(decoder_init_input, (0, 0, 0, max_output_len - 1), \"constant\", 0)\n",
        "\n",
        "    decoder_output, _ = self.decoder(input=decoder_init_input,\n",
        "                                      steps=decoder_steps,\n",
        "                                      hiddens=decoder_hiddens,\n",
        "                                      target=target,\n",
        "                                      output_window_idx=output_window_idx,\n",
        "                                      output_mask=output_mask,\n",
        "                                      output_input_idx=output_input_idx,\n",
        "                                      input_output_idx=input_output_idx,\n",
        "                                      encoder_output=encoder_output)\n",
        "\n",
        "    return decoder_output, hiddens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcKzhc0Jgs1h"
      },
      "outputs": [],
      "source": [
        "class Embedding(torch.nn.Module):\n",
        "    '''\n",
        "    Embedding layer that maps input tokens to continuous vectors.\n",
        "\n",
        "    Args:\n",
        "        num_embeddings (int): Number of unique tokens in the input vocabulary.\n",
        "        embedding_dim (int): Dimensionality of the embedding vectors.\n",
        "        embedding_type (str, optional): Type of embedding to use. Supported types: 'time', 'category'.\n",
        "                                        Defaults to 'time'.\n",
        "        bias (bool, optional): Whether to include a bias term in the embedding layer. Defaults to False.\n",
        "        activation (str, optional): Activation function to apply to the embedding. Defaults to 'identity'.\n",
        "        weight_reg (List[float], optional): Regularization terms for the embedding weights.\n",
        "                                             Defaults to [0.001, 1].\n",
        "        weight_norm (float, optional): Order of the normalization applied to the embedding weights.\n",
        "                                       Defaults to 2.\n",
        "        dropout_p (float, optional): Dropout probability to apply to the embedding layer. Defaults to 0.0.\n",
        "        device (str, optional): Device on which the embedding layer is allocated. Defaults to 'cpu'.\n",
        "        dtype (torch.dtype, optional): Data type of the embedding layer. Defaults to torch.float32.\n",
        "    '''\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_embeddings, embedding_dim, embedding_type='time',\n",
        "                 bias=False, activation='identity',\n",
        "                 weight_reg=[0.001, 1], weight_norm=2,\n",
        "                 dropout_p=0.0,\n",
        "                 device='cpu', dtype=torch.float32):\n",
        "      super(Embedding, self).__init__()\n",
        "\n",
        "      # Check the type of embedding\n",
        "      if embedding_type == 'time':\n",
        "          # Time-based embedding using HiddenLayer\n",
        "          embedding = HiddenLayer(in_features=num_embeddings,\n",
        "                                  out_features=embedding_dim,\n",
        "                                  bias=bias,\n",
        "                                  activation=activation,\n",
        "                                  weight_reg=weight_reg, weight_norm=weight_norm,\n",
        "                                  dropout_p=dropout_p,\n",
        "                                  device=device, dtype=dtype)\n",
        "      elif embedding_type == 'category':\n",
        "          # Category-based embedding using torch.nn.Embedding\n",
        "          embedding = torch.nn.Embedding(num_embeddings, embedding_dim)\n",
        "      else:\n",
        "          raise ValueError(f\"Unsupported embedding type: {embedding_type}\")\n",
        "\n",
        "      self.embedding = embedding\n",
        "      self.embedding_type = embedding_type\n",
        "\n",
        "    def forward(self, input, input_mask=None):\n",
        "      '''\n",
        "      Forward pass of the embedding layer.\n",
        "\n",
        "      Args:\n",
        "          input (torch.Tensor): Input tensor of shape (batch_size, sequence_length).\n",
        "          input_mask (torch.Tensor): Input mask tensor of shape (batch_size, sequence_length)\n",
        "                                      or None if no mask is applied.\n",
        "\n",
        "      Returns:\n",
        "          torch.Tensor: Embedded input tensor of shape (batch_size, sequence_length, embedding_dim).\n",
        "      '''\n",
        "\n",
        "      # Apply input mask if provided\n",
        "      input = input*input_mask if input_mask is not None else input\n",
        "\n",
        "      # Embed the input\n",
        "      input_embedding = self.embedding(input)\n",
        "\n",
        "      return input_embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiQJEvk1KoZf"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(torch.nn.Module):\n",
        "  '''\n",
        "  Positional encoding layer that adds positional information to the input.\n",
        "\n",
        "  Args:\n",
        "    dim (int): Dimensionality of the input.\n",
        "    seq_len (int): Length of the input sequence.\n",
        "    encoding_type (str, optional): Type of positional encoding to use. Supported types: 'absolute', 'relative'.\n",
        "                                    Defaults to 'absolute'.\n",
        "    device (str, optional): Device on which the positional encoding layer is allocated. Defaults to 'cpu'.\n",
        "    dtype (torch.dtype, optional): Data type of the positional encoding layer. Defaults to torch.float32.\n",
        "  '''\n",
        "\n",
        "  def __init__(self,\n",
        "                dim, seq_len, encoding_type='absolute',\n",
        "                device='cpu', dtype=torch.float32):\n",
        "      super(PositionalEncoding, self).__init__()\n",
        "\n",
        "      self.dim, self.seq_len = dim, seq_len\n",
        "      self.encoding_type = encoding_type\n",
        "      self.device, self.dtype = device, dtype\n",
        "\n",
        "      self.positional_encoding = self.generate_positional_encoding()\n",
        "\n",
        "  def generate_positional_encoding(self):\n",
        "      '''\n",
        "      Generates the positional encoding based on the encoding type.\n",
        "\n",
        "      Returns:\n",
        "        torch.Tensor: Positional encoding tensor of shape (seq_len, dim).\n",
        "      '''\n",
        "\n",
        "      position = torch.arange(self.seq_len).unsqueeze(1).to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "      if self.encoding_type == 'absolute':\n",
        "          positional_encoding = torch.zeros((self.seq_len, self.dim)).to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "          scaler = torch.exp(torch.arange(0, self.dim, 2) * -(torch.math.log(10000.0) / self.dim)).to(\n",
        "              device=self.device, dtype=self.dtype)\n",
        "\n",
        "          positional_encoding[:, 0::2] = torch.sin((position) * scaler)\n",
        "          positional_encoding[:, 1::2] = torch.cos((position) * scaler)\n",
        "\n",
        "      elif self.encoding_type == 'relative':\n",
        "          positional_encoding = (position.repeat(1, self.dim) +\n",
        "                                  torch.arange(self.dim).reshape(1, -1).to(device=self.device, dtype=self.dtype)) / self.seq_len\n",
        "\n",
        "          positional_encoding = positional_encoding / positional_encoding.max()\n",
        "\n",
        "      return positional_encoding\n",
        "\n",
        "  def forward(self, input):\n",
        "      '''\n",
        "      Forward pass of the positional encoding layer.\n",
        "\n",
        "      Args:\n",
        "        input (torch.Tensor): Input tensor of shape (batch_size, seq_len, dim).\n",
        "\n",
        "      Returns:\n",
        "        torch.Tensor: Input tensor with added positional encoding of shape (batch_size, seq_len, dim).\n",
        "      '''\n",
        "\n",
        "      return input + self.positional_encoding[:input.shape[1], :]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Od6RS-5Byaff"
      },
      "outputs": [],
      "source": [
        "class SequenceDataset(torch.utils.data.Dataset):\n",
        "  '''\n",
        "  Dataset class for sequence data.\n",
        "\n",
        "  Args:\n",
        "      data (dict): Dictionary containing input and output data.\n",
        "      input_names (list): Names of the input data.\n",
        "      output_names (list): Names of the output data.\n",
        "      step_name (str): Name of the step data.\n",
        "      input_len (list): List of input sequence lengths. If a single value is provided, it is replicated for all inputs.\n",
        "      output_len (list): List of output sequence lengths. If a single value is provided, it is replicated for all outputs.\n",
        "      shift (list): List of output shifts. If a single value is provided, it is replicated for all outputs.\n",
        "      stride (int): Stride value.\n",
        "      init_input (torch.Tensor or None): Initial input for padding. Defaults to None.\n",
        "      print_summary (bool): Whether to print summary information. Defaults to False.\n",
        "      device (str): Device on which the dataset is allocated. Defaults to 'cpu'.\n",
        "      dtype (torch.dtype): Data type of the dataset. Defaults to torch.float32.\n",
        "  '''\n",
        "\n",
        "  def __init__(self,\n",
        "                data: dict,\n",
        "                input_names, output_names, step_name='steps',\n",
        "                input_len=[1], output_len=[1], shift=[0], stride=1,\n",
        "                init_input=None,\n",
        "                print_summary=False,\n",
        "                device='cpu', dtype=torch.float32):\n",
        "\n",
        "    num_inputs, num_outputs = len(input_names), len(output_names)\n",
        "\n",
        "    if len(input_len) == 1:\n",
        "        input_len = input_len * num_inputs\n",
        "\n",
        "    if len(output_len) == 1:\n",
        "        output_len = output_len * num_outputs\n",
        "    if len(shift) == 1:\n",
        "        shift = shift * num_outputs\n",
        "\n",
        "    data_len = data[input_names[0]].shape[0]\n",
        "\n",
        "    input_len = [data_len if len == -1 else len for len in input_len]\n",
        "    output_len = [np.max(input_len) if len == -1 else len for len in output_len]\n",
        "\n",
        "    input_size = [data[name].shape[-1] for name in input_names]\n",
        "    output_size = [data[name].shape[-1] for name in output_names]\n",
        "\n",
        "    max_input_len = np.max(input_len)\n",
        "    max_output_len = np.max(output_len)\n",
        "    max_shift = np.max(shift)\n",
        "\n",
        "    has_ar = np.isin(output_names, input_names).any()\n",
        "\n",
        "    input_window_idx = []\n",
        "    for i in range(num_inputs):\n",
        "      input_window_idx.append(torch.arange(max_input_len - input_len[i], max_input_len).to(device=device,\n",
        "                                                                                              dtype=torch.long))\n",
        "\n",
        "    output_window_idx = []\n",
        "    for i in range(num_outputs):\n",
        "      output_window_idx_i = torch.arange(max_input_len - output_len[i], max_input_len).to(device=device,\n",
        "                                                                                          dtype=torch.long) + shift[i]\n",
        "      output_window_idx.append(output_window_idx_i)\n",
        "\n",
        "    total_window_size = torch.cat(output_window_idx).max().item() + 1\n",
        "    total_window_idx = torch.arange(total_window_size).to(device=device, dtype=torch.long)\n",
        "\n",
        "    start_step = max_input_len - max_output_len + max_shift + int(has_ar)\n",
        "\n",
        "    if print_summary:\n",
        "      print('\\n'.join([f'Data length: {data_len}',\n",
        "                        f'Window size: {total_window_size}',\n",
        "                        f'Step indices: {total_window_idx.tolist()}',\n",
        "                        '\\n'.join([f'Input indices for {input_names[i]}: {input_window_idx[i].tolist()}' for i in\n",
        "                                  range(num_inputs)]),\n",
        "                        '\\n'.join(\n",
        "                            [f'Output indices for {output_names[i]}: {output_window_idx[i].tolist()}' for i in\n",
        "                            range(num_outputs)])]))\n",
        "\n",
        "    self.data = data\n",
        "    self.input_names, self.output_names, self.step_name = input_names, output_names, step_name\n",
        "    self.has_ar = has_ar\n",
        "    self.data_len = data_len\n",
        "    self.num_inputs, self.num_outputs = num_inputs, num_outputs\n",
        "    self.input_size, self.output_size = input_size, output_size\n",
        "    self.start_step = start_step\n",
        "    self.shift, self.stride = shift, stride\n",
        "    self.total_window_size, self.total_window_idx = total_window_size, total_window_idx\n",
        "    self.input_len, self.input_window_idx = input_len, input_window_idx\n",
        "    self.output_len, self.output_window_idx = output_len, output_window_idx\n",
        "    self.init_input = init_input\n",
        "    self.device, self.dtype = device, dtype\n",
        "\n",
        "    self.input_samples, self.output_samples, self.steps_samples = self.get_samples()\n",
        "\n",
        "  def get_samples(self):\n",
        "    '''\n",
        "    Generates input, output, and steps samples for the dataset.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing input samples, output samples, and steps samples.\n",
        "    '''\n",
        "\n",
        "    input_samples, output_samples, steps_samples = [], [], []\n",
        "\n",
        "    unique_input_window_idx = torch.cat(self.input_window_idx).unique()\n",
        "    unique_output_window_idx = torch.cat(self.output_window_idx).unique()\n",
        "\n",
        "    max_input_len, max_output_len = np.max(self.input_len), np.max(self.output_len + self.shift)\n",
        "\n",
        "    min_output_idx = torch.cat(self.output_window_idx).min().item()\n",
        "\n",
        "    window_idx_n = self.total_window_idx\n",
        "\n",
        "    num_samples = 0\n",
        "    while window_idx_n.max() < self.data_len:\n",
        "        num_samples += 1\n",
        "\n",
        "        steps_samples.append(self.data[self.step_name][window_idx_n])\n",
        "\n",
        "        # input\n",
        "        input_n = torch.zeros((max_input_len, np.sum(self.input_size))).to(device=self.device,\n",
        "                                                                            dtype=self.dtype)\n",
        "\n",
        "        j = 0\n",
        "        for i in range(self.num_inputs):\n",
        "            input_window_idx_i = self.input_window_idx[i]\n",
        "\n",
        "            input_samples_window_idx_i = window_idx_n[input_window_idx_i] - int(\n",
        "                self.input_names[i] in self.output_names)\n",
        "\n",
        "            if (input_samples_window_idx_i[0] == -1) & (self.init_input is not None):\n",
        "                input_n[0, j:(j + self.input_size[i])] = self.init_input[j:(j + self.input_size[i])]\n",
        "\n",
        "            input_window_idx_i = input_window_idx_i[input_samples_window_idx_i >= 0]\n",
        "            input_samples_window_idx_i = input_samples_window_idx_i[input_samples_window_idx_i >= 0]\n",
        "\n",
        "            input_n[input_window_idx_i, j:(j + self.input_size[i])] = self.data[self.input_names[i]].clone()[\n",
        "                input_samples_window_idx_i]\n",
        "\n",
        "            j += self.input_size[i]\n",
        "\n",
        "        input_samples.append(input_n)\n",
        "\n",
        "        # output\n",
        "        output_n = torch.zeros((len(unique_output_window_idx), np.sum(self.output_size))).to(device=self.device,\n",
        "                                                                                              dtype=self.dtype)\n",
        "\n",
        "        j = 0\n",
        "        for i in range(self.num_outputs):\n",
        "            output_window_idx_i = self.output_window_idx[i]\n",
        "            output_samples_window_idx_i = window_idx_n[output_window_idx_i]\n",
        "\n",
        "            output_window_idx_j = output_window_idx_i - min_output_idx\n",
        "\n",
        "            output_n[output_window_idx_j, j:(j + self.output_size[i])] = self.data[self.output_names[i]].clone()[\n",
        "                output_samples_window_idx_i]\n",
        "\n",
        "            j += self.output_size[i]\n",
        "\n",
        "        output_samples.append(output_n)\n",
        "\n",
        "        window_idx_n = num_samples * self.stride + self.total_window_idx\n",
        "\n",
        "    input_samples = torch.stack(input_samples)\n",
        "    output_samples = torch.stack(output_samples)\n",
        "    steps_samples = torch.stack(steps_samples)\n",
        "\n",
        "    self.num_samples = num_samples\n",
        "\n",
        "    return input_samples, output_samples, steps_samples\n",
        "\n",
        "  def __len__(self):\n",
        "    '''\n",
        "    Returns the number of samples in the dataset.\n",
        "\n",
        "    Returns:\n",
        "        int: Number of samples in the dataset.\n",
        "    '''\n",
        "    return self.num_samples\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    '''\n",
        "    Returns a sample from the dataset at the given index.\n",
        "\n",
        "    Args:\n",
        "        idx (int): Index of the sample.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the input, output, and steps for the sample.\n",
        "    '''\n",
        "    return self.input_samples[idx], self.output_samples[idx], self.steps_samples[idx]\n",
        "\n",
        "\n",
        "class SequenceDataloader:\n",
        "  '''\n",
        "  Dataloader class for sequence data.\n",
        "\n",
        "  Args:\n",
        "      input_names (list): Names of the input data.\n",
        "      output_names (list): Names of the output data.\n",
        "      step_name (str): Name of the step data.\n",
        "      data (dict): Dictionary containing input and output data.\n",
        "      batch_size (int): Batch size. Defaults to 1.\n",
        "      input_len (list): List of input sequence lengths. If a single value is provided, it is replicated for all inputs.\n",
        "      output_len (list): List of output sequence lengths. If a single value is provided, it is replicated for all outputs.\n",
        "      shift (list): List of output shifts. If a single value is provided, it is replicated for all outputs.\n",
        "      stride (int): Stride value. Defaults to 1.\n",
        "      init_input (torch.Tensor or None): Initial input for padding. Defaults to None.\n",
        "      print_summary (bool): Whether to print summary information. Defaults to False.\n",
        "      device (str): Device on which the dataloader is allocated. Defaults to 'cpu'.\n",
        "      dtype (torch.dtype): Data type of the dataloader. Defaults to torch.float32.\n",
        "  '''\n",
        "\n",
        "  def __init__(self,\n",
        "                input_names, output_names, step_name,\n",
        "                data: dict,\n",
        "                batch_size=1,\n",
        "                input_len=[1], output_len=[1], shift=[0], stride=1,\n",
        "                init_input=None,\n",
        "                print_summary=False,\n",
        "                device='cpu', dtype=torch.float32):\n",
        "\n",
        "    self.data = data\n",
        "    self.batch_size = batch_size\n",
        "    self.input_names, self.output_names, self.step_name = input_names, output_names, step_name\n",
        "    self.input_len, self.output_len, self.shift, self.stride = input_len, output_len, shift, stride\n",
        "    self.init_input = init_input\n",
        "    self.print_summary = print_summary\n",
        "    self.device, self.dtype = device, dtype\n",
        "\n",
        "    self.dl = self.get_dataloader\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "    '''\n",
        "    Collate function for the dataloader.\n",
        "\n",
        "    Args:\n",
        "        batch (list): List of samples.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing input, output, steps, and batch size.\n",
        "    '''\n",
        "\n",
        "    input_samples, output_samples, steps_samples = zip(*batch)\n",
        "\n",
        "    batch_size = len(input_samples)\n",
        "\n",
        "    pad_fn = lambda x, fill_value: \\\n",
        "        x + tuple(\n",
        "            torch.full(x[0].shape, fill_value=fill_value).to(device=x[0].device, dtype=x[0].dtype)\n",
        "            if isinstance(x[0], torch.Tensor)\n",
        "            else np.full(x[0].shape, fill_value=fill_value)\n",
        "            for _ in range(self.batch_size - batch_size))\n",
        "\n",
        "    if batch_size % self.batch_size != 0:\n",
        "        input_samples = pad_fn(input_samples, 0)\n",
        "        output_samples = pad_fn(output_samples, 0)\n",
        "        steps_samples = pad_fn(steps_samples, -1)\n",
        "\n",
        "    input = torch.stack(input_samples)\n",
        "    output = torch.stack(output_samples)\n",
        "    steps = torch.stack(steps_samples)\n",
        "\n",
        "    return input, output, steps, batch_size\n",
        "\n",
        "  @property\n",
        "  def get_dataloader(self):\n",
        "    '''\n",
        "    Property function that returns the dataloader.\n",
        "\n",
        "    Returns:\n",
        "        torch.utils.data.DataLoader: DataLoader for the sequence dataset.\n",
        "    '''\n",
        "\n",
        "    if len(self.data) > 0:\n",
        "      ds = SequenceDataset(data=self.data,\n",
        "                            input_names=self.input_names, output_names=self.output_names,\n",
        "                            step_name=self.step_name,\n",
        "                            input_len=self.input_len, output_len=self.output_len,\n",
        "                            shift=self.shift, stride=self.stride,\n",
        "                            init_input=self.init_input,\n",
        "                            print_summary=self.print_summary,\n",
        "                            device=self.device, dtype=self.dtype)\n",
        "\n",
        "      self.batch_size = len(ds) if self.batch_size == -1 else self.batch_size\n",
        "\n",
        "      self.input_size, self.output_size = ds.input_size, ds.output_size\n",
        "      self.num_inputs, self.num_outputs = ds.num_inputs, ds.num_outputs\n",
        "      self.input_size, self.output_size = ds.input_size, ds.output_size\n",
        "      self.data_len, self.num_samples = ds.data_len, ds.num_samples\n",
        "      self.total_window_size, self.total_window_idx = ds.total_window_size, ds.total_window_idx\n",
        "      self.shift, self.stride = ds.shift, ds.stride\n",
        "      self.input_len, self.input_window_idx = ds.input_len, ds.input_window_idx\n",
        "      self.output_len, self.output_window_idx = ds.output_len, ds.output_window_idx\n",
        "\n",
        "      self.total_input_len, self.total_output_len = len(torch.cat(ds.input_window_idx, 0).unique()), len(\n",
        "          torch.cat(ds.output_window_idx, 0).unique())\n",
        "      self.unique_output_window_idx = torch.cat(ds.output_window_idx, 0).unique()\n",
        "\n",
        "      self.output_mask = torch.zeros((self.total_output_len, np.sum(self.output_size)), device=self.device,\n",
        "                                      dtype=self.dtype)\n",
        "      j = 0\n",
        "      for i in range(len(ds.output_window_idx)):\n",
        "          output_window_idx_k = [k for k, l in enumerate(self.unique_output_window_idx) if\n",
        "                                  l in ds.output_window_idx[i]]\n",
        "          self.output_mask[output_window_idx_k, j:(j + self.output_size[i])] = 1\n",
        "\n",
        "          j += self.output_size[i]\n",
        "\n",
        "    else:\n",
        "      class NoDataset(torch.utils.data.Dataset):\n",
        "          def __init__(self):\n",
        "              pass\n",
        "\n",
        "          def __getitem__(self, index):\n",
        "              pass\n",
        "\n",
        "          def __len__(self):\n",
        "              return 0\n",
        "\n",
        "      self.input_size, self.output_size = None, None\n",
        "      self.num_inputs, self.num_outputs = None, None\n",
        "      self.input_size, self.output_size = None, None\n",
        "      self.data_len, self.num_samples = None, None\n",
        "      self.total_window_size, self.total_window_idx = None, None\n",
        "      self.shift, self.stride = None, None\n",
        "      self.input_len, self.input_window_idx = None, None\n",
        "      self.output_len, self.output_window_idx = None, None\n",
        "\n",
        "      self.total_input_len, self.total_output_len = None, None\n",
        "      self.unique_output_window_idx = None\n",
        "\n",
        "      self.output_mask = None\n",
        "\n",
        "      ds = NoDataset()\n",
        "\n",
        "    dl = torch.utils.data.DataLoader(ds,\n",
        "                                      batch_size=self.batch_size,\n",
        "                                      shuffle=False,\n",
        "                                      collate_fn=self.collate_fn)\n",
        "\n",
        "    self.num_batches = len(dl)\n",
        "\n",
        "    return dl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BpnDpAlpEyC"
      },
      "outputs": [],
      "source": [
        "class DataModule(pl.LightningDataModule):\n",
        "  def __init__(self,\n",
        "                data,\n",
        "                time_name, input_names, output_names,\n",
        "                fuse_features=None, transforms=None,\n",
        "                pct_train_val_test=[1., 0., 0.],\n",
        "                batch_size=-1,\n",
        "                input_len=[1], output_len=[1], shift=[0], stride=1,\n",
        "                dt=1,\n",
        "                time_unit='s',\n",
        "                pad_data=False,\n",
        "                print_summary=True,\n",
        "                device='cpu', dtype=torch.float32):\n",
        "\n",
        "      '''\n",
        "      Initializes a DataModule object.\n",
        "\n",
        "      Args:\n",
        "          data (str or pd.DataFrame): Path to structured data or a pandas DataFrame containing the data.\n",
        "          time_name (str): Name of the column in the data that represents time.\n",
        "          input_names (list): List of input feature names.\n",
        "          output_names (list): List of output feature names.\n",
        "          fuse_features (list, optional): List of features to fuse into a single feature. Defaults to None.\n",
        "          transforms (dict, optional): Dictionary specifying the transformations to be applied to each feature. Defaults to None.\n",
        "          pct_train_val_test (list, optional): List specifying the percentage of data to use for training,\n",
        "                                                validation, and testing, respectively. Defaults to [1., 0., 0.].\n",
        "          batch_size (int, optional): Batch size for the dataloaders. If -1, the entire dataset is treated as a\n",
        "                                      single batch. Defaults to -1.\n",
        "          input_len (list, optional): List of input sequence lengths for each input feature. If a single value is\n",
        "                                      provided, it is used for all input features. Defaults to [1].\n",
        "          output_len (list, optional): List of output sequence lengths for each output feature. If a single value\n",
        "                                        is provided, it is used for all output features. Defaults to [1].\n",
        "          shift (list, optional): List of output sequence shifts for each output feature. If a single value is\n",
        "                                  provided, it is used for all output features. Defaults to [0].\n",
        "          stride (int, optional): Stride value for creating input-output pairs. Defaults to 1.\n",
        "          dt (int, optional): Time step size. Defaults to 1.\n",
        "          time_unit (str, optional): Time unit of the data. Defaults to 's'.\n",
        "          pad_data (bool, optional): Whether to pad the data to ensure each output sequence has at least one input sequence. Defaults to False.\n",
        "          print_summary (bool, optional): Whether to print a summary of the data module configuration. Defaults to True.\n",
        "          device (str, optional): Device to use for tensor operations. Defaults to 'cpu'.\n",
        "          dtype (torch.dtype, optional): Data type of the tensors. Defaults to torch.float32.\n",
        "      '''\n",
        "\n",
        "      super().__init__()\n",
        "\n",
        "      self.time_name = time_name\n",
        "      self.input_names = input_names\n",
        "      self.output_names = output_names\n",
        "      self.fuse_features = fuse_features\n",
        "      self.transforms = transforms\n",
        "      self.pct_train_val_test = pct_train_val_test\n",
        "      self.batch_size = batch_size\n",
        "      self.input_len = input_len\n",
        "      self.output_len = output_len\n",
        "      self.max_input_len = np.max(input_len).item()\n",
        "      self.max_output_len = np.max(output_len).item()\n",
        "      self.shift = shift\n",
        "      self.stride = stride\n",
        "      self.max_shift = np.max(shift).item()\n",
        "      self.dt = dt\n",
        "      self.time_unit = time_unit\n",
        "      self.pad_data = pad_data\n",
        "      self.start_step = np.max([0, (self.max_input_len - self.max_output_len + self.max_shift)]).item()\n",
        "      self.print_summary = print_summary\n",
        "      self.data = data\n",
        "      self.device = device\n",
        "      self.dtype = dtype\n",
        "      self.predicting = False\n",
        "      self.data_prepared = False\n",
        "\n",
        "  def prepare_data(self):\n",
        "    '''\n",
        "    Prepares the data for training, validation, and testing.\n",
        "\n",
        "    This method is responsible for converting the input data to a dictionary of tensors, applying transformations\n",
        "    to the data, splitting the data into training, validation, and testing sets, and padding the data if necessary.\n",
        "    '''\n",
        "    if not (self.predicting or self.data_prepared):\n",
        "      self.input_output_names = np.unique(self.input_names + self.output_names).tolist()\n",
        "\n",
        "      if isinstance(self.data, str):\n",
        "          # If data is a string, assume it is a path to structured data\n",
        "          with open(self.data, \"rb\") as file:\n",
        "              self.data = pickle.load(file)\n",
        "\n",
        "      if isinstance(self.data, pd.DataFrame):\n",
        "          # If data is a pandas dataframe, assume each column is an individual feature\n",
        "          self.data = self.data.filter(items=[self.time_name] + self.input_output_names)\n",
        "\n",
        "      # Convert dataframe to dictionary of tensors. Concatenate features, if desired.\n",
        "      data = {self.time_name: self.data[self.time_name]}\n",
        "      for key in self.data:\n",
        "          if key != self.time_name:\n",
        "              if not isinstance(self.data[key], torch.Tensor):\n",
        "                  data[key] = torch.tensor(np.array(self.data[key])).to(device=self.device, dtype=self.dtype)\n",
        "              else:\n",
        "                  data[key] = self.data[key].to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "              data[key] = data[key].unsqueeze(1) if data[key].ndim == 1 else data[key]\n",
        "      self.data = data\n",
        "\n",
        "      self.feature_names = None\n",
        "      if self.fuse_features is not None:\n",
        "          self.feature_names = {}\n",
        "          for feature in self.fuse_features:\n",
        "              self.data[feature] = torch.cat([self.data[name] for name in self.data if feature in name], -1)\n",
        "              input_output_names_with_feature = [name for name in self.input_output_names if feature in name]\n",
        "              if len(input_output_names_with_feature) > 0:\n",
        "                  for name in input_output_names_with_feature:\n",
        "                      _, feature_name = name.split('_', 1)\n",
        "                      if feature not in self.feature_names:\n",
        "                          self.feature_names[feature] = [feature_name]\n",
        "                      else:\n",
        "                          self.feature_names[feature] += [feature_name]\n",
        "\n",
        "                      self.input_output_names.remove(name)\n",
        "\n",
        "                      if name in self.data:\n",
        "                          del self.data[name]\n",
        "\n",
        "                  if any(feature in name for name in self.input_names):\n",
        "                      self.input_names = [name for name in self.input_names if feature not in name] + [feature]\n",
        "                  if any(feature in name for name in self.output_names):\n",
        "                      self.output_names = [name for name in self.output_names if feature not in name] + [feature]\n",
        "              else:\n",
        "                  self.feature_names[feature] = []\n",
        "\n",
        "      self.input_output_names = np.unique(self.input_names + self.output_names).tolist()\n",
        "      self.num_inputs, self.num_outputs = len(self.input_names), len(self.output_names)\n",
        "      self.input_size = [self.data[name].shape[-1] for name in self.input_names]\n",
        "      self.output_size = [self.data[name].shape[-1] for name in self.output_names]\n",
        "      self.max_input_size, self.max_output_size = np.max(self.input_size), np.max(self.output_size)\n",
        "\n",
        "      if len(self.input_len) == 1:\n",
        "          self.input_len = self.input_len * self.num_inputs\n",
        "\n",
        "      if len(self.output_len) == 1:\n",
        "          self.output_len = self.output_len * self.num_outputs\n",
        "      if len(self.shift) == 1:\n",
        "          self.shift = self.shift * self.num_outputs\n",
        "\n",
        "      self.has_ar = np.isin(self.output_names, self.input_names).any()\n",
        "\n",
        "      for name in self.input_output_names:\n",
        "          if self.transforms is None:\n",
        "              if 'all' in [name for name in self.transforms]:\n",
        "                  self.transforms[name] = self.transforms['all']\n",
        "              else:\n",
        "                  self.transforms = {name: FeatureTransform(scale_type='identity')}\n",
        "          if name not in self.transforms:\n",
        "              if 'all' in [name for name in self.transforms]:\n",
        "                  self.transforms[name] = self.transforms['all']\n",
        "              else:\n",
        "                  self.transforms = {name: FeatureTransform(scale_type='identity')}\n",
        "\n",
        "      self.data_len = self.data[self.input_output_names[0]].shape[0]\n",
        "\n",
        "      for name in self.input_output_names:\n",
        "          self.data[name] = self.transforms[name].fit_transform(self.data[name])\n",
        "\n",
        "      self.data['steps'] = torch.arange(self.data_len).to(device=self.device, dtype=torch.long)\n",
        "\n",
        "      j = 0\n",
        "      output_input_idx = []\n",
        "      for i, name in enumerate(self.trainer.datamodule.input_names):\n",
        "          input_idx = torch.arange(j, (j + self.input_size[i])).to(dtype=torch.long)\n",
        "          if name in self.trainer.datamodule.output_names:\n",
        "              output_input_idx.append(input_idx)\n",
        "          j += self.input_size[i]\n",
        "      output_input_idx = torch.cat(output_input_idx, -1) if len(output_input_idx) > 0 else []\n",
        "\n",
        "      j = 0\n",
        "      input_output_idx = []\n",
        "      for i, name in enumerate(self.trainer.datamodule.output_names):\n",
        "          size_i =  self.output_size[i] if np.sum(self.output_size) > 0 \\\n",
        "                    else self.model.hidden_out_features[i] if np.sum(self.model.hidden_out_features) > 0 \\\n",
        "                    else self.model.base_hidden_size[i]\n",
        "\n",
        "          output_idx = torch.arange(j, (j + size_i)).to(dtype=torch.long)\n",
        "          if name in self.trainer.datamodule.input_names:\n",
        "              input_output_idx.append(output_idx)\n",
        "          j += size_i\n",
        "      input_output_idx = torch.cat(input_output_idx, -1) if len(input_output_idx) > 0 else []\n",
        "\n",
        "      self.input_output_idx, self.output_input_idx = input_output_idx, output_input_idx\n",
        "      self.data_prepared = True\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "    '''\n",
        "    Sets up the data module for a specific stage of training.\n",
        "\n",
        "    Args:\n",
        "        stage (str, optional): The current stage of training ('fit' or 'predict'). Defaults to None.\n",
        "    '''\n",
        "    if (stage == 'fit') and (not self.predicting):\n",
        "\n",
        "      # Split the data\n",
        "      train_len = int(self.pct_train_val_test[0] * self.data_len)\n",
        "      val_len = int(self.pct_train_val_test[1] * self.data_len)\n",
        "\n",
        "      train_data = {name: self.data[name][:train_len] for name in ([self.time_name, 'steps'] + self.input_output_names)}\n",
        "      if self.pct_train_val_test[1] > 0:\n",
        "        val_data = {name: self.data[name][train_len:(train_len + val_len)] for name in ([self.time_name, 'steps'] + self.input_output_names)}\n",
        "      else:\n",
        "        val_data = {}\n",
        "\n",
        "      if self.pct_train_val_test[2] > 0:\n",
        "        test_data = {name: self.data[name][(train_len + val_len):] for name in ([self.time_name, 'steps'] + self.input_output_names)}\n",
        "        test_len = len(next(iter(test_data.values())))\n",
        "      else:\n",
        "          test_data = {}\n",
        "          test_len = 0\n",
        "\n",
        "      self.train_len, self.val_len, self.test_len = train_len, val_len, test_len\n",
        "\n",
        "      train_init_input, val_init_input, test_init_input = None, None, None\n",
        "\n",
        "      if self.pad_data and (self.start_step > 0):\n",
        "\n",
        "        pad_dim = self.start_step\n",
        "\n",
        "        train_data['steps'] = torch.cat((train_data['steps'],\n",
        "                                         torch.arange(1, 1 + pad_dim).to(device=self.device, dtype=torch.long) + train_data['steps'][-1]),0)\n",
        "\n",
        "        for name in self.input_output_names:\n",
        "          train_data[name] = torch.nn.functional.pad(train_data[name], (0, 0, pad_dim, 0), mode='constant', value=0)\n",
        "\n",
        "        if len(val_data) > 0:\n",
        "          val_data['steps'] = torch.cat((train_data['steps'][-pad_dim:], torch.arange(1, 1 + len(val_data['steps'])) + train_data['steps'][-1]))\n",
        "          for name in self.input_output_names:\n",
        "              val_data[name] = torch.cat((train_data[name][-pad_dim:], val_data[name]), 0)\n",
        "\n",
        "          val_init_input = val_init_input or []\n",
        "          for i, name in enumerate(self.input_names):\n",
        "              val_init_input.append(train_data[name][-(pad_dim + 1)])\n",
        "\n",
        "        if len(test_data) > 0:\n",
        "          data_ = val_data if len(val_data) > 0 else train_data\n",
        "          test_data['steps'] = torch.cat((data_['steps'][-pad_dim:], torch.arange(1, 1 + len(test_data['steps'])) + data_['steps'][-1]))\n",
        "          for name in self.input_output_names:\n",
        "            test_data[name] = torch.cat((data_[name][-pad_dim:], test_data[name]), 0)\n",
        "\n",
        "          test_init_input = test_init_input or []\n",
        "          for i, name in enumerate(self.input_names):\n",
        "            test_init_input.append(data_[name][-(pad_dim + 1)])\n",
        "\n",
        "        else:\n",
        "\n",
        "          data_ = val_data if len(val_data) > 0 else train_data\n",
        "\n",
        "          if (len(val_data) > 0) and self.has_ar:\n",
        "            val_init_input = []\n",
        "          if (len(test_data) > 0) and self.has_ar:\n",
        "            test_init_input = []\n",
        "\n",
        "          for i, name in enumerate(self.input_names):\n",
        "\n",
        "              if (len(val_data) > 0) and self.has_ar:\n",
        "                val_init_input.append(train_data[name][-1])\n",
        "\n",
        "              if (len(test_data) > 0) and self.has_ar:\n",
        "                test_init_input.append(data_[name][-1])\n",
        "\n",
        "        if val_init_input is not None:\n",
        "          val_init_input = torch.cat(val_init_input, -1)\n",
        "        if test_init_input is not None:\n",
        "          test_init_input = torch.cat(test_init_input, -1)\n",
        "\n",
        "        self.train_data, self.val_data, self.test_data = train_data, val_data, test_data\n",
        "        self.train_init_input, self.val_init_input, self.test_init_input = train_init_input, val_init_input, test_init_input\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    '''\n",
        "    Returns the training dataloader.\n",
        "\n",
        "    Returns:\n",
        "        torch.utils.data.DataLoader: The training dataloader.\n",
        "    '''\n",
        "    if not self.predicting:\n",
        "      self.train_batch_size = len(self.train_data['steps']) if self.batch_size == -1 else self.batch_size\n",
        "\n",
        "      self.train_dl = SequenceDataloader(input_names=self.input_names,\n",
        "                                          output_names=self.output_names,\n",
        "                                          step_name='steps',\n",
        "                                          data=self.train_data,\n",
        "                                          batch_size=self.train_batch_size,\n",
        "                                          input_len=self.input_len,\n",
        "                                          output_len=self.output_len,\n",
        "                                          shift=self.shift,\n",
        "                                          stride=self.stride,\n",
        "                                          init_input=self.train_init_input,\n",
        "                                          print_summary=self.print_summary,\n",
        "                                          device=self.device,\n",
        "                                          dtype=self.dtype)\n",
        "      self.num_train_batches = self.train_dl.num_batches\n",
        "\n",
        "      self.train_output_mask = self.train_dl.output_mask\n",
        "      self.train_input_window_idx, self.train_output_window_idx = self.train_dl.input_window_idx, self.train_dl.output_window_idx\n",
        "      self.train_total_input_len, self.train_total_output_len = self.train_dl.total_input_len, self.train_dl.total_output_len\n",
        "\n",
        "      self.train_unique_output_window_idx = self.train_dl.unique_output_window_idx\n",
        "\n",
        "      print(\"Training Dataloader Created.\")\n",
        "\n",
        "      return self.train_dl.dl\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    '''\n",
        "    Returns the validation dataloader.\n",
        "\n",
        "    Returns:\n",
        "        torch.utils.data.DataLoader: The validation dataloader.\n",
        "    '''\n",
        "    if not self.predicting:\n",
        "      if len(self.val_data) > 0:\n",
        "        self.val_batch_size = len(self.val_data['steps']) if self.batch_size == -1 else self.batch_size\n",
        "      else:\n",
        "        self.val_batch_size = 1\n",
        "\n",
        "      self.val_dl = SequenceDataloader(input_names=self.input_names,\n",
        "                                      output_names=self.output_names,\n",
        "                                      step_name='steps',\n",
        "                                      data=self.val_data,\n",
        "                                      batch_size=self.val_batch_size,\n",
        "                                      input_len=self.input_len,\n",
        "                                      output_len=self.output_len,\n",
        "                                      shift=self.shift,\n",
        "                                      stride=self.stride,\n",
        "                                      init_input=self.val_init_input,\n",
        "                                      print_summary=self.print_summary,\n",
        "                                      device=self.device,\n",
        "                                      dtype=self.dtype)\n",
        "\n",
        "      self.num_val_batches = self.val_dl.num_batches\n",
        "\n",
        "      self.val_output_mask = self.val_dl.output_mask\n",
        "      self.val_input_window_idx, self.val_output_window_idx = self.val_dl.input_window_idx, self.val_dl.output_window_idx\n",
        "      self.val_total_input_len, self.val_total_output_len = self.val_dl.total_input_len, self.val_dl.total_output_len\n",
        "\n",
        "      self.val_unique_output_window_idx = self.val_dl.unique_output_window_idx\n",
        "\n",
        "      return self.val_dl.dl\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    '''\n",
        "    Returns the test dataloader.\n",
        "\n",
        "    Returns:\n",
        "        torch.utils.data.DataLoader: The test dataloader.\n",
        "    '''\n",
        "    if self.predicting and not hasattr(self, 'test_dl'):\n",
        "      if len(self.test_data) > 0:\n",
        "        self.test_batch_size = len(self.test_data['steps']) if self.batch_size == -1 else self.batch_size\n",
        "      else:\n",
        "        self.test_batch_size = 1\n",
        "\n",
        "      self.test_dl = SequenceDataloader(input_names=self.input_names,\n",
        "                                        output_names=self.output_names,\n",
        "                                        step_name='steps',\n",
        "                                        data=self.test_data,\n",
        "                                        batch_size=self.test_batch_size,\n",
        "                                        input_len=self.input_len,\n",
        "                                        output_len=self.output_len,\n",
        "                                        shift=self.shift,\n",
        "                                        stride=self.stride,\n",
        "                                        init_input=self.test_init_input,\n",
        "                                        print_summary=self.print_summary,\n",
        "                                        device=self.device,\n",
        "                                        dtype=self.dtype)\n",
        "\n",
        "      self.num_test_batches = self.test_dl.num_batches\n",
        "\n",
        "      self.test_output_mask = self.test_dl.output_mask\n",
        "      self.test_input_window_idx, self.test_output_window_idx = self.test_dl.input_window_idx, self.test_dl.output_window_idx\n",
        "      self.test_total_input_len, self.test_total_output_len = self.test_dl.total_input_len, self.test_dl.total_output_len\n",
        "\n",
        "      self.test_unique_output_window_idx = self.test_dl.unique_output_window_idx\n",
        "\n",
        "      return self.test_dl.dl\n",
        "    else:\n",
        "      return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgfwpcJebqlT"
      },
      "outputs": [],
      "source": [
        "class SequenceModule(pl.LightningModule):\n",
        "  def __init__(self,\n",
        "               model,\n",
        "               opt, loss_fn, metric_fn = None,\n",
        "               constrain = False, penalize = False,\n",
        "               track = False,\n",
        "               model_dir = None):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.automatic_optimization = False\n",
        "\n",
        "    self.model = model\n",
        "\n",
        "    self.opt, self.loss_fn, self.metric_fn = opt, loss_fn, metric_fn\n",
        "\n",
        "    self.constrain, self.penalize = constrain, penalize\n",
        "\n",
        "    input_size, output_size = self.model.input_size, self.model.output_size\n",
        "\n",
        "    self.train_history, self.val_history = None, None\n",
        "    self.current_val_epoch = 0\n",
        "\n",
        "    self.train_step_loss = []\n",
        "    self.val_step_loss = []\n",
        "    self.test_step_loss = []\n",
        "\n",
        "    self.hiddens = None\n",
        "\n",
        "    self.track = track\n",
        "\n",
        "    self.model_dir = model_dir\n",
        "\n",
        "  def forward(self,\n",
        "              input,\n",
        "              hiddens = None,\n",
        "              steps = None,\n",
        "              target = None,\n",
        "              output_window_idx = None,\n",
        "              output_mask = None,\n",
        "              output_input_idx = None, input_output_idx = None,\n",
        "              encoder_output= None):\n",
        "\n",
        "    output, hiddens = self.model.forward(input = input,\n",
        "                                         steps = steps,\n",
        "                                        hiddens = hiddens,\n",
        "                                        target = target,\n",
        "                                        output_window_idx = output_window_idx,\n",
        "                                        output_mask = output_mask,\n",
        "                                        output_input_idx = output_input_idx,\n",
        "                                        input_output_idx = input_output_idx,\n",
        "                                        encoder_output= encoder_output)\n",
        "\n",
        "    return output, hiddens\n",
        "\n",
        "  ## Configure optimizers\n",
        "  def configure_optimizers(self):\n",
        "    return self.opt\n",
        "  ##\n",
        "\n",
        "  ## train model\n",
        "  def on_train_start(self):\n",
        "    self.run_time = time.time()\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "\n",
        "    # constrain model if desired\n",
        "    if self.constrain: self.model.constrain()\n",
        "    #\n",
        "\n",
        "    # unpack batch\n",
        "    input_batch, output_batch, steps_batch, batch_size = batch\n",
        "    #\n",
        "\n",
        "    # keep the first `batch_size` batches of hiddens\n",
        "    if self.hiddens is not None:\n",
        "      for i in range(self.model.num_inputs):\n",
        "        if (self.model.base_type[i] in ['gru', 'lstm', 'lru']) & (self.hiddens[i] is not None):\n",
        "          if self.model.base_type[i] == 'lstm':\n",
        "            if self.hiddens[i][0].shape[1] >= batch_size:\n",
        "              self.hiddens[i] = [s[:, :batch_size].contiguous() for s in self.hiddens[i]]\n",
        "            else:\n",
        "              self.hiddens[i] = [torch.nn.functional.pad(s.contiguous(), pad=(0, 0, 0, batch_size-s.shape[1]), mode='constant', value=0) for s in self.hiddens[i]]\n",
        "          else:\n",
        "            if self.hiddens[i].shape[1] >= batch_size:\n",
        "              self.hiddens[i] = self.hiddens[i][:, :batch_size].contiguous()\n",
        "            else:\n",
        "              self.hiddens[i] = torch.nn.functional.pad(self.hiddens[i].contiguous(), pad=(0, 0, 0, batch_size-self.hiddens[i].shape[1]), mode='constant', value=0)\n",
        "\n",
        "    input_batch = input_batch[:batch_size]\n",
        "    output_batch = output_batch[:batch_size]\n",
        "    steps_batch = steps_batch[:batch_size]\n",
        "    #\n",
        "\n",
        "    # perform forward pass to compute gradients\n",
        "    output_pred_batch, self.hiddens = self.forward(input = input_batch,\n",
        "                                                   steps = steps_batch,\n",
        "                                                   hiddens = self.hiddens,\n",
        "                                                   target = output_batch,\n",
        "                                                   output_window_idx = self.trainer.datamodule.train_output_window_idx,\n",
        "                                                   output_input_idx = self.trainer.datamodule.output_input_idx,\n",
        "                                                   input_output_idx = self.trainer.datamodule.input_output_idx,\n",
        "                                                   output_mask = self.trainer.datamodule.train_output_mask)\n",
        "    #\n",
        "\n",
        "    # get loss for each output\n",
        "    loss = self.loss_fn(output_pred_batch*self.trainer.datamodule.train_output_mask,\n",
        "                        output_batch*self.trainer.datamodule.train_output_mask)\n",
        "    loss = torch.stack([l.sum() for l in loss.split(self.model.output_size, -1)], 0)\n",
        "    #\n",
        "\n",
        "    # add penalty loss if desired\n",
        "    if self.penalize: loss += self.model.penalize()\n",
        "    #\n",
        "\n",
        "    self.opt.zero_grad()\n",
        "    loss.sum().backward()\n",
        "    self.opt.step()\n",
        "\n",
        "    # store loss to be used later in `on_train_epoch_end`\n",
        "    self.train_step_loss.append(loss)\n",
        "    #\n",
        "\n",
        "    return {\"loss\": loss}\n",
        "\n",
        "  def on_train_batch_start(self, batch, batch_idx):\n",
        "    if self.hiddens is not None:\n",
        "      for i in range(self.model.num_inputs):\n",
        "        if (self.model.base_type[i] in ['gru', 'lstm', 'lru']) & (self.hiddens[i] is not None):\n",
        "          if self.model.base_type[i] == 'lstm':\n",
        "            self.hiddens[i] = [s.detach() for s in self.hiddens[i]]\n",
        "          else:\n",
        "            self.hiddens[i] = self.hiddens[i].detach()\n",
        "\n",
        "  def on_train_batch_end(self, outputs, batch, batch_idx):\n",
        "\n",
        "    # reduced loss of current batch\n",
        "    train_step_loss = outputs['loss'].detach()\n",
        "    #\n",
        "\n",
        "    # log and display sum of batch loss\n",
        "    self.log('train_step_loss', train_step_loss.sum(), on_step = True, prog_bar = True)\n",
        "    #\n",
        "\n",
        "    if self.track:\n",
        "      if self.train_history is None:\n",
        "        self.current_train_step = 0\n",
        "        self.train_history = {'steps': torch.empty((0, 1)).to(device = train_step_loss.device,\n",
        "                                                              dtype = torch.long)}\n",
        "        for i in range(self.model.num_outputs):\n",
        "          loss_name_i = self.loss_fn.name + '_' + self.trainer.datamodule.output_names[i]\n",
        "          self.train_history[loss_name_i] = torch.empty((0, 1)).to(train_step_loss)\n",
        "\n",
        "        for name, param in self.model.named_parameters():\n",
        "          if param.requires_grad == True:\n",
        "            self.train_history[name] = torch.empty((0, param.numel())).to(param)\n",
        "\n",
        "      else:\n",
        "        self.train_history['steps'] = torch.cat((self.train_history['steps'],\n",
        "                                                 torch.tensor(self.current_train_step).reshape(1, 1).to(train_step_loss)), 0)\n",
        "\n",
        "        for i in range(self.trainer.datamodule.num_outputs):\n",
        "          loss_name_i = self.loss_fn.name + '_' + self.trainer.datamodule.output_names[i]\n",
        "          self.train_history[loss_name_i] = torch.cat((self.train_history[loss_name_i],\n",
        "                                                       train_step_loss[i].cpu().reshape(1, 1).to(train_step_loss)), 0)\n",
        "\n",
        "        for i,(name, param) in enumerate(self.model.named_parameters()):\n",
        "          if param.requires_grad:\n",
        "            self.train_history[name] = torch.cat((self.train_history[name],\n",
        "                                                  param.clone().detach().cpu().reshape(1, -1).to(param)), 0)\n",
        "\n",
        "    self.current_train_step += 1\n",
        "\n",
        "  def on_train_epoch_start(self):\n",
        "    self.hiddens = None\n",
        "    self.train_step_loss = []\n",
        "\n",
        "  def on_train_epoch_end(self):\n",
        "\n",
        "    # epoch loss\n",
        "    train_epoch_loss = torch.stack(self.train_step_loss).mean(0)\n",
        "    #\n",
        "\n",
        "    self.log('train_epoch_loss', train_epoch_loss.sum(), on_epoch = True, prog_bar = True)\n",
        "\n",
        "    self.train_step_loss.clear()\n",
        "  ## End of Training\n",
        "\n",
        "  ## Validate Model\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "\n",
        "    # unpack batch\n",
        "    input_batch, output_batch, steps_batch, batch_size = batch\n",
        "    #\n",
        "\n",
        "    # keep the first `batch_size` batches of hiddens\n",
        "    if self.hiddens is not None:\n",
        "\n",
        "      for i in range(self.model.num_inputs):\n",
        "        if (self.model.base_type[i] in ['gru', 'lstm', 'lru']) & (self.hiddens[i] is not None):\n",
        "          if self.model.base_type[i] == 'lstm':\n",
        "            if self.hiddens[i][0].shape[1] >= batch_size:\n",
        "              self.hiddens[i] = [s[:, :batch_size].contiguous() for s in self.hiddens[i]]\n",
        "            else:\n",
        "              self.hiddens[i] = [torch.nn.functional.pad(s.contiguous(), pad=(0, 0, 0, batch_size-s.shape[1]), mode='constant', value=0) for s in self.hiddens[i]]\n",
        "          else:\n",
        "            if self.hiddens[i].shape[1] >= batch_size:\n",
        "              self.hiddens[i] = self.hiddens[i][:, :batch_size].contiguous()\n",
        "            else:\n",
        "              self.hiddens[i] = torch.nn.functional.pad(self.hiddens[i].contiguous(), pad=(0, 0, 0, batch_size-self.hiddens[i].shape[1]), mode='constant', value=0)\n",
        "\n",
        "    input_batch = input_batch[:batch_size]\n",
        "    output_batch = output_batch[:batch_size]\n",
        "    steps_batch = steps_batch[:batch_size]\n",
        "    #\n",
        "\n",
        "    # perform forward pass to compute gradients\n",
        "    output_pred_batch, self.hiddens = self.forward(input = input_batch,\n",
        "                                                  steps = steps_batch,\n",
        "                                                  hiddens = self.hiddens,\n",
        "                                                  target = None,\n",
        "                                                  output_window_idx = self.trainer.datamodule.val_output_window_idx,\n",
        "                                                  output_input_idx = self.trainer.datamodule.output_input_idx,\n",
        "                                                  input_output_idx = self.trainer.datamodule.input_output_idx,\n",
        "                                                  output_mask = self.trainer.datamodule.val_output_mask)\n",
        "    #\n",
        "\n",
        "    # get loss for each output\n",
        "    loss = self.loss_fn(output_pred_batch*self.trainer.datamodule.val_output_mask,\n",
        "                        output_batch*self.trainer.datamodule.val_output_mask)\n",
        "    loss = torch.stack([l.sum() for l in loss.split(self.model.output_size, -1)], 0)\n",
        "    #\n",
        "\n",
        "    self.val_step_loss.append(loss)\n",
        "\n",
        "    {\"loss\": loss}\n",
        "\n",
        "  def on_validation_epoch_end(self):\n",
        "    # epoch loss\n",
        "    val_epoch_loss = torch.stack(self.val_step_loss).mean(0)\n",
        "    #\n",
        "\n",
        "    self.log('val_epoch_loss', val_epoch_loss.sum(), on_step = False, on_epoch = True, prog_bar = True)\n",
        "\n",
        "    if self.track:\n",
        "      if self.val_history is None:\n",
        "        self.val_history = {'epochs': torch.empty((0, 1)).to(device = val_epoch_loss.device,\n",
        "                                                             dtype = torch.long)}\n",
        "        for i in range(self.trainer.datamodule.num_outputs):\n",
        "          self.val_history[self.loss_fn.name + '_' + self.trainer.datamodule.output_names[i]] = torch.empty((0, 1)).to(val_epoch_loss)\n",
        "\n",
        "      else:\n",
        "        self.val_history['epochs'] = torch.cat((self.val_history['epochs'],\n",
        "                                              torch.tensor(self.current_val_epoch).reshape(1, 1).to(val_epoch_loss)), 0)\n",
        "\n",
        "        for i in range(self.trainer.datamodule.num_outputs):\n",
        "          loss_name_i = self.loss_fn.name + '_' + self.trainer.datamodule.output_names[i]\n",
        "          self.val_history[loss_name_i] = torch.cat((self.val_history[loss_name_i],\n",
        "                                                    val_epoch_loss[i].cpu().reshape(1, 1).to(val_epoch_loss)), 0)\n",
        "\n",
        "    self.val_step_loss.clear()\n",
        "\n",
        "    self.current_val_epoch += 1\n",
        "  ## End of validation\n",
        "\n",
        "  ## Test Model\n",
        "  def test_step(self, batch, batch_idx):\n",
        "\n",
        "    # unpack batch\n",
        "    input_batch, output_batch, steps_batch, batch_size = batch\n",
        "    #\n",
        "\n",
        "    # keep the first `batch_size` batches of hiddens\n",
        "    if self.hiddens is not None:\n",
        "      for i in range(self.model.num_inputs):\n",
        "        if (self.model.base_type[i] in ['gru', 'lstm', 'lru']) & (self.hiddens[i] is not None):\n",
        "          if self.model.base_type[i] == 'lstm':\n",
        "            if self.hiddens[i][0].shape[1] >= batch_size:\n",
        "              self.hiddens[i] = [s[:, :batch_size].contiguous() for s in self.hiddens[i]]\n",
        "            else:\n",
        "              self.hiddens[i] = [torch.nn.functional.pad(s.contiguous(), pad=(0, 0, 0, batch_size-s.shape[1]), mode='constant', value=0) for s in self.hiddens[i]]\n",
        "          else:\n",
        "            if self.hiddens[i].shape[1] >= batch_size:\n",
        "              self.hiddens[i] = self.hiddens[i][:, :batch_size].contiguous()\n",
        "            else:\n",
        "              self.hiddens[i] = torch.nn.functional.pad(self.hiddens[i].contiguous(), pad=(0, 0, 0, batch_size-self.hiddens[i].shape[1]), mode='constant', value=0)\n",
        "\n",
        "    input_batch = input_batch[:batch_size]\n",
        "    output_batch = output_batch[:batch_size]\n",
        "    steps_batch = steps_batch[:batch_size]\n",
        "    #\n",
        "\n",
        "    # perform forward pass to compute gradients\n",
        "    output_pred_batch, self.hiddens = self.forward(input = input_batch,\n",
        "                                                  steps = steps_batch,\n",
        "                                                  hiddens = self.hiddens,\n",
        "                                                  target = None,\n",
        "                                                  output_window_idx = self.trainer.datamodule.test_output_window_idx,\n",
        "                                                  output_input_idx = self.trainer.datamodule.output_input_idx,\n",
        "                                                  input_output_idx = self.trainer.datamodule.input_output_idx,\n",
        "                                                  output_mask = self.trainer.datamodule.test_output_mask)\n",
        "    #\n",
        "\n",
        "    # get loss for each output\n",
        "    loss = self.loss_fn(output_pred_batch*self.trainer.datamodule.test_output_mask,\n",
        "                        output_batch*self.trainer.datamodule.test_output_mask)\n",
        "    loss = torch.stack([l.sum() for l in loss.split(self.model.output_size, -1)], 0)\n",
        "    #\n",
        "\n",
        "    self.test_step_loss.append(loss)\n",
        "\n",
        "    {\"loss\": loss}\n",
        "\n",
        "  def on_test_epoch_end(self):\n",
        "    # epoch loss\n",
        "    test_epoch_loss = torch.stack(self.test_step_loss).mean(0)\n",
        "    self.test_step_loss.clear()\n",
        "    #\n",
        "\n",
        "    self.log('test_epoch_loss', test_epoch_loss.sum(), on_epoch = True, prog_bar = True)\n",
        "  ## End of Testing\n",
        "\n",
        "  ## plot history\n",
        "  def plot_history(self, history = None, plot_train_history_by = 'epochs'):\n",
        "\n",
        "    history = [self.loss_fn.name] if history is None else history\n",
        "\n",
        "    if plot_train_history_by == 'epochs':\n",
        "      num_batches = len(self.trainer.datamodule.train_dl.dl)\n",
        "      train_history_epoch = {'epochs': torch.arange(len(self.train_history['steps'])//num_batches).to(dtype = torch.long)}\n",
        "      num_epochs = len(train_history_epoch['epochs'])\n",
        "      for key in self.train_history.keys():\n",
        "        if key != 'steps':\n",
        "          batch_param = []\n",
        "          for batch in self.train_history[key].split(num_batches, 0):\n",
        "            batch_param.append(batch.mean(0, keepdim = True))\n",
        "          batch_param = torch.cat(batch_param, 0)\n",
        "          train_history_epoch[key] = batch_param[:num_epochs]\n",
        "\n",
        "      train_history = train_history_epoch\n",
        "\n",
        "      x_label = 'epochs'\n",
        "\n",
        "    else:\n",
        "      x_label = 'steps'\n",
        "      train_history = self.train_history\n",
        "\n",
        "    num_params = len(history)\n",
        "    fig = plt.figure(figsize = (5, 5*num_params))\n",
        "    ax_i = 0\n",
        "    for param in history:\n",
        "      ax_i += 1\n",
        "      ax = fig.add_subplot(num_params, 1, ax_i)\n",
        "      ax.plot(train_history[x_label], train_history[param], label = 'Train')\n",
        "      if (self.val_history is not None) & (x_label == 'epochs') & ((self.loss_fn.name in param) | (self.metric_fn.name in param)):\n",
        "        N = np.min([self.val_history[x_label].shape[0], self.val_history[param].shape[0]])\n",
        "        ax.plot(self.val_history[x_label][:N], self.val_history[param][:N], label = 'Val')\n",
        "      ax.set_title(param)\n",
        "      ax.set_ylabel(param)\n",
        "      ax.legend()\n",
        "    plt.grid()\n",
        "  ##\n",
        "\n",
        "  ## Prediction\n",
        "  def predict_step(self, batch, batch_idx):\n",
        "\n",
        "    # unpack batch\n",
        "    input_batch, output_batch, steps_batch, batch_size = batch\n",
        "    #\n",
        "\n",
        "    # keep the first `batch_size` batches of hiddens\n",
        "    if self.hiddens is not None:\n",
        "      for i in range(self.model.num_inputs):\n",
        "        if (self.model.base_type[i] in ['gru', 'lstm', 'lru']) & (self.hiddens[i] is not None):\n",
        "          if self.model.base_type[i] == 'lstm':\n",
        "            if self.hiddens[i][0].shape[1] >= batch_size:\n",
        "              self.hiddens[i] = [s[:, :batch_size].contiguous() for s in self.hiddens[i]]\n",
        "            else:\n",
        "              self.hiddens[i] = [torch.nn.functional.pad(s.contiguous(), pad=(0, 0, 0, batch_size-s.shape[1]), mode='constant', value=0) for s in self.hiddens[i]]\n",
        "          else:\n",
        "            if self.hiddens[i].shape[1] >= batch_size:\n",
        "              self.hiddens[i] = self.hiddens[i][:, :batch_size].contiguous()\n",
        "            else:\n",
        "              self.hiddens[i] = torch.nn.functional.pad(self.hiddens[i].contiguous(), pad=(0, 0, 0, batch_size-self.hiddens[i].shape[1]), mode='constant', value=0)\n",
        "\n",
        "    input_batch = input_batch[:batch_size]\n",
        "    output_batch = output_batch[:batch_size]\n",
        "    steps_batch = steps_batch[:batch_size]\n",
        "    #\n",
        "\n",
        "    output_len = output_batch.shape[1]\n",
        "\n",
        "    # perform forward pass to compute gradients\n",
        "    output_pred_batch, self.hiddens = self.forward(input = input_batch,\n",
        "                                                   steps = steps_batch,\n",
        "                                                   hiddens = self.hiddens,\n",
        "                                                   target = None,\n",
        "                                                   output_window_idx = self.predict_output_window_idx,\n",
        "                                                   output_input_idx = self.trainer.datamodule.output_input_idx,\n",
        "                                                   input_output_idx = self.trainer.datamodule.input_output_idx,\n",
        "                                                   output_mask = self.predict_output_mask)\n",
        "    #\n",
        "\n",
        "    # get loss for each output\n",
        "    step_loss = self.loss_fn(output_pred_batch*self.predict_output_mask,\n",
        "                             output_batch*self.predict_output_mask)\n",
        "    step_loss = torch.stack([l.sum() for l in step_loss.split(self.model.input_size, -1)], 0)\n",
        "    #\n",
        "\n",
        "    output_steps_batch = steps_batch[:, -output_len:]\n",
        "\n",
        "    return output_batch, output_pred_batch, output_steps_batch # , baseline_pred_batch\n",
        "\n",
        "  def on_predict_batch_end(self, outputs, batch, batch_idx, dataloader_idx = 0):\n",
        "    self.step_target.append(outputs[0])\n",
        "    self.output_pred_batch.append(outputs[1])\n",
        "    self.output_steps_batch.append(outputs[2])\n",
        "    # self.step_baseline_pred.append(outputs[3])\n",
        "\n",
        "  def on_predict_epoch_end(self):\n",
        "    self.target = torch.cat(self.step_target, 0)\n",
        "    self.prediction = torch.cat(self.output_pred_batch, 0)\n",
        "    self.output_steps = torch.cat(self.output_steps_batch, 0)\n",
        "    # self.baseline_prediction = torch.cat(self.step_baseline_pred, 0)\n",
        "\n",
        "    self.step_target.clear()\n",
        "    self.output_pred_batch.clear()\n",
        "    self.output_steps_batch.clear()\n",
        "    # self.step_baseline_pred.clear()\n",
        "\n",
        "  def on_predict_epoch_start(self):\n",
        "    self.output_pred_batch, self.step_target = [], []\n",
        "    self.output_steps_batch = []\n",
        "    # self.step_baseline_pred = []\n",
        "\n",
        "  def predict(self,\n",
        "              reduction = 'mean',\n",
        "              baseline_model = None):\n",
        "\n",
        "    self.baseline_model = baseline_model\n",
        "\n",
        "    self.trainer.datamodule.predicting = True\n",
        "\n",
        "    self.trainer.enable_progress_bar = False\n",
        "\n",
        "    pad_dim = self.trainer.datamodule.start_step*int(self.trainer.datamodule.pad_data)\n",
        "\n",
        "    hiddens = None\n",
        "    with torch.no_grad():\n",
        "\n",
        "      ## Predict training data\n",
        "      self.predict_output_mask = self.trainer.datamodule.train_output_mask\n",
        "      self.predict_output_window_idx = self.trainer.datamodule.train_output_window_idx\n",
        "\n",
        "      self.trainer.predict(self, self.trainer.datamodule.train_dl.dl)\n",
        "\n",
        "      self.prediction, self.target, self.output_steps = self.prediction[pad_dim:], self.target[pad_dim:], self.output_steps[pad_dim:]\n",
        "\n",
        "      train_prediction, train_output_steps = self.generate_reduced_output(self.prediction, self.output_steps,\n",
        "                                                                          reduction = reduction, transforms=self.trainer.datamodule.transforms)\n",
        "\n",
        "      train_target, _ = self.generate_reduced_output(self.target, self.output_steps,\n",
        "                                                     reduction = reduction, transforms=self.trainer.datamodule.transforms)\n",
        "\n",
        "      # train_loss = self.loss_fn(train_prediction.unsqueeze(0),\n",
        "      #                           train_target.unsqueeze(0))\n",
        "\n",
        "      # train_loss = torch.stack([l.sum() for l in train_loss.split(self.model.input_size, -1)], 0)\n",
        "\n",
        "      train_time = self.trainer.datamodule.train_data[self.trainer.datamodule.time_name][pad_dim:]\n",
        "\n",
        "      train_baseline_pred, train_baseline_loss = None, None\n",
        "      if self.baseline_model is not None:\n",
        "        train_baseline_pred = self.baseline_model(train_target)\n",
        "        # train_baseline_loss = self.loss_fn(train_baseline_pred.unsqueeze(0),\n",
        "        #                                    train_target.unsqueeze(0))\n",
        "      ##\n",
        "\n",
        "      # Predict validation data\n",
        "      val_prediction, val_target, val_time, val_loss, val_baseline_pred, val_baseline_loss = None, None, None, None, None, None\n",
        "      if len(self.trainer.datamodule.val_dl.dl) > 0:\n",
        "        self.predict_output_mask = self.trainer.datamodule.val_output_mask\n",
        "        self.predict_output_window_idx = self.trainer.datamodule.val_output_window_idx\n",
        "\n",
        "        self.trainer.predict(self, self.trainer.datamodule.val_dl.dl) ;\n",
        "\n",
        "        val_prediction, val_output_steps = self.generate_reduced_output(self.prediction, self.output_steps,\n",
        "                                                                        reduction = reduction, transforms=self.trainer.datamodule.transforms)\n",
        "\n",
        "        val_target, _ = self.generate_reduced_output(self.target, self.output_steps,\n",
        "                                                     reduction = reduction, transforms=self.trainer.datamodule.transforms)\n",
        "\n",
        "        # val_loss = self.loss_fn(val_prediction.unsqueeze(0),\n",
        "        #                         val_target.unsqueeze(0))\n",
        "        # val_loss = torch.stack([l.sum() for l in val_loss.split(self.model.input_size, -1)], 0)\n",
        "\n",
        "        val_time = self.trainer.datamodule.val_data[self.trainer.datamodule.time_name]\n",
        "\n",
        "        val_baseline_pred, val_baseline_loss = None, None\n",
        "        if self.baseline_model is not None:\n",
        "          val_baseline_pred = self.baseline_model(val_target)\n",
        "          # val_baseline_loss = self.loss_fn(val_baseline_pred.unsqueeze(0),\n",
        "          #                                  val_target.unsqueeze(0))\n",
        "      #\n",
        "\n",
        "      # Predict testing data\n",
        "      if not hasattr(self.trainer.datamodule, 'test_dl'):\n",
        "        self.trainer.datamodule.test_dataloader()\n",
        "      test_prediction, test_target, test_time, test_loss, test_baseline_pred, test_baseline_loss = None, None, None, None, None, None\n",
        "      if len(self.trainer.datamodule.test_dl.dl) > 0:\n",
        "        self.predict_output_mask = self.trainer.datamodule.test_output_mask\n",
        "        self.predict_output_window_idx = self.trainer.datamodule.test_output_window_idx\n",
        "\n",
        "        self.trainer.predict(self, self.trainer.datamodule.test_dl.dl) ;\n",
        "\n",
        "        test_prediction, test_output_steps = self.generate_reduced_output(self.prediction, self.output_steps,\n",
        "                                                                          reduction = reduction, transforms=self.trainer.datamodule.transforms)\n",
        "\n",
        "        test_target, _ = self.generate_reduced_output(self.target, self.output_steps,\n",
        "                                                      reduction = reduction, transforms=self.trainer.datamodule.transforms)\n",
        "\n",
        "        # test_loss = self.loss_fn(test_prediction.unsqueeze(0),\n",
        "        #                         test_target.unsqueeze(0))\n",
        "        # test_loss = torch.stack([l.sum() for l in test_loss.split(self.model.input_size, -1)], 0)\n",
        "\n",
        "        test_time = self.trainer.datamodule.test_data[self.trainer.datamodule.time_name]\n",
        "\n",
        "        test_baseline_pred, test_baseline_loss = None, None\n",
        "        if self.baseline_model is not None:\n",
        "          test_baseline_pred = self.baseline_model(test_target)\n",
        "          # test_baseline_loss = self.loss_fn(test_baseline_pred.unsqueeze(0),\n",
        "          #                                   test_target.unsqueeze(0))\n",
        "      #\n",
        "\n",
        "    train_prediction_data, val_prediction_data, test_prediction_data = {self.trainer.datamodule.time_name: train_time}, None, None\n",
        "\n",
        "    if val_prediction is not None: val_prediction_data = {self.trainer.datamodule.time_name: val_time}\n",
        "    if test_prediction is not None: test_prediction_data = {self.trainer.datamodule.time_name: test_time}\n",
        "\n",
        "    j = 0\n",
        "    for i,output_name in enumerate(self.trainer.datamodule.output_names):\n",
        "\n",
        "      # train\n",
        "      train_target_i = train_target[:, j:(j+self.trainer.datamodule.output_size[i])]\n",
        "      train_prediction_i = train_prediction[:, j:(j+self.trainer.datamodule.output_size[i])]\n",
        "\n",
        "      train_prediction_data[f\"{output_name}_actual\"] = train_target_i\n",
        "      train_prediction_data[f\"{output_name}_prediction\"] = train_prediction_i\n",
        "\n",
        "      train_loss_i = Loss(self.loss_fn.name,\n",
        "                          dims=(0,1))(train_prediction_i.unsqueeze(0), train_target_i.unsqueeze(0))\n",
        "      train_prediction_data[f\"{output_name}_{self.loss_fn.name}\"] = train_loss_i\n",
        "\n",
        "      if self.metric_fn is not None:\n",
        "        train_metric_i = Loss(self.metric_fn.name,\n",
        "                            dims=(0,1))(train_prediction_i.unsqueeze(0), train_target_i.unsqueeze(0))\n",
        "        train_prediction_data[f\"{output_name}_{self.metric_fn.name}\"] = train_metric_i\n",
        "\n",
        "      train_baseline_pred_i, train_baseline_loss_i, train_baseline_metric_i = None, None, None\n",
        "      if train_baseline_pred is not None:\n",
        "        train_baseline_pred_i = train_baseline_pred[:, j:(j+self.trainer.datamodule.output_size[i])]\n",
        "\n",
        "        train_baseline_loss_i = Loss(self.loss_fn.name,\n",
        "                                     dims=(0,1))(train_baseline_pred_i.unsqueeze(0), train_target_i.unsqueeze(0))\n",
        "\n",
        "        if self.metric_fn is not None:\n",
        "          train_baseline_metric_i = Loss(self.metric_fn.name,\n",
        "                                         dims=(0,1))(train_baseline_pred_i.unsqueeze(0), train_target_i.unsqueeze(0))\n",
        "\n",
        "      train_prediction_data[f\"{output_name}_baseline_prediction\"] = train_baseline_pred_i\n",
        "      train_prediction_data[f\"{output_name}_baseline_{self.loss_fn.name}\"] = train_baseline_loss_i\n",
        "      train_prediction_data[f\"{output_name}_baseline_{self.metric_fn.name}\"] = train_baseline_metric_i\n",
        "      #\n",
        "\n",
        "      # val\n",
        "      if val_prediction is not None:\n",
        "        val_prediction_data[output_name] = {}\n",
        "\n",
        "        val_target_i = val_target[:, j:(j+self.trainer.datamodule.output_size[i])]\n",
        "        val_prediction_i = val_prediction[:, j:(j+self.trainer.datamodule.output_size[i])]\n",
        "\n",
        "        val_prediction_data[f\"{output_name}_actual\"] = val_target_i\n",
        "        val_prediction_data[f\"{output_name}_prediction\"] = val_prediction_i\n",
        "\n",
        "        val_loss_i = Loss(self.loss_fn.name,\n",
        "                            dims=(0,1))(val_prediction_i.unsqueeze(0), val_target_i.unsqueeze(0))\n",
        "        val_prediction_data[f\"{output_name}_{self.loss_fn.name}\"] = val_loss_i\n",
        "\n",
        "        if self.metric_fn is not None:\n",
        "          val_metric_i = Loss(self.metric_fn.name,\n",
        "                              dims=(0,1))(val_prediction_i.unsqueeze(0), val_target_i.unsqueeze(0))\n",
        "          val_prediction_data[f\"{output_name}_{self.metric_fn.name}\"] = val_metric_i\n",
        "\n",
        "        val_baseline_pred_i, val_baseline_loss_i, val_baseline_metric_i = None, None, None\n",
        "        if val_baseline_pred is not None:\n",
        "          val_baseline_pred_i = val_baseline_pred[:, j:(j+self.trainer.datamodule.output_size[i])]\n",
        "\n",
        "          val_baseline_loss_i = Loss(self.loss_fn.name,\n",
        "                              dims=(0,1))(val_baseline_pred_i.unsqueeze(0), val_target_i.unsqueeze(0))\n",
        "\n",
        "          if self.metric_fn is not None:\n",
        "            val_baseline_metric_i = Loss(self.metric_fn.name,\n",
        "                                         dims=(0,1))(val_baseline_pred_i.unsqueeze(0), val_target_i.unsqueeze(0))\n",
        "\n",
        "        val_prediction_data[f\"{output_name}_baseline_prediction\"] = val_baseline_pred_i\n",
        "        val_prediction_data[f\"{output_name}_baseline_{self.loss_fn.name}\"] = val_baseline_loss_i\n",
        "        val_prediction_data[f\"{output_name}_baseline_{self.metric_fn.name}\"] = val_baseline_metric_i\n",
        "      #\n",
        "\n",
        "      # test\n",
        "      if test_prediction is not None:\n",
        "        test_prediction_data[output_name] = {}\n",
        "\n",
        "        test_target_i = test_target[:, j:(j+self.trainer.datamodule.output_size[i])]\n",
        "        test_prediction_i = test_prediction[:, j:(j+self.trainer.datamodule.output_size[i])]\n",
        "\n",
        "        test_prediction_data[f\"{output_name}_actual\"] = test_target_i\n",
        "        test_prediction_data[f\"{output_name}_prediction\"] = test_prediction_i\n",
        "\n",
        "        test_loss_i = Loss(self.loss_fn.name,\n",
        "                           dims=(0,1))(test_prediction_i.unsqueeze(0), test_target_i.unsqueeze(0))\n",
        "        test_prediction_data[f\"{output_name}_{self.loss_fn.name}\"] = test_loss_i\n",
        "\n",
        "        if self.metric_fn is not None:\n",
        "          test_metric_i = Loss(self.metric_fn.name,\n",
        "                              dims=(0,1))(test_prediction_i.unsqueeze(0), test_target_i.unsqueeze(0))\n",
        "          test_prediction_data[f\"{output_name}_{self.metric_fn.name}\"] = test_metric_i\n",
        "\n",
        "        test_baseline_pred_i, test_baseline_loss_i, test_baseline_metric_i = None, None, None\n",
        "        if test_baseline_pred is not None:\n",
        "          test_baseline_pred_i = test_baseline_pred[:, j:(j+self.trainer.datamodule.output_size[i])]\n",
        "\n",
        "          test_baseline_loss_i = Loss(self.loss_fn.name,\n",
        "                                      dims=(0,1))(test_baseline_pred_i.unsqueeze(0), test_target_i.unsqueeze(0))\n",
        "\n",
        "          if self.metric_fn is not None:\n",
        "            test_baseline_metric_i = Loss(self.metric_fn.name,\n",
        "                                          dims=(0,1))(test_baseline_pred_i.unsqueeze(0), test_target_i.unsqueeze(0))\n",
        "\n",
        "        test_prediction_data[f\"{output_name}_baseline_prediction\"] = test_baseline_pred_i\n",
        "        test_prediction_data[f\"{output_name}_baseline_{self.loss_fn.name}\"] = test_baseline_loss_i\n",
        "        test_prediction_data[f\"{output_name}_baseline_{self.metric_fn.name}\"] = test_baseline_metric_i\n",
        "      #\n",
        "\n",
        "      j += self.trainer.datamodule.output_size[i]\n",
        "\n",
        "    self.train_prediction_data, self.val_prediction_data, self.test_prediction_data = train_prediction_data, val_prediction_data, test_prediction_data\n",
        "\n",
        "    self.trainer.enable_progress_bar = True\n",
        "    self.trainer.datamodule.predicting = False\n",
        "\n",
        "  ##\n",
        "  def plot_predictions(self,\n",
        "                       output_feature_units = None,\n",
        "                       include_baseline = False):\n",
        "\n",
        "    time_name = self.trainer.datamodule.time_name\n",
        "    output_names = self.trainer.datamodule.output_names\n",
        "    feature_names = self.trainer.datamodule.feature_names\n",
        "    num_outputs = len(output_names)\n",
        "    output_size = self.trainer.datamodule.output_size\n",
        "    max_output_size = np.max(output_size)\n",
        "\n",
        "    start_step = self.trainer.datamodule.start_step\n",
        "\n",
        "    rows, cols = max_output_size, num_outputs\n",
        "    fig, ax = plt.subplots(rows, cols, figsize = (10*num_outputs, 5*max_output_size))\n",
        "\n",
        "    train_time = self.train_prediction_data[time_name]\n",
        "    val_time = self.val_prediction_data[time_name] if self.val_prediction_data is not None else None\n",
        "    test_time = self.test_prediction_data[time_name] if self.test_prediction_data is not None else None\n",
        "\n",
        "    for i,output_name in enumerate(output_names):\n",
        "\n",
        "      try:\n",
        "        ax_i = ax[i, :]\n",
        "        [ax_j.axis(\"off\") for ax_j in ax_i]\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "      for f in range(output_size[i]):\n",
        "\n",
        "        if (feature_names is not None):\n",
        "          if any(output_name in name for name in feature_names) & (output_size[i] > 1):\n",
        "            output_feature_name_if = feature_names[output_name][f]\n",
        "        else:\n",
        "          output_feature_name_if = None\n",
        "\n",
        "        if output_feature_units is not None:\n",
        "          if output_name in output_feature_units:\n",
        "            output_feature_units_if = output_feature_units[output_name][f]\n",
        "          else:\n",
        "            output_feature_units_if = None\n",
        "        else:\n",
        "          output_feature_units_if = None\n",
        "\n",
        "        try:\n",
        "          ax_if = ax[f,i]\n",
        "        except:\n",
        "          try:\n",
        "            j = i if (cols>1) & (rows == 1) else f\n",
        "            ax_if = ax[j]\n",
        "          except:\n",
        "            ax_if = ax\n",
        "\n",
        "        train_target_if = self.train_prediction_data[f\"{output_name}_actual\"][:, f]\n",
        "        train_prediction_if = self.train_prediction_data[f\"{output_name}_prediction\"][:, f]\n",
        "        train_loss_if = np.round(self.train_prediction_data[f\"{output_name}_{self.loss_fn.name}\"][f].item(),2)\n",
        "        train_metric_if = np.round(self.train_prediction_data[f\"{output_name}_{self.metric_fn.name}\"][f].item(),2) if self.metric_fn is not None else None\n",
        "        if include_baseline:\n",
        "          train_baseline_prediction_if = self.train_prediction_data[f\"{output_name}_baseline_prediction\"][:, f]\n",
        "          train_baseline_loss_if = np.round(self.train_prediction_data[f\"{output_name}_baseline_{self.loss_fn.name}\"][f].item(),2)\n",
        "          train_baseline_metric_if = np.round(self.train_prediction_data[f\"{output_name}_baseline_{self.metric_fn.name}\"][f].item(),2) if self.metric_fn is not None else None\n",
        "\n",
        "        ax_if.plot(train_time, train_target_if, '-k', label = 'Actual')\n",
        "        ax_if.plot(train_time, train_prediction_if, '-r', label = 'Prediction')\n",
        "        train_label = f\"Train ({self.loss_fn.name} = {train_loss_if}, {self.metric_fn.name} = {train_metric_if})\" \\\n",
        "                      if train_metric_if is not None \\\n",
        "                      else f\"Train ({self.loss_fn.name} = {train_loss_if})\"\n",
        "        if include_baseline:\n",
        "          ax_if.plot(train_time, train_baseline_prediction_if, '--g', linewidth = 1.0, label = 'Baseline')\n",
        "          train_label = train_label + f\", Baseline ({self.loss_fn.name} = {train_baseline_loss_if}, {self.metric_fn.name} = {train_baseline_metric_if})\"\n",
        "\n",
        "        ax_if.axvspan(train_time.min(), train_time.max(), facecolor='gray', alpha=0.2, label = train_label)\n",
        "\n",
        "        if val_time is not None:\n",
        "          val_target_if = self.val_prediction_data[f\"{output_name}_actual\"][:, f]\n",
        "          val_prediction_if = self.val_prediction_data[f\"{output_name}_prediction\"][:, f]\n",
        "          val_loss_if = np.round(self.val_prediction_data[f\"{output_name}_{self.loss_fn.name}\"][f].item(),2)\n",
        "          val_metric_if = np.round(self.val_prediction_data[f\"{output_name}_{self.metric_fn.name}\"][f].item(),2) if self.metric_fn is not None else None\n",
        "          if include_baseline:\n",
        "            val_baseline_prediction_if = self.val_prediction_data[f\"{output_name}_baseline_prediction\"][:, f]\n",
        "            val_baseline_loss_if = np.round(self.val_prediction_data[f\"{output_name}_baseline_{self.loss_fn.name}\"][f].item(),2)\n",
        "            val_baseline_metric_if = np.round(self.val_prediction_data[f\"{output_name}_baseline_{self.metric_fn.name}\"][f].item(),2) if self.metric_fn is not None else None\n",
        "\n",
        "          ax_if.plot(val_time, val_target_if, '-k')\n",
        "          ax_if.plot(val_time, val_prediction_if, '-r')\n",
        "          val_label = f\"Val ({self.loss_fn.name} = {val_loss_if}, {self.metric_fn.name} = {val_metric_if})\" \\\n",
        "                        if val_metric_if is not None \\\n",
        "                        else f\"Val ({self.loss_fn.name} = {val_loss_if})\"\n",
        "          if include_baseline:\n",
        "            ax_if.plot(val_time, val_baseline_prediction_if, '--g', linewidth = 1.0)\n",
        "            val_label = val_label + f\", Baseline ({self.loss_fn.name} = {val_baseline_loss_if}, {self.metric_fn.name} = {val_baseline_metric_if})\"\n",
        "\n",
        "          ax_if.axvspan(val_time.min(), val_time.max(), facecolor='blue', alpha=0.2, label = val_label)\n",
        "\n",
        "        if test_time is not None:\n",
        "          test_target_if = self.test_prediction_data[f\"{output_name}_actual\"][:, f]\n",
        "          test_prediction_if = self.test_prediction_data[f\"{output_name}_prediction\"][:, f]\n",
        "          test_loss_if = np.round(self.test_prediction_data[f\"{output_name}_{self.loss_fn.name}\"][f].item(),2)\n",
        "          test_metric_if = np.round(self.test_prediction_data[f\"{output_name}_{self.metric_fn.name}\"][f].item(),2) if self.metric_fn is not None else None\n",
        "          if include_baseline:\n",
        "            test_baseline_prediction_if = self.test_prediction_data[f\"{output_name}_baseline_prediction\"][:, f]\n",
        "            test_baseline_loss_if = np.round(self.test_prediction_data[f\"{output_name}_baseline_{self.loss_fn.name}\"][f].item(),2)\n",
        "            test_baseline_metric_if = np.round(self.test_prediction_data[f\"{output_name}_baseline_{self.metric_fn.name}\"][f].item(),2) if self.metric_fn is not None else None\n",
        "\n",
        "          ax_if.plot(test_time, test_target_if, '-k')\n",
        "          ax_if.plot(test_time, test_prediction_if, '-r')\n",
        "          test_label = f\"Test ({self.loss_fn.name} = {test_loss_if}, {self.metric_fn.name} = {test_metric_if})\" \\\n",
        "                        if test_metric_if is not None \\\n",
        "                        else f\"Test ({self.loss_fn.name} = {test_loss_if})\"\n",
        "          if include_baseline:\n",
        "            ax_if.plot(test_time, test_baseline_prediction_if, '--g', linewidth = 1.0)\n",
        "            test_label = test_label + f\", Baseline ({self.loss_fn.name} = {test_baseline_loss_if}, {self.metric_fn.name} = {test_baseline_metric_if})\"\n",
        "\n",
        "          ax_if.axvspan(test_time.min(), test_time.max(), facecolor='red', alpha=0.2, label = test_label)\n",
        "\n",
        "        if (f == 0) & (feature_names is not None):\n",
        "          ax_if.set_title(output_name)\n",
        "        if f == output_size[i] - 1:\n",
        "          ax_if.set_xlabel(f\"Time [{self.trainer.datamodule.time_unit}]\")\n",
        "\n",
        "        if feature_names is None:\n",
        "          ylabel = f\"{output_name} [{output_feature_units_if}]\" if output_feature_units_if is not None else f\"{output_name}\"\n",
        "        elif output_feature_name_if is not None:\n",
        "          ylabel = f\"{output_feature_name_if} [{output_feature_units_if}]\" if output_feature_units_if is not None else f\"{output_feature_name_if}\"\n",
        "        else:\n",
        "          ylabel = f\"[{output_feature_units_if}]\" if output_feature_units_if is not None else None\n",
        "\n",
        "        ax_if.set_ylabel(ylabel)\n",
        "\n",
        "        ax_if.legend(loc='upper left', bbox_to_anchor=(1.02, 1), ncol=1) # loc = 'upper center', bbox_to_anchor = (0.5, 1.15), ncol = 5))\n",
        "        ax_if.grid()\n",
        "\n",
        "    if num_outputs > 1:\n",
        "      for i in range(num_outputs, rows):\n",
        "          ax[i].axis(\"off\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "\n",
        "    self.actual_prediction_plot = plt.gcf()\n",
        "  ##\n",
        "\n",
        "  ## forecast\n",
        "  def forecast(self, num_forecast_steps = 1, hiddens = None):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      steps = None\n",
        "\n",
        "      if self.trainer.datamodule.test_dl is not None:\n",
        "        for batch in self.trainer.datamodule.test_dl.dl: last_sample = batch\n",
        "        data = self.trainer.datamodule.test_data\n",
        "      elif self.trainer.datamodule.val_dl is not None:\n",
        "        for batch in self.trainer.datamodule.val_dl.dl: last_sample = batch\n",
        "        data = self.trainer.datamodule.val_data\n",
        "      else:\n",
        "        for batch in self.trainer.datamodule.train_dl.dl: last_sample = batch\n",
        "        data = self.trainer.datamodule.train_data\n",
        "\n",
        "      input, _, steps, batch_size = last_sample\n",
        "\n",
        "      last_input_sample, last_steps_sample = input[:batch_size][-1:], steps[:batch_size][-1:]\n",
        "\n",
        "      max_output_len = self.trainer.datamodule.max_output_len\n",
        "      max_input_size, max_output_size = self.trainer.datamodule.max_input_size, self.trainer.datamodule.max_output_size\n",
        "      output_mask = self.trainer.datamodule.train_output_mask\n",
        "      output_input_idx, input_output_idx = self.trainer.datamodule.output_input_idx, self.trainer.datamodule.input_output_idx\n",
        "\n",
        "      output, hiddens = self.forward(input = last_input_sample,\n",
        "                                    steps = last_steps_sample,\n",
        "                                    hiddens = hiddens,\n",
        "                                    target = None,\n",
        "                                    output_len = max_output_len,\n",
        "                                    output_mask = output_mask)\n",
        "\n",
        "      forecast = torch.empty((1, 0, max_output_size)).to(output)\n",
        "      forecast_steps = torch.empty((1, 0)).to(last_steps_sample)\n",
        "\n",
        "      input, steps = last_input_sample, last_steps_sample\n",
        "\n",
        "      steps += max_output_len\n",
        "\n",
        "      while forecast.shape[1] < num_forecast_steps:\n",
        "\n",
        "        input_ = torch.zeros((1, max_output_len, max_input_size)).to(input)\n",
        "\n",
        "        if len(output_input_idx) > 0:\n",
        "          input_[:, :, output_input_idx] = output[:, -max_output_len:, input_output_idx]\n",
        "\n",
        "        input = torch.cat((input[:, max_output_len:], input_), 1)\n",
        "\n",
        "        output, hiddens = self.forward(input = input,\n",
        "                                       steps = steps,\n",
        "                                       hiddens = hiddens,\n",
        "                                       target = None,\n",
        "                                       output_len = max_output_len,\n",
        "                                       output_mask = output_mask)\n",
        "\n",
        "        forecast = torch.cat((forecast, output[:, -max_output_len:]), 1)\n",
        "        forecast_steps = torch.cat((forecast_steps, steps[:, -max_output_len:]), 1)\n",
        "\n",
        "        steps += max_output_len\n",
        "\n",
        "      forecast, forecast_steps = forecast[:, -num_forecast_steps:], forecast_steps[:, -num_forecast_steps:]\n",
        "      forecast_reduced, forecast_steps_reduced = self.generate_reduced_output(forecast, forecast_steps,\n",
        "                                                                          transforms=self.trainer.datamodule.transforms)\n",
        "\n",
        "      # self.forecast_data = {\"warmup_time\": }\n",
        "\n",
        "    return forecast_reduced, forecast_steps_reduced\n",
        "\n",
        "\n",
        "  ##\n",
        "  def generate_reduced_output(self, output, output_steps, reduction='mean', transforms=None):\n",
        "\n",
        "    # Get unique output steps and remove any -1 values\n",
        "    unique_output_steps = output_steps.unique()\n",
        "    unique_output_steps = unique_output_steps[unique_output_steps != -1]\n",
        "\n",
        "    # Create a tensor to store the reduced output\n",
        "    output_reduced = torch.zeros((len(unique_output_steps), np.sum(self.model.output_size))).to(output)\n",
        "\n",
        "    k = -1\n",
        "    for step in unique_output_steps:\n",
        "        k += 1\n",
        "\n",
        "        # Find the indices of the current step in the output_steps tensor\n",
        "        batch_step_idx = torch.where(output_steps == step)\n",
        "        num_step_output = len(batch_step_idx[0])\n",
        "\n",
        "        j = 0\n",
        "        for i in range(self.model.num_outputs):\n",
        "\n",
        "            # Extract the output for the current output index\n",
        "            output_i = output[:, :, j:(j + self.model.output_size[i])]\n",
        "            output_reduced_i = []\n",
        "\n",
        "            step_output_i = []\n",
        "            for batch_idx, step_idx in zip(*batch_step_idx[:2]):\n",
        "                step_output_i.append(output_i[batch_idx, step_idx, :].reshape(1, 1, -1))\n",
        "\n",
        "            if len(step_output_i) > 0:\n",
        "                step_output_i = torch.cat(step_output_i, 0)\n",
        "\n",
        "                # Reduce the step outputs based on the specified reduction method\n",
        "                step_output_reduced_i = (step_output_i.median(0)[0] if reduction == 'median' else\n",
        "                                         step_output_i.mean(0)).reshape(-1, self.model.output_size[i])\n",
        "\n",
        "                # Assign the reduced output to the output_reduced tensor\n",
        "                output_reduced[k, j:(j + self.model.output_size[i])] = step_output_reduced_i.squeeze(0)\n",
        "\n",
        "            j += self.model.output_size[i]\n",
        "\n",
        "    # Optionally invert the reduced output using data scalers\n",
        "    if transforms is not None:\n",
        "        j = 0\n",
        "        for i in range(self.model.num_outputs):\n",
        "            output_name_i = self.trainer.datamodule.output_names[i]\n",
        "            output_reduced[:, j:(j + self.model.output_size[i])] = transforms[output_name_i].inverse_transform(output_reduced[:, j:(j + self.model.output_size[i])])\n",
        "            j += self.model.output_size[i]\n",
        "\n",
        "    # Return the reduced output and unique output steps\n",
        "    return output_reduced, unique_output_steps\n",
        "\n",
        "  def fit(self,\n",
        "          datamodule,\n",
        "          max_epochs = 20,\n",
        "          callbacks = [None]):\n",
        "\n",
        "    try:\n",
        "      self.trainer = pl.Trainer(max_epochs = max_epochs,\n",
        "                                accelerator = 'gpu' if self.model.device == 'cuda' else 'cpu',\n",
        "                                callbacks = callbacks)\n",
        "\n",
        "      self.trainer.fit(self,\n",
        "                       datamodule = datamodule)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "      state_dict = self.model.state_dict()\n",
        "      self.model.to(device = self.model.device,\n",
        "                    dtype = self.model.dtype)\n",
        "      self.model.load_state_dict(state_dict)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}